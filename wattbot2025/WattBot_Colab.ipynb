{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ü§ñ WattBot 2025 - Google Colab Deployment\n",
    "\n",
    "Run WattBot pipeline on Google Colab with **FREE GPU**!\n",
    "\n",
    "**Advantages:**\n",
    "- ‚úÖ Free GPU (T4)\n",
    "- ‚úÖ 15GB RAM\n",
    "- ‚úÖ No disk space issues\n",
    "- ‚úÖ No setup required\n",
    "- ‚úÖ Run in browser\n",
    "\n",
    "**Estimated Time:** ~10-15 minutes with GPU\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Quick Start\n",
    "\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí T4\n",
    "2. **Run all cells**: Runtime ‚Üí Run all\n",
    "3. **Enter your API key** when prompted\n",
    "4. **Wait ~10-15 minutes**\n",
    "5. **Download results** from the last cell\n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": "# Step 1: Clone the repository\nprint(\"üì¶ Cloning WattBot repository...\")\n!git clone https://github.com/Arunjay4213/Wattbot.git\n%cd Wattbot/wattbot2025\n\nprint(\"\\n‚úÖ Repository cloned!\")\nprint(\"\\nüìä Checking data chunks...\")\n!ls data/chunks/*.json | wc -l"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": "# Step 2: Install dependencies\nprint(\"üì¶ Installing dependencies (this may take 2-3 minutes)...\")\nprint(\"‚è≥ Using Colab-compatible versions...\")\nprint()\n\n# Install all required packages (Colab has pandas, numpy, torch pre-installed)\n!pip install python-dotenv pyyaml google-generativeai sentence-transformers rank-bm25 scikit-learn anthropic openai\n\nprint()\nprint(\"‚úÖ Dependencies installed!\")\nprint()\nprint(\"Verifying installation...\")\n!pip list | grep -E \"(rank-bm25|sentence-transformers|google-generativeai|anthropic)\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "api_key"
   },
   "outputs": [],
   "source": [
    "# Step 3: Set up API key\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "print(\"üîë Enter your Google API key\")\n",
    "print(\"Get it from: https://makersuite.google.com/app/apikey\")\n",
    "print()\n",
    "\n",
    "GOOGLE_API_KEY = getpass(\"Paste your GOOGLE_API_KEY: \")\n",
    "\n",
    "# Create .env file\n",
    "with open('.env', 'w') as f:\n",
    "    f.write(f\"GOOGLE_API_KEY={GOOGLE_API_KEY}\\n\")\n",
    "    f.write(\"OPENAI_API_KEY=your_openai_api_key_here\\n\")\n",
    "    f.write(\"ANTHROPIC_API_KEY=your_anthropic_key_here\\n\")\n",
    "\n",
    "print(\"‚úÖ API key configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": "# Step 4: Check GPU availability\nimport torch\n\nif torch.cuda.is_available():\n    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\nelse:\n    print(\"‚ö†Ô∏è  No GPU detected. Pipeline will run on CPU (slower).\")\n    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_gemini"
   },
   "outputs": [],
   "source": "# Step 5: Modify run.py for auto-execution\nprint(\"üîß Configuring pipeline for automatic execution...\")\n\nwith open('run.py', 'r') as f:\n    content = f.read()\n\n# Replace the input prompt with automatic 'y'\ncontent = content.replace(\n    'response = input(\"\\\\nü§î Proceed with test set? (y/n): \")',\n    'response = \"y\"  # Auto-proceed in Colab'\n)\n\nwith open('run.py', 'w') as f:\n    f.write(content)\n\nprint(\"‚úÖ Pipeline configured for automatic execution!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_pipeline"
   },
   "outputs": [],
   "source": "# Step 6: Run the full pipeline\nprint(\"=\"*70)\nprint(\"üöÄ Starting WattBot Pipeline\")\nprint(\"=\"*70)\nprint()\nprint(\"This will take approximately 10-15 minutes with GPU\")\nprint(\"You can monitor progress below...\")\nprint()\n\n!python3 run.py"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download"
   },
   "outputs": [],
   "source": [
    "# Step 7: Download results\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"üì• Downloading submission.csv...\")\n",
    "\n",
    "if os.path.exists('data/processed/submission.csv'):\n",
    "    files.download('data/processed/submission.csv')\n",
    "    print(\"‚úÖ Download started! Check your browser downloads.\")\n",
    "    \n",
    "    # Show preview\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('data/processed/submission.csv')\n",
    "    print(f\"\\nüìä Results Preview ({len(df)} questions):\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"‚ùå submission.csv not found. Check if pipeline completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "troubleshooting"
   },
   "source": [
    "---\n",
    "\n",
    "## üîß Troubleshooting\n",
    "\n",
    "### No GPU available?\n",
    "- Go to: **Runtime** ‚Üí **Change runtime type** ‚Üí **Hardware accelerator** ‚Üí **GPU** ‚Üí **Save**\n",
    "- Then: **Runtime** ‚Üí **Restart runtime**\n",
    "\n",
    "### Out of memory?\n",
    "- Use GPU with high RAM: **Runtime** ‚Üí **Change runtime type** ‚Üí **GPU** ‚Üí **T4**\n",
    "- Clear outputs: **Edit** ‚Üí **Clear all outputs**\n",
    "\n",
    "### Session timeout?\n",
    "- Colab free tier has ~12 hour limit\n",
    "- Keep the tab active\n",
    "- Pipeline should complete in 10-15 minutes\n",
    "\n",
    "### API quota exceeded?\n",
    "- Gemini 2.5 Flash has high free tier limits\n",
    "- If exceeded, wait or use a different API key\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Expected Timeline\n",
    "\n",
    "| Step | Time (GPU) | Time (CPU) |\n",
    "|------|-----------|------------|\n",
    "| Clone repo | 10s | 10s |\n",
    "| Install deps | 2-3 min | 2-3 min |\n",
    "| Build index | 5-7 min | 20-30 min |\n",
    "| Test questions | 2-3 min | 5-10 min |\n",
    "| **Total** | **~10-15 min** | **~30-45 min** |\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Tips\n",
    "\n",
    "- **Save to Drive**: Uncomment cells below to save to Google Drive\n",
    "- **Monitor**: Watch the progress bars in real-time\n",
    "- **Cost**: Completely FREE on Colab!\n",
    "\n",
    "---\n",
    "\n",
    "**Need help?** Check the GitHub repo: https://github.com/Arunjay4213/Wattbot\n",
    "\n",
    "**Good luck with WattBot! üöÄ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_to_drive"
   },
   "outputs": [],
   "source": [
    "# Optional: Save results to Google Drive\n",
    "# Uncomment to use:\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import shutil\n",
    "# shutil.copy('data/processed/submission.csv', '/content/drive/MyDrive/wattbot_submission.csv')\n",
    "# print(\"‚úÖ Saved to Google Drive: MyDrive/wattbot_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}