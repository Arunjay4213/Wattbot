[
  {
    "rank": 1,
    "score": 6.067754851013553,
    "content": "cifically, the SCI uses a \"consequential\" carbon accounting approach, which aims to quantify the marginal change in\nemissions caused by decisions or interventions. This differs from the commonly used \"attributional\" carbon accounting\napproach, which uses average carbon intensity data, meaning it does not provide the most actionable information to\nhelp reduce carbon emissions. Due to the myriad pot",
    "type": "text"
  },
  {
    "rank": 2,
    "score": 5.662717558775276,
    "content": "enter plays a significant role in the carbon intensity for\n\"a given cloud instance, and find that choosing an appropriate region can have the largest operational emissions reduction impact. We\"\n\"also present new results showing that the time of day has meaningful impact on operational software carbon intensity.Finally, we\"\nconclude with recommendations for how machine learning practitioners can us",
    "type": "table"
  },
  {
    "rank": 3,
    "score": 5.602384503884998,
    "content": "carbon intensity for\na given cloud instance, and find that choosing an appropriate region can have the largest operational emissions reduction impact. We\nalso present new results showing that the time of day has meaningful impact on operational software carbon intensity.Finally, we\nconclude with recommendations for how machine learning practitioners can use software carbon intensity information to",
    "type": "text"
  },
  {
    "rank": 4,
    "score": 5.539398340826914,
    "content": "ch aims to quantify the marginal change in\"\n\"emissions caused by decisions or interventions. This differs from the commonly used \"\"attributional\"\" carbon accounting\"\n\"approach, which uses average carbon intensity data, meaning it does not provide the most actionable information to\"\nhelp reduce carbon emissions. Due to the myriad potential pitfalls of relying on market-based measures in place of\n\"a",
    "type": "table"
  },
  {
    "rank": 5,
    "score": 5.31341952264698,
    "content": "high emissions and very low emissions, and\nthus Pause and Resume can lead to significant reductions. However, other regions do not present as much variance,\nand thus lead to less reduction in emissions. See Figures 3 and 4. The lack of geographic diversity in the region list is\nan unfortunate consequence of the unavailability of carbon intensity data from other continents; we hope such data\nbecome",
    "type": "text"
  },
  {
    "rank": 6,
    "score": 4.961725706120289,
    "content": "y\nWest EuropeNorth EuropeNorwayUK SouthAustralia051015202530CO2 emissions decrease in %25%\n50%\n75%\n100% (b)Pause and Resume optimization for 6B parameters Transformer.\nFig. 4. What proportion of emissions can we expect to save if we pause an AI workload when emissions in a region are high and\nresume when emissions are low, increasing the total duration by up to double the original duration? For sh",
    "type": "text"
  },
  {
    "rank": 7,
    "score": 4.182917165402106,
    "content": "to about 25%. We confirmed with WattTime that emissions estimates for West US were correct, as that region has large\nvariance.\n6.1.2 Comparable Duration Increases. In the previous section we examined the amount of emissions reduction for\nour two algorithms by region, and compared Pause and Resume increasing duration by a proportion of the original\nexperiment and Flexible Start by a fixed duration.",
    "type": "text"
  },
  {
    "rank": 8,
    "score": 3.547281611519623,
    "content": "than 30% in multiple regions,\nand up to 80% in West US; for very long runs like training a 6 billion parameter language model for 8 days (b), changing the start time\nby up to 24 hours leads to less than 1.5% reduction at best in any region. Note: we confirmed with WattTime that emissions estimates\nfor West US were correct, that region has large variance.\nduring those intervals and compute the corr",
    "type": "text"
  },
  {
    "rank": 9,
    "score": 3.547281611519623,
    "content": "0\n\"and up to 80% in West US; for very long runs like training a 6 billion parameter language model for 8 days (b), changing the start time\"\nby up to 24 hours leads to less than 1.5% reduction at best in any region. Note: we confirmed with WattTime that emissions estimates\n\"for West US were correct, that region has large variance.\"\nduring those intervals and compute the corresponding emissions. We ",
    "type": "table"
  },
  {
    "rank": 10,
    "score": 3.270534195996002,
    "content": "on of this paper is the simplest: a,\npresentation of the software carbon intensity (SCI) as a proxy for carbon emissions for a given cloud instance as it is,\nrunning.,\n\"3.1\nMethodology: Computing CO2 Intensity\",\n\"In this section we describe a method for estimating carbon intensity for cloud instances. At a high level, this involves\",\n\"tracking electricity consumption of hardware related to a singl",
    "type": "table"
  },
  {
    "rank": 11,
    "score": 3.090977841120739,
    "content": "tensity measurement ( ğ¼). Once more this can be further refined to simply:\nğ‘†ğ¶ğ¼=ğ¶perğ‘… (3)\n4\n\nMeasuring the Carbon Intensity of AI in Cloud Instances FAccT â€™22, June 21â€“24, 2022, Seoul, Republic of Korea\nwhereğ¶=ğ‘‚+ğ‘€is the software carbon intensity for a given cloud instance. In this paper, we focus on measuring\noperational emissions ğ‘‚, and leave measurement and accounting for embodied emissions due t",
    "type": "text"
  },
  {
    "rank": 12,
    "score": 3.0866916391297647,
    "content": "icity consumption of hardware related to a single cloud instance, and mapping that electricity usage to\nCO2emissions by using a grid-based carbon intensity.\nAs developed by the Green Software Foundation, the Software Carbon Intensity ( ğ‘†ğ¶ğ¼) is a rate, carbon emissions per\none functional unit, or R. The equation used to calculate the ğ‘†ğ¶ğ¼value of a software system is therefore:\nğ‘†ğ¶ğ¼=((ğ¸âˆ—ğ¼)+ğ‘€)perğ‘… (1)",
    "type": "text"
  },
  {
    "rank": 13,
    "score": 3.0834868048108928,
    "content": "0\n\"Measuring the Carbon Intensity of AI in Cloud Instances\nFAccT â€™22, June 21â€“24, 2022, Seoul, Republic of Korea\"\n\"where ğ¶ = ğ‘‚ + ğ‘€ is the software carbon intensity for a given cloud instance. In this paper, we focus on measuring\"\n\"operational emissions ğ‘‚, and leave measurement and accounting for embodied emissions due to specialized ML hardware\"\nsuch as GPUs to future work (see Â§8).\nThe objective ",
    "type": "table"
  },
  {
    "rank": 14,
    "score": 3.07192430247256,
    "content": ", the computational demands of which incur a high energy cost and a\ncommensurate carbon footprint. As a result, recent scholarship has called for better estimates of the greenhouse gas impact of AI: data\nscientists today do not have easy or reliable access to measurements of this information, which precludes development of actionable\ntactics. We argue that cloud providers presenting information ab",
    "type": "text"
  },
  {
    "rank": 15,
    "score": 2.998958101248194,
    "content": "uch as machine learning, the computational demands of which incur a high energy cost and a\"\n\"commensurate carbon footprint. As a result, recent scholarship has called for better estimates of the greenhouse gas impact of AI: data\"\n\"scientists today do not have easy or reliable access to measurements of this information, which precludes development of actionable\"\ntactics. We argue that cloud provide",
    "type": "table"
  },
  {
    "rank": 16,
    "score": 2.9457213147497834,
    "content": "of carbon dioxide equivalent per kilowatt-hour of electricity (gCO 2eq/kWh)\nâ€¢ğ‘€=Embodied carbon (also referred to as â€œembedded carbonâ€) is the amount of carbon emitted during the\ncreation, usage, and disposal of a hardware device. When software runs on a device, a fraction of the total\nembodied emissions of the device is allocated to the software.\nâ€¢ğ‘…=Functional unit. In this instance, we are defini",
    "type": "text"
  },
  {
    "rank": 17,
    "score": 2.916176182819811,
    "content": "0,1\n,(1)\nwhere:,\n,\"â€¢ ğ¸ = Energy consumed by a software system. Specifically, we focus on energy consumption of Graphical Processing\"\n\"Units, or GPUs. The units used are kilowatt-hours (kWh).\",\n,â€¢ ğ¼ = Location-based marginal carbon emissions for the grid that powers the datacenter. WattTime provides\nmeasurements of grams of carbon dioxide equivalent per kilowatt-hour of electricity (gCO2eq/kWh),\nâ€¢ ",
    "type": "table"
  },
  {
    "rank": 18,
    "score": 2.881688600970552,
    "content": "ligible but beyond the scope of this paper. Finally, for workloads that do not use GPUs (e.g., storage\",,,,,,,\n,\"or web hosting) we recommend users choose low emissions regions and times of day, as they will not have access to\",,,,,,,\n,single-instance emissions calculations. We leave it open for future research to address how to appropriately allocate,,,,,,,\n,CO2 emissions from such data center-wi",
    "type": "table"
  },
  {
    "rank": 19,
    "score": 2.8655566026074037,
    "content": "0\n\"Measuring the Carbon Intensity of AI in Cloud Instances\nFAccT â€™22, June 21â€“24, 2022, Seoul, Republic of Korea\"\n\"Foundationâ€™s guidelines regarding Software Carbon Intensity (SCI), and suggest future areas of research to improve the\"\nstate of carbon estimation and reporting in AI.\n\"2\nRELATED WORK\"\n\"Attention was first drawn to the environmental impact of AI research by the seminal work of Strubel",
    "type": "table"
  },
  {
    "rank": 20,
    "score": 2.815830515023203,
    "content": "fic marginal emissions data per energy unit. We provide measurements of operational\n\"software carbon intensity for a set of modern models covering natural language processing and computer vision applications, and a\"\n\"wide range of model sizes, including pretraining of a 6.1 billion parameter language model. We then evaluate a suite of approaches for\"\n\"reducing emissions on the Microsoft Azure clou",
    "type": "table"
  }
]