[
  {
    "rank": 1,
    "score": 8.270308979716624,
    "content": "s): Average power draw can be calculated by dividing total energy,,,,,,,,,,,,\n,consumption by the time taken to run the benchmark. This is useful for power provisioning.,,,,,,,,,,,,\n,• Monetary cost ($): Monetary cost can be calculated by multiplying energy consumption by the,,,,,,,,,,,,\n,cost of electricity in the region and time frame in which the benchmark was run.,,,,,,,,,,,,\n,• Operational ca",
    "type": "table"
  },
  {
    "rank": 2,
    "score": 7.382568397923224,
    "content": "ars behind each solid bar are estimations based on the GPU’s TDP, with numbers showing\nthe ratio of overestimation. Note the log scale Y-axis.\nMetrics. Energy consumption (Joules) reported by the ML.ENERGY Benchmark is a fundamental\nquantity that can be used to derive other useful metrics.\n•Average power draw (Watts) : Average power draw can be calculated by dividing total energy\nconsumption by th",
    "type": "text"
  },
  {
    "rank": 3,
    "score": 6.218229076649438,
    "content": "ohan Yan, Hasan\nGenc, Grace Dinh, Qijing Huang, Kurt Keutzer, Michael W. Mahoney, Sophia Shao, and Amir\nGholami. Full stack optimization of transformer inference. Architecture and System Support\nfor Transformer Models , 2023.\n[34] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu,\nJoseph Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large languag",
    "type": "text"
  },
  {
    "rank": 4,
    "score": 6.016895361492303,
    "content": "ty estimates the greenhouse gas emissions\nassociated with the electricity consumed. It can be calculated by multiplying energy consumption\nby the carbon intensity of the particular region and time frame in which the benchmark was run.\n4 Results Highlight\nIn this section, we highlight notable results from the ML.ENERGY Benchmark; the full set of\nresults is available on the ML.ENERGY Leaderboard.3Th",
    "type": "text"
  },
  {
    "rank": 5,
    "score": 3.803028321050168,
    "content": "apacity of a single GPU. This requires\nmultiple GPUs to execute inference for a single model, and GPUs must constantly communicate with\neach other to do so [58].\nIn order to ablate the effect of communication, we employ the same Llama 3.1 8B model and vary\nthe number of GPUs used (Figure 9). Because the amount of computation executed is the same\nregardless of the number of GPUs, energy consumption",
    "type": "text"
  },
  {
    "rank": 6,
    "score": 3.492094166077999,
    "content": "ween the GPUs offsets the\nreduction in computation time. Since communication time increases with the number of GPUs, using\ntoo many GPUs can lead to slowdowns in executing the same amount of computation and increase\nenergy consumption.\n15\n\n0 200 400 600 800 1000\nBatch size0200400600Power draw (W)\nA100 TDP (max power draw)H100 TDP (max power draw)\nA100 H100(a) Llama 3.1 8B\n0 200 400 600 800 1000\nBa",
    "type": "text"
  },
  {
    "rank": 7,
    "score": 3.386991346470018,
    "content": "r code generated by\nchatGPT really correct? rigorous evaluation of large language models for code generation. In\nNeurIPS , 2023.\n[41] Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Noua-\nmane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, et al. Starcoder 2 and the stack\nv2: The next generation. arXiv preprint arXiv:2402.19173 , 2024.\n[42] Alexandra Sash",
    "type": "text"
  },
  {
    "rank": 8,
    "score": 3.1209486650314147,
    "content": "s in the cloud.\n\"ASPLOS, 2024.\"\n\"[51] David Patterson,\nJoseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel\"\n\"Rothchild, David So, Maud Texier, and Jeff Dean. Carbon emissions and large neural network\"\n\"training. arXiv preprint, 2021.\"\n\"[52] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller,\"\n\"Joe Penna, and Robin Rombach. SDXL: Improving latent d",
    "type": "table"
  },
  {
    "rank": 9,
    "score": 3.1075587181115893,
    "content": "Sora. https://openai.com/index/sora , 2024.\n[50] Pratyush Patel, Esha Choukse, Chaojie Zhang, Íñigo Goiri, Brijesh Warrier, Nithish Mahalingam,\nand Ricardo Bianchini. Characterizing power management opportunities for llms in the cloud.\nASPLOS , 2024.\n[51] David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel\nRothchild, David So, Maud Texier, and Jeff Dean. Carbon emis",
    "type": "text"
  },
  {
    "rank": 10,
    "score": 0.0,
    "content": "arXiv:2505.06371v1  [cs.LG]  9 May 2025The ML.ENERGY Benchmark: Toward Automated\nInference Energy Measurement and Optimization\nJae-Won Chung Jiachen Liu Jeff J. Ma Ruofan Wu\nOh Jun Kweon Yuxuan Xia Zhiyu Wu Mosharaf Chowdhury\nUniversity of Michigan\nAbstract\nAs the adoption of Generative AI in real-world services grow explosively, energy\nhas emerged as a critical bottleneck resource. However, energ",
    "type": "text"
  },
  {
    "rank": 11,
    "score": 0.0,
    "content": "derboard, which have\nserved as a valuable resource for those hoping to understand and optimize the\nenergy consumption of their generative AI services. In this paper, we explain four\nkey design principles for benchmarking ML energy we have acquired over time,\nand then describe how they are implemented in the ML.ENERGY Benchmark.\nWe then highlight results from the latest iteration of the benchmark, ",
    "type": "text"
  },
  {
    "rank": 12,
    "score": 0.0,
    "content": "g computed by the\nmodel. The ML.ENERGY Benchmark is open-source and can be easily extended\nto various customized models and application scenarios.\n1 Introduction\nGenerative AI models have rapidly transitioned from research prototypes to real-world services such\nas ChatGPT [48], Character AI [4], Sora [49], and Midjourney [45]. However, exponential growth\nrarely continues without facing scaling bot",
    "type": "text"
  },
  {
    "rank": 13,
    "score": 0.0,
    "content": "ow, and sometimes impossible. This particularly impacts\nserving real-world services as ML inference reportedly accounts for 80–90% of the total compute\ndemand [10, 27, 50, 51]. Left unaddressed, the energy bottleneck will not only hinder AI research and\ndevelopment progress [26], but also lead to energy being either squeezed out of existing electricity\ngrids and impacting availability and price [3",
    "type": "text"
  },
  {
    "rank": 14,
    "score": 0.0,
    "content": "nergy measurement and accounting during\nexecution, let alone optimization? To bridge this gap, we launched the ML.ENERGY Leaderboard,1\nthe first inference energy leaderboard for modern generative AI models to the best of our knowledge.\nThe Leaderboard has been gradually expanding in multiple dimensions to now include (1) 40 different\ngenerative AI model architectures across a wide range of tasks –",
    "type": "text"
  },
  {
    "rank": 15,
    "score": 0.0,
    "content": "U type = A100……Max batch size = 256Pipeline parallel = 1Tensor parallel = 2GPU type = H100123\nTime (s)Energy (J)\nTarget4\nMeasured energy & latencyFigure 1: Overview of the benchmarking and optimization flow of the ML.ENERGY Benchmark.\ncoding, VLM [38] visual chat, and text-to-image, text-to-video, and image-to-video generation using\nDiffusion models [12, 20] – and (2) more up-to-date hardware and ",
    "type": "text"
  },
  {
    "rank": 16,
    "score": 0.0,
    "content": "provides an easily extensible benchmark suite and a comprehensive\nset of tools for measuring the inference energy consumption of generative AI models for various\ntasks under realistic deployment environments.\n•Automated Optimization : Based on energy measurement results, it provides automated energy\noptimization recommendations for generative AI model deployment.\nFinally, we highlight notable resu",
    "type": "text"
  },
  {
    "rank": 17,
    "score": 0.0,
    "content": "cked by automated optimization (Section 4).\nThe ML.ENERGY Benchmark is open-source on GitHub,2and the ML.ENERGY Leaderboard allows\neveryone to browse full results from the ML.ENERGY Benchmark. The benchmark is designed to be\neasily extensible, allowing users to benchmark their models and compare them to others without the\nheavy lifting of building their own benchmarking dataset, runtime, and analy",
    "type": "text"
  },
  {
    "rank": 18,
    "score": 0.0,
    "content": ", and ultimately actionable.\n2.1 Generalizability and Portability\nGoal. Every computer system is configured with different hardware and software components, and\nmeasurements from a particular system will never truly represent those from another system. For\ninstance, systems can be configured with different CPU and DRAM models, and running different\n2https://github.com/ml-energy/leaderboard\n2\n\nLinu",
    "type": "text"
  },
  {
    "rank": 19,
    "score": 0.0,
    "content": "provide generalizable insights and recommendations across a wide range of systems.\nOur approach. We focus on software-based GPU energy measurement for the following reasons:\n•GPUs are the dominant worker and energy consumer in a system running ML services, accounting\nfor 50–70% of the total provisioned power in the datacenter [50].\n•Compared to other hardware components, GPU models are more standa",
    "type": "text"
  },
  {
    "rank": 20,
    "score": 0.0,
    "content": "senting Real-World Deployments\nGoal. Benchmarking results often inform real-world deployment optimizations, are used to plan\nfuture energy usage, affect the design of new hardware and software systems, and serve as base num-\nbers for long term projections that affect policymaking. Therefore, it is crucial that our measurements\nrepresent those from real-world deployments as closely as possible.\nOur",
    "type": "text"
  }
]