[
  {
    "type": "text",
    "content": "ARTIFICIAL INTELLIGENCE\nAND LIFE IN 2030\nONE HUNDRED YEAR STUDY ON ARTIFICIAL INTELLIGENCE | REPORT OF THE 2015 STUDY PANEL | SEPTEMBER 2016\nPREFACE\nThe One Hundred Year Study on\nArtificial Intelligence, launched\nin the fall of 2014, is a long-\nterm investigation of the field of\nArtificial Intelligence (AI) and\nits influences on people, their\ncommunities, and society. It\nconsiders the science, engineering,\nand deployment of AI-enabled\ncomputing systems. As its core\nactivity, the Standing Committee\nthat oversees the One Hundred\nYear Study forms a Study Panel\nevery five years to assess the\ncurrent state of AI. The Study\nPanel reviews AI’s progress in the years following the immediately prior report, The overarching purpose",
    "page": 1
  },
  {
    "type": "text",
    "content": "reviews AI’s progress in the years following the immediately prior report, The overarching purpose\nenvisions the potential advances that lie ahead, and describes the technical and\nof the One Hundred Year\nsocietal challenges and opportunities these advances raise, including in such arenas as\nethics, economics, and the design of systems compatible with human cognition. The\nStudy’s periodic expert\noverarching purpose of the One Hundred Year Study’s periodic expert review is to\nprovide a collected and connected set of reflections about AI and its influences as the review is to provide a\nfield advances. The studies are expected to develop syntheses and assessments that\ncollected and connected\nprovide expert-informed guidance for directions in",
    "page": 1
  },
  {
    "type": "text",
    "content": "ses and assessments that\ncollected and connected\nprovide expert-informed guidance for directions in\nAI research, development, and systems design, as well as programs and policies to\nset of reflections about\nhelp ensure that these systems broadly benefit individuals and society.1\nThe One Hundred Year Study is modeled on an earlier effort informally known as AI and its influences as\nthe “AAAI Asilomar Study.” During 2008-2009, the then president of the Association\nfor the Advancement of Artificial Intelligence (AAAI), Eric Horvitz, assembled a the field advances.\ngroup of AI experts from multiple institutions and areas of the field, along with\nscholars of cognitive science, philosophy, and law. Working in distributed subgroups,",
    "page": 1
  },
  {
    "type": "text",
    "content": "d, along with\nscholars of cognitive science, philosophy, and law. Working in distributed subgroups,\nthe participants addressed near-term AI developments, long-term possibilities,\nand legal and ethical concerns, and then came together in a three-day meeting at\nAsilomar to share and discuss their findings. A short written report on the intensive\nmeeting discussions, amplified by the participants’ subsequent discussions with other\ncolleagues, generated widespread interest and debate in the field and beyond.\nThe impact of the Asilomar meeting, and important advances in AI that included\nAI algorithms and technologies starting to enter daily life around the globe, spurred\nthe idea of a long-term recurring study of AI and its influence on people and society.",
    "page": 1
  },
  {
    "type": "text",
    "content": "obe, spurred\nthe idea of a long-term recurring study of AI and its influence on people and society.\nThe One Hundred Year Study was subsequently endowed at a university to enable\n1 “One Hundred Year Study on Artificial Intelligence (AI100),” Stanford University, accessed\nAugust 1, 2016, https://ai100.stanford.edu.",
    "page": 1
  },
  {
    "type": "text",
    "content": "extended deep thought and cross-disciplinary scholarly investigations that could\ninspire innovation and provide intelligent advice to government agencies and industry.\nThis report is the first in the planned series of studies that will continue for at least\na hundred years. The Standing Committee defined a Study Panel charge for the\ninaugural Study Panel in the summer of 2015 and recruited Professor Peter Stone,\nat the University of Texas at Austin, to chair the panel. The seventeen-member\nStudy Panel, comprised of experts in AI from academia, corporate laboratories\nand industry, and AI-savvy scholars in law, political science, policy, and economics,\nwas launched in mid-fall 2015. The participants represent diverse specialties and\ngeographic regions, genders, and career stages.",
    "page": 2
  },
  {
    "type": "text",
    "content": "The participants represent diverse specialties and\ngeographic regions, genders, and career stages.\nThe Standing Committee extensively discussed ways to frame the Study Panel\ncharge to consider both recent advances in AI and potential societal impacts on jobs,\nthe environment, transportation, public safety, healthcare, community engagement,\nand government. The committee considered various ways to focus the study,\nincluding surveying subfields and their status, examining a particular technology\nsuch as machine learning or natural language processing, and studying particular\napplication areas such as healthcare or transportation. The committee ultimately\nchose a thematic focus on “AI and Life in 2030” to recognize that AI’s various uses",
    "page": 2
  },
  {
    "type": "text",
    "content": "ttee ultimately\nchose a thematic focus on “AI and Life in 2030” to recognize that AI’s various uses\nand impacts will not occur independently of one another, or of a multitude of other\nsocietal and technological developments. Acknowledging the central role cities have\nplayed throughout most of human experience, the focus was narrowed to the large\nurban areas where most people live. The Standing Committee further narrowed the\nfocus to a typical North American city in recognition of the great variability of urban\nsettings and cultures around the world, and limits on the first Study Panel’s efforts.\nThe Standing Committee expects that the projections, assessments, and proactive\nguidance stemming from the study will have broader global relevance and is making",
    "page": 2
  },
  {
    "type": "text",
    "content": "ts, and proactive\nguidance stemming from the study will have broader global relevance and is making\nplans for future studies to expand the scope of the project internationally.\nTABLE OF CONTENTS\nPREFACE\nEXECUTIVE SUMMARY 4\nOVERVIEW 6\nSECTION I: WHAT IS ARTIFICIAL INTELLIGENCE? 12\nDefining AI 12\nAI Research Trends 14\nSECTION II: AI BY DOMAIN 18\nTransportation 18\nHome/Service Robots 24\nHealthcare 25\nEducation 31\nLow-resource Communities 35\nPublic Safety and Security 36\nEmployment and Workplace 38\nEntertainment 40\nSECTION III: PROSPECTS AND RECOMMENDATIONS FOR AI PUBLIC POLICY 42\nAI Policy, Now and in the Future 42\n2 APPENDIX I: A SHORT HISTORY OF AI 50",
    "page": 2
  },
  {
    "type": "text",
    "content": "As one consequence of the decision to focus on life in North American cities,\nmilitary applications were deemed to be outside the scope of this initial report. This\nis not to minimize the importance of careful monitoring and deliberation about\nthe implications of AI advances for defense and warfare, including potentially\ndestabilizing developments and deployments.\nThe report is designed to address four intended audiences. For the general public,\nit aims to provide an accessible, scientifically and technologically accurate portrayal\nof the current state of AI and its potential. For industry, the report describes relevant\ntechnologies and legal and ethical challenges, and may help guide resource allocation.",
    "page": 3
  },
  {
    "type": "text",
    "content": "bes relevant\ntechnologies and legal and ethical challenges, and may help guide resource allocation.\nThe report is also directed to local, national, and international governments to help\nthem better plan for AI in governance. Finally, the report can help AI researchers,\nas well as their institutions and funders, to set priorities and consider the ethical and\nlegal issues raised by AI research and its applications.\nGiven the unique nature of the One Hundred Year Study on AI, we expect that\nfuture generations of Standing Committees and Study Panels, as well as research\nscientists, policy experts, leaders in the private and public sectors, and the general\npublic, will reflect on this assessment as they make new assessments of AI’s future. We",
    "page": 3
  },
  {
    "type": "text",
    "content": "the general\npublic, will reflect on this assessment as they make new assessments of AI’s future. We\nhope that this first effort in the series stretching out before us will be useful for both its\nfailures and successes in accurately predicting the trajectory and influences of AI.\nThe Standing Committee is grateful to the members of the Study Panel for\ninvesting their expertise, perspectives, and significant time to the creation of this\ninaugural report. We especially thank Professor Peter Stone for agreeing to serve as\nchair of the study and for his wise, skillful, and dedicated leadership of the panel,\nits discussions, and creation of the report.\nStanding Committee of the One Hundred Year Study of Artificial Intelligence\nBarbara J. Grosz, Chair Russ Altman Eric Horvitz",
    "page": 3
  },
  {
    "type": "text",
    "content": "One Hundred Year Study of Artificial Intelligence\nBarbara J. Grosz, Chair Russ Altman Eric Horvitz\nAlan Mackworth Tom Mitchell Deirdre Mulligan Yoav Shoham\nSTUDY PANEL\nPeter Stone, University of Texas at Austin, Chair\nRodney Brooks, Rethink Robotics\nErik Brynjolfsson, Massachussets Institute of Technology\nRyan Calo, University of Washington\nOren Etzioni, Allen Institute for AI\nGreg Hager, Johns Hopkins University\nJulia Hirschberg, Columbia University\nShivaram Kalyanakrishnan, Indian Institute of Technology Bombay\nEce Kamar, Microsoft Research\nSarit Kraus, Bar Ilan University\nKevin Leyton-Brown, University of British Columbia\nDavid Parkes, Harvard University\nWilliam Press, University of Texas at Austin\nAnnaLee (Anno) Saxenian, University of California, Berkeley",
    "page": 3
  },
  {
    "type": "text",
    "content": "am Press, University of Texas at Austin\nAnnaLee (Anno) Saxenian, University of California, Berkeley\nJulie Shah, Massachussets Institute of Technology\nMilind Tambe, University of Southern California\nAstro Teller, X\n© 2016 by Stanford University. Artificial\nAcknowledgments: The members of the Study Panel gratefully acknowledge the\nIntelligence and Life in 2030 is made\nsupport of and valuable input from the Standing Committee, especially the chair,\navailable under a Creative Commons\nBarbara Grosz, who handled with supreme grace the unenviable role of mediating Attribution-NoDerivatives 4.0 License\nbetween two large, very passionate committees. We also thank Kerry Tremain for his (International): https://creativecommons.",
    "page": 3
  },
  {
    "type": "text",
    "content": "assionate committees. We also thank Kerry Tremain for his (International): https://creativecommons.\ntireless and insightful input on the written product during the extensive editing and org/licenses/by-nd/4.0/\npolishing process, which unquestionably strengthened the report considerably. 3",
    "page": 3
  },
  {
    "type": "text",
    "content": "EXECUTIVE SUMMARY\nArtificial Intelligence (AI) is a science and a set of computational technologies that\nare inspired by—but typically operate quite differently from—the ways people use\ntheir nervous systems and bodies to sense, learn, reason, and take action. While the\nrate of progress in AI has been patchy and unpredictable, there have been significant\nadvances since the field’s inception sixty years ago. Once a mostly academic area of\nstudy, twenty-first century AI enables a constellation of mainstream technologies that\nSubstantial increases are having a substantial impact on everyday lives. Computer vision and AI planning,\nfor example, drive the video games that are now a bigger entertainment industry than\nin the future uses of AI\nHollywood.",
    "page": 4
  },
  {
    "type": "text",
    "content": "he video games that are now a bigger entertainment industry than\nin the future uses of AI\nHollywood. Deep learning, a form of machine learning based on layered representations\nof variables referred to as neural networks, has made speech-understanding practical\napplications, including\non our phones and in our kitchens, and its algorithms can be applied widely to an\nmore self-driving cars, array of applications that rely on pattern recognition. Natural Language Processing\n(NLP) and knowledge representation and reasoning have enabled a machine to beat\nhealthcare diagnostics\nthe Jeopardy champion and are bringing new power to Web searches.\nWhile impressive, these technologies are highly tailored to particular tasks. Each\nand targeted treatment,",
    "page": 4
  },
  {
    "type": "text",
    "content": "mpressive, these technologies are highly tailored to particular tasks. Each\nand targeted treatment,\napplication typically requires years of specialized research and careful, unique\nand physical assistance construction. In similarly targeted applications, substantial increases in the future\nuses of AI technologies, including more self-driving cars, healthcare diagnostics\nfor elder care can be and targeted treatments, and physical assistance for elder care can be expected. AI\nand robotics will also be applied across the globe in industries struggling to attract\nexpected.\nyounger workers, such as agriculture, food processing, fulfillment centers, and\nfactories. They will facilitate delivery of online purchases through flying drones,",
    "page": 4
  },
  {
    "type": "text",
    "content": "nt centers, and\nfactories. They will facilitate delivery of online purchases through flying drones,\nself-driving trucks, or robots that can get up the stairs to the front door.\nThis report is the first in a series to be issued at regular intervals as a part of the\nOne Hundred Year Study on Artificial Intelligence (AI100). Starting from a charge\ngiven by the AI100 Standing Committee to consider the likely influences of AI in a\ntypical North American city by the year 2030, the 2015 Study Panel, comprising experts\nin AI and other relevant areas focused their attention on eight domains they considered\nmost salient: transportation; service robots; healthcare; education; low-resource\ncommunities; public safety and security; employment and workplace; and entertainment.",
    "page": 4
  },
  {
    "type": "text",
    "content": "low-resource\ncommunities; public safety and security; employment and workplace; and entertainment.\nIn each of these domains, the report both reflects on progress in the past fifteen years\nand anticipates developments in the coming fifteen years. Though drawing from a\ncommon source of research, each domain reflects different AI influences and challenges,\nsuch as the difficulty of creating safe and reliable hardware (transportation and service\nrobots), the difficulty of smoothly interacting with human experts (healthcare and\neducation), the challenge of gaining public trust (low-resource communities and public\nsafety and security), the challenge of overcoming fears of marginalizing humans\n(employment and workplace), and the social and societal risk of diminishing interpersonal",
    "page": 4
  },
  {
    "type": "text",
    "content": "ng humans\n(employment and workplace), and the social and societal risk of diminishing interpersonal\ninteractions (entertainment). The report begins with a reflection on what constitutes\nArtificial Intelligence, and concludes with recommendations concerning AI-related\npolicy. These recommendations include accruing technical expertise about AI in\ngovernment and devoting more resources—and removing impediments—to research\non the fairness, security, privacy, and societal impacts of AI systems.\nContrary to the more fantastic predictions for AI in the popular press, the Study\nPanel found no cause for concern that AI is an imminent threat to humankind.\nNo machines with self-sustaining long-term goals and intent have been developed,\nnor are they likely to be developed in the near future.",
    "page": 4
  },
  {
    "type": "text",
    "content": "g-term goals and intent have been developed,\nnor are they likely to be developed in the near future. Instead, increasingly useful\napplications of AI, with potentially profound positive impacts on our society and\neconomy are likely to emerge between now and 2030, the period this report\n4 considers. At the same time, many of these developments will spur disruptions in",
    "page": 4
  },
  {
    "type": "text",
    "content": "how human labor is augmented or replaced by AI, creating new challenges for the\neconomy and society more broadly. Application design and policy decisions made in\nthe near term are likely to have long-lasting influences on the nature and directions\nof such developments, making it important for AI researchers, developers, social\nscientists, and policymakers to balance the imperative to innovate with mechanisms\nto ensure that AI’s economic and social benefits are broadly shared across society. If\nsociety approaches these technologies primarily with fear and suspicion, missteps that\nslow AI’s development or drive it underground will result, impeding important work\nWhile drawing on common\non ensuring the safety and reliability of AI technologies. On the other hand, if society",
    "page": 5
  },
  {
    "type": "text",
    "content": "on common\non ensuring the safety and reliability of AI technologies. On the other hand, if society\napproaches AI with a more open mind, the technologies emerging from the field\nresearch and technologies,\ncould profoundly transform society for the better in the coming decades.\nAI systems are specialized\nStudy Panel: Peter Stone, Chair, University of Texas at Austin, Rodney Brooks,\nRethink Robotics, Erik Brynjolfsson, Massachussets Institute of Technology, Ryan to accomplish particular\nCalo, University of Washington, Oren Etzioni, Allen Institute for AI, Greg Hager, Johns\ntasks. Each application\nHopkins University, Julia Hirschberg, Columbia University, Shivaram Kalyanakrishnan,\nIndian Institute of Technology Bombay, Ece Kamar, Microsoft Research, Sarit Kraus,\nrequires years of focused",
    "page": 5
  },
  {
    "type": "text",
    "content": "stitute of Technology Bombay, Ece Kamar, Microsoft Research, Sarit Kraus,\nrequires years of focused\nBar Ilan University. Kevin Leyton-Brown, University of British Columbia, David Parkes,\nHarvard University, William Press, University of Texas at Austin, AnnaLee (Anno) research and a careful,\nSaxenian, University of California, Berkeley, Julie Shah, Massachussets Institute of\nunique construction.\nTechnology, Milind Tambe, University of Southern California, Astro Teller, X\nStanding Committee of the One Hundred Year Study of Artificial Intelligence:\nBarbara J. Grosz, Chair, Russ Altman, Eric Horvitz, Alan Mackworth, Tom Mitchell,\nDeidre Mulligan, Yoav Shoham\n5",
    "page": 5
  },
  {
    "type": "text",
    "content": "OVERVIEW\nThe frightening, futurist portrayals of Artificial Intelligence that dominate films and\nnovels, and shape the popular imagination, are fictional. In reality, AI is already\nchanging our daily lives, almost entirely in ways that improve human health, safety,\nand productivity. Unlike in the movies, there is no race of superhuman robots on the\nhorizon or probably even possible. And while the potential to abuse AI technologies\nmust be acknowledged and addressed, their greater potential is, among other things,\nMany have already grown to make driving safer, help children learn, and extend and enhance people’s lives. In\nfact, beneficial AI applications in schools, homes, and hospitals are already growing\naccustomed to touching\nat an accelerated pace.",
    "page": 6
  },
  {
    "type": "text",
    "content": "in schools, homes, and hospitals are already growing\naccustomed to touching\nat an accelerated pace. Major research universities devote departments to AI studies,\nand technology companies such as Apple, Facebook, Google, IBM, and Microsoft\nand talking to their\nspend heavily to explore AI applications they regard as critical to their futures. Even\nsmart phones. People’s Hollywood uses AI technologies to bring its dystopian AI fantasies to the screen.\nInnovations relying on computer-based vision, speech recognition, and Natural\nfuture relationships with\nLanguage Processing have driven these changes, as have concurrent scientific and\ntechnological advances in related fields. AI is also changing how people interact with\nmachines will become ever\ntechnology.",
    "page": 6
  },
  {
    "type": "text",
    "content": "n related fields. AI is also changing how people interact with\nmachines will become ever\ntechnology. Many people have already grown accustomed to touching and talking to\nmore nuanced, fluid, and their smart phones. People’s future relationships with machines will become ever more\nnuanced, fluid, and personalized as AI systems learn to adapt to individual personalities\npersonalized. and goals. These AI applications will help monitor people’s well-being, alert them to\nrisks ahead, and deliver services when needed or wanted. For example, in a mere\nfifteen years in a typical North American city—the time frame and scope of this report—\nAI applications are likely to transform transportation toward self-driving vehicles with\non-time pickup and delivery of people and packages.",
    "page": 6
  },
  {
    "type": "text",
    "content": "transportation toward self-driving vehicles with\non-time pickup and delivery of people and packages. This alone will reconfigure the\nurban landscape, as traffic jams and parking challenges become obsolete.\nThis study’s focus on a typical North American city is deliberate and meant to\nhighlight specific changes affecting the everyday lives of the millions of people who\ninhabit them. The Study Panel further narrowed its inquiry to eight domains where\nAI is already having or is projected to have the greatest impact: transportation,\nhealthcare, education, low-resource communities, public safety and security,\nemployment and workplace, home/service robots, and entertainment.\nThough drawing from a common source of research, AI technologies have",
    "page": 6
  },
  {
    "type": "text",
    "content": "ce robots, and entertainment.\nThough drawing from a common source of research, AI technologies have\ninfluenced and will continue to influence these domains differently. Each domain\nfaces varied AI-related challenges, including the difficulty of creating safe and reliable\nhardware for sensing and effecting (transportation and service robots), the difficulty\nof smoothly interacting with human experts (healthcare and education), the challenge\nof gaining public trust (low-resource communities and public safety and security), the\nchallenge of overcoming fears of marginalizing humans (employment and workplace)\nand the risk of diminishing interpersonal interaction (entertainment). Some domains\nare primarily business sectors, such as transportation and healthcare, while others are",
    "page": 6
  },
  {
    "type": "text",
    "content": "ome domains\nare primarily business sectors, such as transportation and healthcare, while others are\nmore oriented to consumers, such as entertainment and home service robots. Some\ncut across sectors, such as employment/workplace and low-resource communities.\nIn each domain, even as AI continues to deliver important benefits, it also raises\nimportant ethical and social issues, including privacy concerns. Robots and other AI\ntechnologies have already begun to displace jobs in some sectors. As a society, we are now\nat a crucial juncture in determining how to deploy AI-based technologies in ways that\npromote, not hinder, democratic values such as freedom, equality, and transparency. For\nindividuals, the quality of the lives we lead and how our contributions are valued are",
    "page": 6
  },
  {
    "type": "text",
    "content": "parency. For\nindividuals, the quality of the lives we lead and how our contributions are valued are\nlikely to shift gradually, but markedly. Over the next several years, AI research, systems\ndevelopment, and social and regulatory frameworks will shape how the benefits of AI\n6 are weighed against its costs and risks, and how broadly these benefits are spread.",
    "page": 6
  },
  {
    "type": "text",
    "content": "An accurate and sophisticated picture of AI—one that competes with its popular\nportrayal—is hampered at the start by the difficulty of pinning down a precise\ndefinition of artificial intelligence. In the approaches the Study Panel considered,\nnone suggest there is currently a “general purpose” AI. While drawing on common\nresearch and technologies, AI systems are specialized to accomplish particular\ntasks, and each application requires years of focused research and a careful, unique\nconstruction. As a result, progress is uneven within and among the eight domains.\nA prime example is Transportation, where a few key technologies have catalyzed\nSociety is now at a crucial\nthe widespread adoption of AI with astonishing speed. Autonomous transportation",
    "page": 7
  },
  {
    "type": "text",
    "content": "is now at a crucial\nthe widespread adoption of AI with astonishing speed. Autonomous transportation\nwill soon be commonplace and, as most people’s first experience with physically\njuncture in determining\nembodied AI systems, will strongly influence the public’s perception of AI. As cars\nbecome better drivers than people, city-dwellers will own fewer cars, live further from how to deploy AI-based\nwork, and spend time differently, leading to an entirely new urban organization. In\nthe typical North American city in 2030, physically embodied AI applications will technologies in ways that\nnot be limited to cars, but are likely to include trucks, flying vehicles, and personal\npromote rather than hinder\nrobots. Improvements in safe and reliable hardware will spur innovation over the next",
    "page": 7
  },
  {
    "type": "text",
    "content": "r than hinder\nrobots. Improvements in safe and reliable hardware will spur innovation over the next\nfifteen years, as they will with Home/Service Robots, which have already entered\ndemocratic values such\npeople’s houses, primarily in the form of vacuum cleaners. Better chips, low-cost 3D\nsensors, cloud-based machine learning, and advances in speech understanding will as freedom, equality, and\nenhance future robots’ services and their interactions with people. Special purpose\ntransparency.\nrobots will deliver packages, clean offices, and enhance security. But technical\nconstraints and the high costs of reliable mechanical devices will continue to limit\ncommercial opportunities to narrowly defined applications for the foreseeable future.",
    "page": 7
  },
  {
    "type": "text",
    "content": "inue to limit\ncommercial opportunities to narrowly defined applications for the foreseeable future.\nIn Healthcare, there has been an immense forward leap in collecting useful data\nfrom personal monitoring devices and mobile apps, from electronic health records (EHR)\nin clinical settings and, to a lesser extent, from surgical robots designed to assist with\nmedical procedures and service robots supporting hospital operations. AI-based\napplications could improve health outcomes and the quality of life for millions of\npeople in the coming years. Though clinical applications have been slow to move from\nthe computer science lab to the real-world, there are hopeful signs that the pace of\ninnovation will improve. Advances in healthcare can be promoted via the development",
    "page": 7
  },
  {
    "type": "text",
    "content": "hat the pace of\ninnovation will improve. Advances in healthcare can be promoted via the development\nof incentives and mechanisms for sharing data and for removing overbearing policy,\nregulatory, and commercial obstacles. For many applications, AI systems will have to work\nclosely with care providers and patients to gain their trust. Advances in how intelligent\nmachines interact naturally with caregivers, patients, and patients’ families are crucial.\nEnabling more fluid interactions between people and promising AI technologies\nalso remains a critical challenge in Education, which has seen considerable progress\nin the same period. Though quality education will always require active engagement\nby human teachers, AI promises to enhance education at all levels, especially by",
    "page": 7
  },
  {
    "type": "text",
    "content": "active engagement\nby human teachers, AI promises to enhance education at all levels, especially by\nproviding personalization at scale. Interactive machine tutors are now being matched\nto students for teaching science, math, language, and other disciplines. Natural\nLanguage Processing, machine learning, and crowdsourcing have boosted online\nlearning and enabled teachers in higher education to multiply the size of their\nclassrooms while addressing individual students’ learning needs and styles. Over the\nnext fifteen years in a typical North American city, the use of these technologies in\nthe classroom and in the home is likely to expand significantly, provided they can be\nmeaningfully integrated with face-to-face learning.\nBeyond education, many opportunities exist for AI methods to assist",
    "page": 7
  },
  {
    "type": "text",
    "content": "ted with face-to-face learning.\nBeyond education, many opportunities exist for AI methods to assist\nLow-resource Communities by providing mitigations and solutions to a\nvariety of social problems. Traditionally, funders have underinvested in AI research\nlacking commercial application. With targeted incentives and funding priorities,\n7",
    "page": 7
  },
  {
    "type": "text",
    "content": "AI technologies could help address the needs of low-resource communities, and\nbudding efforts are promising. Using data mining and machine learning, for example,\nAI has been used to create predictive models to help government agencies address\nissues such as prevention of lead poisoning in at-risk children and distribution of\nfood efficiently. These budding efforts suggest more could be done, particularly if\nagencies and organizations can engage and build trust with these communities.\nGaining public trust is also a challenge for AI use by Public Safety and Security\nprofessionals. North American cities and federal agencies have already begun to\nLonger term, AI may be\ndeploy AI technologies in border administration and law enforcement. By 2030,",
    "page": 8
  },
  {
    "type": "text",
    "content": "onger term, AI may be\ndeploy AI technologies in border administration and law enforcement. By 2030,\nthey will rely heavily upon them, including improved cameras and drones for\nthought of as a radically\nsurveillance, algorithms to detect financial fraud, and predictive policing. The latter\ndifferent mechanism raises the specter of innocent people being unjustifiably monitored, and care must be\ntaken to avoid systematizing human bias and to protect civil liberties. Well-deployed\nfor wealth creation in AI prediction tools have the potential to provide new kinds of transparency about\ndata and inferences, and may be applied to detect, remove, or reduce human bias,\nwhich everyone should\nrather than reinforcing it.\nSocial and political decisions are likewise at play in AI’s influences on",
    "page": 8
  },
  {
    "type": "text",
    "content": "ther than reinforcing it.\nSocial and political decisions are likewise at play in AI’s influences on\nbe entitled to a portion of\nEmployment and Workplace trends, such as the safety nets needed to protect\nthe world’s AI-produced people from structural changes in the economy. AI is poised to replace people in\ncertain kinds of jobs, such as in the driving of taxis and trucks. However, in many\ntreasures.\nrealms, AI will likely replace tasks rather than jobs in the near term, and will also\ncreate new kinds of jobs. But the new jobs that will emerge are harder to imagine in\nadvance than the existing jobs that will likely be lost. AI will also lower the cost of\nmany goods and services, effectively making everyone better off. Longer term, AI may",
    "page": 8
  },
  {
    "type": "text",
    "content": "er the cost of\nmany goods and services, effectively making everyone better off. Longer term, AI may\nbe thought of as a radically different mechanism for wealth creation in which everyone\nshould be entitled to a portion of the world’s AI-produced treasures. It is not too soon\nfor social debate on how the economic fruits of AI technologies should be shared.\nEntertainment has been transformed by social networks and other platforms for\nsharing and browsing blogs, videos, and photos, which rely on techniques actively\ndeveloped in NLP, information retrieval, image processing, crowdsourcing, and machine\nlearning. Some traditional sources of entertainment have also embraced AI to compose\nmusic, create stage performances, and even to generate 3D scenes from natural\nlanguage text.",
    "page": 8
  },
  {
    "type": "text",
    "content": "compose\nmusic, create stage performances, and even to generate 3D scenes from natural\nlanguage text. The enthusiasm with which people have already responded to AI-driven\nentertainment has been surprising. As with many aspects of AI, there is ongoing debate\nabout the extent to which the technology replaces or enhances sociability. AI will\nincreasingly enable entertainment that is more interactive, personalized, and engaging.\nResearch should be directed toward understanding how to leverage these attributes\nfor individuals’ and society’s benefit.\nWhat’s next for AI research?\nThe research that fuels the AI revolution has also seen rapid changes. Foremost\namong them is the maturation of machine learning, stimulated in part by the rise of",
    "page": 8
  },
  {
    "type": "text",
    "content": "anges. Foremost\namong them is the maturation of machine learning, stimulated in part by the rise of\nthe digital economy, which both provides and leverages large amounts of data. Other\nfactors include the rise of cloud computing resources and consumer demand for\nwidespread access to services such as speech recognition and navigation support.\nMachine learning has been propelled dramatically forward by impressive\nempirical successes of artificial neural networks, which can now be trained with huge\ndata sets and large-scale computing. This approach has been come to be known as\n“deep learning.” The leap in the performance of information processing algorithms\nhas been accompanied by significant progress in hardware technology for basic",
    "page": 8
  },
  {
    "type": "text",
    "content": "processing algorithms\nhas been accompanied by significant progress in hardware technology for basic\noperations such as sensing, perception, and object recognition. New platforms and\n8",
    "page": 8
  },
  {
    "type": "text",
    "content": "markets for data-driven products, and the economic incentives to find new products\nand markets, have also stimulated research advances. Now, as it becomes a central\nforce in society, the field of AI is shifting toward building intelligent systems that\ncan collaborate effectively with people, and that are more generally human-aware,\nincluding creative ways to develop interactive and scalable ways for people to\nteach robots. These trends drive the currently “hot” areas of AI research into both\nfundamental methods and application areas:\nLarge-scale machine learning concerns the design of learning algorithms, as\nThe field of AI is shifting\nwell as scaling existing algorithms, to work with extremely large data sets.",
    "page": 9
  },
  {
    "type": "text",
    "content": "ield of AI is shifting\nwell as scaling existing algorithms, to work with extremely large data sets.\nDeep learning, a class of learning procedures, has facilitated object recognition toward building intelligent\nin images, video labeling, and activity recognition, and is making significant inroads into\nsystems that can\nother areas of perception, such as audio, speech, and natural language processing.\nReinforcement learning is a framework that shifts the focus of machine\ncollaborate effectively with\nlearning from pattern recognition to experience-driven sequential decision-making.\nIt promises to carry AI applications forward toward taking actions in the real world. people, including creative\nWhile largely confined to academia over the past several decades, it is now seeing",
    "page": 9
  },
  {
    "type": "text",
    "content": "cluding creative\nWhile largely confined to academia over the past several decades, it is now seeing\nways to develop interactive\nsome practical, real-world successes.\nRobotics is currently concerned with how to train a robot to interact with the and scalable ways for\nworld around it in generalizable and predictable ways, how to facilitate manipulation\npeople to teach robots.\nof objects in interactive environments, and how to interact with people. Advances in\nrobotics will rely on commensurate advances to improve the reliability and generality\nof computer vision and other forms of machine perception.\nComputer vision is currently the most prominent form of machine perception.\nIt has been the sub-area of AI most transformed by the rise of deep learning. For the",
    "page": 9
  },
  {
    "type": "text",
    "content": "e perception.\nIt has been the sub-area of AI most transformed by the rise of deep learning. For the\nfirst time, computers are able to perform some vision tasks better than people. Much\ncurrent research is focused on automatic image and video captioning.\nNatural Language Processing, often coupled with automatic speech recognition,\nis quickly becoming a commodity for widely spoken languages with large data sets.\nResearch is now shifting to develop refined and capable systems that are able to\ninteract with people through dialog, not just react to stylized requests. Great strides\nhave also been made in machine translation among different languages, with more\nreal-time person-to-person exchanges on the near horizon.",
    "page": 9
  },
  {
    "type": "text",
    "content": "tion among different languages, with more\nreal-time person-to-person exchanges on the near horizon.\nCollaborative systems research investigates models and algorithms to help develop\nautonomous systems that can work collaboratively with other systems and with humans.\nCrowdsourcing and human computation research investigates methods to\naugment computer systems by making automated calls to human expertise to solve\nproblems that computers alone cannot solve well.\nAlgorithmic game theory and computational social choice draw attention\nto the economic and social computing dimensions of AI, such as how systems can\nhandle potentially misaligned incentives, including self-interested human participants\nor firms and the automated AI-based agents representing them.",
    "page": 9
  },
  {
    "type": "text",
    "content": "ng self-interested human participants\nor firms and the automated AI-based agents representing them.\nInternet of Things (IoT) research is devoted to the idea that a wide array of\ndevices, including appliances, vehicles, buildings, and cameras, can be interconnected to\ncollect and share their abundant sensory information to use for intelligent purposes.\nNeuromorphic computing is a set of technologies that seek to mimic\nbiological neural networks to improve the hardware efficiency and robustness of\ncomputing systems, often replacing an older emphasis on separate modules for input/\noutput, instruction-processing, and memory.\n9",
    "page": 9
  },
  {
    "type": "text",
    "content": "AI policy, now and in the future\nThe measure of success for AI applications is the value they create for human lives.\nIn that light, they should be designed to enable people to understand AI systems\nsuccessfully, participate in their use, and build their trust. Public policies should help\nease society’s adaptation to AI applications, extend their benefits, and mitigate their\ninevitable errors and failures. Debate about how AI is deployed, including concerns\nabout how privacy is protected and AI’s benefits fairly shared, should be encouraged.\nGiven the speed with which AI technologies are being realized, and concomitant\nMisunderstandings\nconcerns about their implications, the Study Panel recommends that all layers of\ngovernment acquire technical expertise in AI.",
    "page": 10
  },
  {
    "type": "text",
    "content": "cations, the Study Panel recommends that all layers of\ngovernment acquire technical expertise in AI. Further, research on the fairness,\nabout what AI is and is\nsecurity, privacy, and societal implications of AI systems should be encouraged by\nnot could fuel opposition removing impediments and increasing private and public spending to support it.\nCurrently in the United States, at least sixteen separate agencies govern sectors\nto technologies with\nof the economy related to AI technologies. Rapid advances in AI research and,\nespecially, its applications require experts in these sectors to develop new concepts\nthe potential to benefit\nand metaphors for law and policy. Who is responsible when a self-driven car crashes\neveryone.",
    "page": 10
  },
  {
    "type": "text",
    "content": "enefit\nand metaphors for law and policy. Who is responsible when a self-driven car crashes\neveryone. Poorly informed or an intelligent medical device fails? How can AI applications be prevented from\npromulgating racial discrimination or financial cheating? Who should reap the gains\nregulation that stifles of efficiencies enabled by AI technologies and what protections should be afforded\nto people whose skills are rendered obsolete? As people integrate AI more broadly\ninnovation would be a\nand deeply into industrial processes and consumer products, best practices need to be\nspread, and regulatory regimes adapted.\ntragic mistake.\nWhile the Study Panel does not consider it likely that near-term AI systems will",
    "page": 10
  },
  {
    "type": "text",
    "content": "d.\ntragic mistake.\nWhile the Study Panel does not consider it likely that near-term AI systems will\nautonomously choose to inflict harm on people, it will be possible for people to use\nAI-based systems for harmful as well as helpful purposes. And though AI algorithms\nmay be capable of making less biased decisions than a typical person, it remains\na deep technical challenge to ensure that the data that inform AI-based decisions\ncan be kept free from biases that could lead to discrimination based on race, sexual\norientation, or other factors.\nFaced with the profound changes that AI technologies can produce, pressure for\n“more” and “tougher” regulation is probably inevitable. Misunderstandings about\nwhat AI is and is not could fuel opposition to technologies with the potential to",
    "page": 10
  },
  {
    "type": "text",
    "content": "erstandings about\nwhat AI is and is not could fuel opposition to technologies with the potential to\nbenefit everyone. Inappropriate regulatory activity would be a tragic mistake. Poorly\ninformed regulation that stifles innovation, or relocates it to other jurisdictions, would\nbe counterproductive.2\nFortunately, principles that guide successful regulation of current digital technologies\nprovide a starting point. In privacy regulation, broad legal mandates coupled with\ntough transparency requirements and meaningful enforcement—rather than strict\ncontrols—encourage companies to develop processes and professional staff to\nenforce privacy controls, engage with outside stakeholders, and adapt their practices\nto technological advances. This in turn supports the development of professional",
    "page": 10
  },
  {
    "type": "text",
    "content": "pt their practices\nto technological advances. This in turn supports the development of professional\ntrade associations and standards committees that spread best practices. In AI, too,\nregulators can strengthen a virtuous cycle of activity involving internal and external\naccountability, transparency, and professionalization, rather than narrow compliance.\nA vigorous and informed debate about how to best steer AI in ways that enrich\nour lives and our society, while encouraging creativity in the field, is an urgent and\nvital need. AI technologies could widen existing inequalities of opportunity if access\nto them—along with the high-powered computation and large-scale data that fuel\nmany of them—is unfairly distributed across society. These technologies will improve",
    "page": 10
  },
  {
    "type": "text",
    "content": "data that fuel\nmany of them—is unfairly distributed across society. These technologies will improve\n2 Kate Crawford, “Artificial Intelligence’s White Guy Problem,” The New York Times, June 25,\n2016, accessed August 1, 2016, http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-\n10 intelligences-white-guy-problem.html.",
    "page": 10
  },
  {
    "type": "text",
    "content": "the abilities and efficiency of people who have access to them. Policies should be\nevaluated as to whether they foster democratic values and equitable sharing of AI’s\nbenefits, or concentrate power and benefits in the hands of a fortunate few.\nAs this report documents, significant AI-related advances have already had\nan impact on North American cities over the past fifteen years, and even more\nsubstantial developments will occur over the next fifteen. Recent advances are largely\ndue to the growth and analysis of large data sets enabled by the internet, advances\nin sensory technologies and, more recently, applications of “deep learning.” In the\ncoming years, as the public encounters new AI applications in domains such as",
    "page": 11
  },
  {
    "type": "text",
    "content": "eep learning.” In the\ncoming years, as the public encounters new AI applications in domains such as\ntransportation and healthcare, they must be introduced in ways that build trust and\nunderstanding, and respect human and civil rights. While encouraging innovation,\npolicies and processes should address ethical, privacy, and security implications, and\nshould work to ensure that the benefits of AI technologies will be spread broadly and\nfairly. Doing so will be critical if Artificial Intelligence research and its applications\nare to exert a positive influence on North American urban life in 2030 and beyond.\n11",
    "page": 11
  },
  {
    "type": "text",
    "content": "SECTION I: WHAT IS ARTIFICIAL\nINTELLIGENCE?\nThis section describes how researchers and practitioners define “Artificial Intelligence,” and\nthe areas of AI research and application that are currently thriving. It proffers definitions of\nwhat AI is and is not, and describes some of the currently “hot” areas of AI Research. This\nsection lays the groundwork for Section II, which elaborates on AI’s impacts and future in\neight domains and Section III, which describes issues related to AI design and public policy\nAn accurate and\nand makes recommendations for encouraging AI innovation while protecting democratic values.\nsophisticated picture of\nDEFINING AI\nAI—one that competes with\nCuriously, the lack of a precise, universally accepted definition of AI probably\nits popular portrayal—is",
    "page": 12
  },
  {
    "type": "text",
    "content": "sly, the lack of a precise, universally accepted definition of AI probably\nits popular portrayal—is\nhas helped the field to grow, blossom, and advance at an ever-accelerating pace.\nPractitioners, researchers, and developers of AI are instead guided by a rough\nhampered by the difficulty\nsense of direction and an imperative to “get on with it.” Still, a definition remains\nof pinning down a precise important and Nils J. Nilsson has provided a useful one:\n“Artificial intelligence is that activity devoted to making machines intelligent, and\ndefinition of artificial intelligence is that quality that enables an entity to function appropriately and with\nforesight in its environment.”3\nintelligence.\nFrom this perspective, characterizing AI depends on the credit one is willing to",
    "page": 12
  },
  {
    "type": "text",
    "content": "t.”3\nintelligence.\nFrom this perspective, characterizing AI depends on the credit one is willing to\ngive synthesized software and hardware for functioning “appropriately” and with\n“foresight.” A simple electronic calculator performs calculations much faster than\nthe human brain, and almost never makes a mistake.4 Is a calculator intelligent?\nLike Nilsson, the Study Panel takes a broad view that intelligence lies on a multi-\ndimensional spectrum. According to this view, the difference between an arithmetic\ncalculator and a human brain is not one of kind, but of scale, speed, degree of\nautonomy, and generality. The same factors can be used to evaluate every other\ninstance of intelligence—speech recognition software, animal brains, cruise-control",
    "page": 12
  },
  {
    "type": "text",
    "content": "ate every other\ninstance of intelligence—speech recognition software, animal brains, cruise-control\nsystems in cars, Go-playing programs, thermostats—and to place them at some\nappropriate location in the spectrum.\nAlthough our broad interpretation places the calculator within the intelligence\nspectrum, such simple devices bear little resemblance to today’s AI. The frontier of\nAI has moved far ahead and functions of the calculator are only one among the\nmillions that today’s smartphones can perform. AI developers now work on improving,\ngeneralizing, and scaling up the intelligence currently found on smartphones.\nIn fact, the field of AI is a continual endeavor to push forward the frontier of\nmachine intelligence. Ironically, AI suffers the perennial fate of losing claim to its",
    "page": 12
  },
  {
    "type": "text",
    "content": "frontier of\nmachine intelligence. Ironically, AI suffers the perennial fate of losing claim to its\nacquisitions, which eventually and inevitably get pulled inside the frontier, a repeating\npattern known as the “AI effect” or the “odd paradox”—AI brings a new technology\ninto the common fold, people become accustomed to this technology, it stops being\nconsidered AI, and newer technology emerges.5 The same pattern will continue in the\nfuture. AI does not “deliver” a life-changing product as a bolt from the blue. Rather,\nAI technologies continue to get better in a continual, incremental way.\n3 Nils J. Nilsson, The Quest for Artificial Intelligence: A History of Ideas and Achievements (Cambridge,\nUK: Cambridge University Press, 2010).",
    "page": 12
  },
  {
    "type": "text",
    "content": "ntelligence: A History of Ideas and Achievements (Cambridge,\nUK: Cambridge University Press, 2010).\n4 Wikimedia Images, accessed August 1, 2016, https://upload.wikimedia.org/wikipedia/\ncommons/b/b6/SHARP_ELSIMATE_EL-W221.jpg.\n5 Pamela McCorduck, Machines Who Think: A Personal Inquiry into the History and Prospects of\nArtificial Intelligence, 2nd ed. (Natick, MA: A. K. Peters, Ltd., 2004; San Francisco: W. H. Freeman,\n12 1979), Citations are to the Peters edition.",
    "page": 12
  },
  {
    "type": "text",
    "content": "The human measure\nNotably, the characterization of intelligence as a spectrum grants no special status\nto the human brain. But to date human intelligence has no match in the biological\nand artificial worlds for sheer versatility, with the abilities “to reason, achieve\ngoals, understand and generate language, perceive and respond to sensory inputs,\nprove mathematical theorems, play challenging games, synthesize and summarize\ninformation, create art and music, and even write histories.”6\nThis makes human intelligence a natural choice for benchmarking the progress\nIntelligence lies on a\nof AI. It may even be proposed, as a rule of thumb, that any activity computers\nare able to perform and people once performed should be counted as an instance\nmulti-dimensional\nof intelligence.",
    "page": 13
  },
  {
    "type": "text",
    "content": "erform and people once performed should be counted as an instance\nmulti-dimensional\nof intelligence. But matching any human ability is only a sufficient condition, not a\nnecessary one. There are already many systems that exceed human intelligence, at spectrum. According to\nleast in speed, such as scheduling the daily arrivals and departures of thousands of\nthis view, the difference\nflights in an airport.\nAI’s long quest—and eventual success—to beat human players at the game of\nbetween an arithmetic\nchess offered a high-profile instance for comparing human to machine intelligence.\nChess has fascinated people for centuries. When the possibility of building computers calculator and a human\nbecame imminent, Alan Turing, who many consider the father of computer science,",
    "page": 13
  },
  {
    "type": "text",
    "content": "culator and a human\nbecame imminent, Alan Turing, who many consider the father of computer science,\n“mentioned the idea of computers showing intelligence with chess as a paradigm.”7 brain is not one of kind,\nWithout access to powerful computers, “Turing played a game in which he simulated\nbut of scale, speed,\nthe computer, taking about half an hour per move.”\nBut it was only after a long line of improvements in the sixties and seventies—\ndegree of autonomy, and\ncontributed by groups at Carnegie Mellon, Stanford, MIT, The Institute for\nTheoretical and Experimental Physics at Moscow, and Northwestern University— generality.\nthat chess-playing programs started gaining proficiency. The final push came\nthrough a long-running project at IBM, which culminated with the Deep Blue",
    "page": 13
  },
  {
    "type": "text",
    "content": "ncy. The final push came\nthrough a long-running project at IBM, which culminated with the Deep Blue\nprogram beating Garry Kasparov, then the world chess champion, by a score of\n3.5-2.5 in 1997. Curiously, no sooner had AI caught up with its elusive target than\nDeep Blue was portrayed as a collection of “brute force methods” that wasn’t “real\nintelligence.”8 In fact, IBM’s subsequent publication about Deep Blue, which gives\nextensive details about its search and evaluation procedures, doesn’t mention the\nword “intelligent” even once!9 Was Deep Blue intelligent or not? Once again, the\nfrontier had moved.\nAn operational definition\nAI can also be defined by what AI researchers do. This report views AI\nprimarily as a branch of computer science that studies the properties of",
    "page": 13
  },
  {
    "type": "text",
    "content": "s do. This report views AI\nprimarily as a branch of computer science that studies the properties of\nintelligence by synthesizing intelligence.10 Though the advent of AI has depended\non the rapid progress of hardware computing resources, the focus here on\nsoftware reflects a trend in the AI community. More recently, though, progress in\nbuilding hardware tailored for neural-network-based computing11 has created a\n6 Nilsson, The Quest for Artificial Intelligence.\n7 Nilsson, The Quest for Artificial Intelligence, 89.\n8 McCorduck, Machines Who Think, 433.\n9 Murray Campbell, A. Joseph Hoane Jr., and Feng-hsiung Hsu, “Deep Blue,” Artificial\nIntelligence 134, nos. 1 and 2 (2002): 57–83.\n10 Herbert A. Simon, “Artificial Intelligence: An Empirical Science,” Artificial Intelligence 77, no. 2",
    "page": 13
  },
  {
    "type": "text",
    "content": "erbert A. Simon, “Artificial Intelligence: An Empirical Science,” Artificial Intelligence 77, no. 2\n(1995):95–127.\n11 Paul Merolla John V. Arthur, Rodrigo Alvarez-Icaza, Andrew S. Cassidy, Jun Sawada, Filipp\nAkopyan, Bryan L. Jackson, Nabil Imam, Chen Guo, Yutaka Nakamura, Bernard Brezzo, Ivan Vo,\nSteven K. Esser, Rathinakumar Appuswamy, Brian Taba, Arnon Amir, Myron D. Flickner, William\nP. Risk, Rajit Manohar, and Dharmendra S. Modha, “A Million Spiking-Neuron Integrated\nCircuit with a Scalable Communication Network and Interface,” accessed August 1, 2016, http://\npaulmerolla.com/merolla_main_som.pdf. 13",
    "page": 13
  },
  {
    "type": "text",
    "content": "tighter coupling between hardware and software in advancing AI.\n“Intelligence” remains a complex phenomenon whose varied aspects have attracted\nthe attention of several different fields of study, including psychology, economics,\nneuroscience, biology, engineering, statistics, and linguistics. Naturally, the field of AI has\nbenefited from the progress made by all of these allied fields. For example, the artificial\nneural network, which has been at the heart of several AI-based solutions12 13 was\noriginally inspired by thoughts about the flow of information in biological neurons.14\nHuman intelligence has AI RESEARCH TRENDS\nUntil the turn of the millennium, AI’s appeal lay largely in its promise to deliver, but\nno match in the biological",
    "page": 14
  },
  {
    "type": "text",
    "content": "f the millennium, AI’s appeal lay largely in its promise to deliver, but\nno match in the biological\nin the last fifteen years, much of that promise has been redeemed.15 AI technologies\nand artificial worlds for already pervade our lives. As they becomes a central force in society, the field is\nshifting from simply building systems that are intelligent to building intelligent systems\nsheer versatility, with\nthat are human-aware and trustworthy.\nSeveral factors have fueled the AI revolution. Foremost among them is the\nthe abilities “to reason,\nmaturing of machine learning, supported in part by cloud computing resources\nachieve goals, understand and wide-spread, web-based data gathering. Machine learning has been propelled",
    "page": 14
  },
  {
    "type": "text",
    "content": "ve goals, understand and wide-spread, web-based data gathering. Machine learning has been propelled\ndramatically forward by “deep learning,” a form of adaptive artificial neural\nand generate language... networks trained using a method called backpropagation.16 This leap in the\nperformance of information processing algorithms has been accompanied by\ncreate art and music, and\nsignificant progress in hardware technology for basic operations such as sensing,\nperception, and object recognition. New platforms and markets for data-driven\neven write histories.”\nproducts, and the economic incentives to find new products and markets, have also\ncontributed to the advent of AI-driven technology.\nAll these trends drive the “hot” areas of research described below. This compilation",
    "page": 14
  },
  {
    "type": "text",
    "content": "en technology.\nAll these trends drive the “hot” areas of research described below. This compilation\nis meant simply to reflect the areas that, by one metric or another, currently receive\ngreater attention than others. They are not necessarily more important or valuable\nthan other ones. Indeed, some of the currently “hot” areas were less popular in past\nyears, and it is likely that other areas will similarly re-emerge in the future.\nLarge-scale machine learning\nMany of the basic problems in machine learning (such as supervised and\nunsupervised learning) are well-understood. A major focus of current efforts is to\nscale existing algorithms to work with extremely large data sets. For example, whereas\ntraditional methods could afford to make several passes over the data set, modern",
    "page": 14
  },
  {
    "type": "text",
    "content": "example, whereas\ntraditional methods could afford to make several passes over the data set, modern\nones are designed to make only a single pass; in some cases, only sublinear methods\n(those that only look at a fraction of the data) can be admitted.\nDeep learning\nThe ability to successfully train convolutional neural networks has most benefited the\nfield of computer vision, with applications such as object recognition, video\n12 Gerald Tesauro, “Practical Issues in Temporal Difference Learning,” Machine Learning, no. 8\n(1992): 257–77.\n13 David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den\nDriessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander",
    "page": 14
  },
  {
    "type": "text",
    "content": "den\nDriessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander\nDieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap,\nMadeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis, “Mastering the game\nof Go with deep neural networks and tree search,” Nature 529 (2016): 484–489.\n14 W. McCulloch and W. Pitts, W., “A logical calculus of the ideas immanent in nervous activity,”\nBulletin of Mathematical Biophysics, 5 (1943): 115–133.\n15 Appendix I offers a short history of AI, including a description of some of the traditionally\ncore areas of research, which have shifted over the past six decades.\n16 Backpropagation is an abbreviation for “backward propagation of errors,” a common method",
    "page": 14
  },
  {
    "type": "text",
    "content": "ecades.\n16 Backpropagation is an abbreviation for “backward propagation of errors,” a common method\nof training artificial neural networks used in conjunction with an optimization method such as\ngradient descent. The method calculates the gradient of a loss function with respect to all the\n14 weights in the network.",
    "page": 14
  },
  {
    "type": "text",
    "content": "labeling, activity recognition, and several variants thereof. Deep learning is also making\nsignificant inroads into other areas of perception, such as audio, speech, and natural\nlanguage processing.\nReinforcement learning\nWhereas traditional machine learning has mostly focused on pattern mining,\nreinforcement learning shifts the focus to decision making, and is a technology that\nwill help AI to advance more deeply into the realm of learning about and executing\nactions in the real world. It has existed for several decades as a framework for\nexperience-driven sequential decision-making, but the methods have not found great AI technologies already\nsuccess in practice, mainly owing to issues of representation and scaling. However,\npervade our lives. As",
    "page": 15
  },
  {
    "type": "text",
    "content": "s in practice, mainly owing to issues of representation and scaling. However,\npervade our lives. As\nthe advent of deep learning has provided reinforcement learning with a “shot in the\narm.” The recent success of AlphaGo, a computer program developed by Google\nthey become a central\nDeepmind that beat the human Go champion in a five-game match, was due in large\npart to reinforcement learning. AlphaGo was trained by initializing an automated force in society, the\nagent with a human expert database, but was subsequently refined by playing a large\nnumber of games against itself and applying reinforcement learning. field is shifting from\nRobotics\nsimply building systems\nRobotic navigation, at least in static environments, is largely solved. Current efforts",
    "page": 15
  },
  {
    "type": "text",
    "content": "ing systems\nRobotic navigation, at least in static environments, is largely solved. Current efforts\nconsider how to train a robot to interact with the world around it in generalizable that are intelligent to\nand predictable ways. A natural requirement that arises in interactive environments\nis manipulation, another topic of current interest. The deep learning revolution is building intelligent\nonly beginning to influence robotics, in large part because it is far more difficult to\nsystems that are\nacquire the large labeled data sets that have driven other learning-based areas of AI.\nReinforcement learning (see above), which obviates the requirement of labeled data,\nhuman-aware and\nmay help bridge this gap but requires systems to be able to safely explore a policy",
    "page": 15
  },
  {
    "type": "text",
    "content": "human-aware and\nmay help bridge this gap but requires systems to be able to safely explore a policy\nspace without committing errors that harm the system itself or others. Advances in trustworthy.\nreliable machine perception, including computer vision, force, and tactile perception,\nmuch of which will be driven by machine learning, will continue to be key enablers to\nadvancing the capabilities of robotics.\nComputer vision\nComputer vision is currently the most prominent form of machine perception. It has\nbeen the sub-area of AI most transformed by the rise of deep learning. Until just a\nfew years ago, support vector machines were the method of choice for most visual\nclassification tasks. But the confluence of large-scale computing, especially on GPUs,",
    "page": 15
  },
  {
    "type": "text",
    "content": "most visual\nclassification tasks. But the confluence of large-scale computing, especially on GPUs,\nthe availability of large datasets, especially via the internet, and refinements of neural\nnetwork algorithms has led to dramatic improvements in performance on benchmark\ntasks (e.g., classification on ImageNet17). For the first time, computers are able to\nperform some (narrowly defined) visual classification tasks better than people. Much\ncurrent research is focused on automatic image and video captioning.\nNatural Language Processing\nOften coupled with automatic speech recognition, Natural Language Processing is\nanother very active area of machine perception. It is quickly becoming a commodity\nfor mainstream languages with large data sets. Google announced that 20% of",
    "page": 15
  },
  {
    "type": "text",
    "content": "ly becoming a commodity\nfor mainstream languages with large data sets. Google announced that 20% of\ncurrent mobile queries are done by voice,18 and recent demonstrations have proven\nthe possibility of real-time translation. Research is now shifting towards developing\nrefined and capable systems that are able to interact with people through dialog, not\njust react to stylized requests.\n17 ImageNet, Stanford Vision Lab, Stanford University, Princeton University, 2016, accessed\nAugust 1, 2016, www.image-net.org/.\n18 Greg Sterling, “Google says 20% of mobile queries are voice searches,” Search Engine Land,\nMay 18, 2016, accessed August 1, 2016, http://searchengineland.com/google-reveals-20-percent-\nqueries-voice-queries-249917. 15",
    "page": 15
  },
  {
    "type": "text",
    "content": "t-\nqueries-voice-queries-249917. 15",
    "page": 15
  },
  {
    "type": "text",
    "content": "Collaborative systems\nResearch on collaborative systems investigates models and algorithms to help\ndevelop autonomous systems that can work collaboratively with other systems and\nwith humans. This research relies on developing formal models of collaboration,\nand studies the capabilities needed for systems to become effective partners. There\nis growing interest in applications that can utilize the complementary strengths of\nhumans and machines—for humans to help AI systems to overcome their limitations,\nand for agents to augment human abilities and activities.\nNatural Language\nCrowdsourcing and human computation\nSince human abilities are superior to automated methods for accomplishing many\nProcessing is a very\ntasks, research on crowdsourcing and human computation investigates methods to",
    "page": 16
  },
  {
    "type": "text",
    "content": "Processing is a very\ntasks, research on crowdsourcing and human computation investigates methods to\nactive area of machine augment computer systems by utilizing human intelligence to solve problems that\ncomputers alone cannot solve well. Introduced only about fifteen years ago, this\nperception. Research research now has an established presence in AI. The best-known example of\ncrowdsourcing is Wikipedia, a knowledge repository that is maintained and updated\nis now shifting towards\nby netizens and that far exceeds traditionally-compiled information sources, such\nas encyclopedias and dictionaries, in scale and depth. Crowdsourcing focuses on\ndeveloping systems that\ndevising innovative ways to harness human intelligence. Citizen science platforms",
    "page": 16
  },
  {
    "type": "text",
    "content": "ping systems that\ndevising innovative ways to harness human intelligence. Citizen science platforms\nare able to interact with energize volunteers to solve scientific problems, while paid crowdsourcing platforms\nsuch as Amazon Mechanical Turk provide automated access to human intelligence on\npeople through dialog,\ndemand. Work in this area has facilitated advances in other subfields of AI, including\ncomputer vision and NLP, by enabling large amounts of labeled training data and/or\nnot just react to stylized\nhuman interaction data to be collected in a short amount of time. Current research\nrequests. efforts explore ideal divisions of tasks between humans and machines based on their\ndiffering capabilities and costs.\nAlgorithmic game theory and computational social choice",
    "page": 16
  },
  {
    "type": "text",
    "content": "on their\ndiffering capabilities and costs.\nAlgorithmic game theory and computational social choice\nNew attention is being drawn to the economic and social computing dimensions of\nAI, including incentive structures. Distributed AI and multi-agent systems have been\nstudied since the early 1980s, gained prominence starting in the late 1990s, and were\naccelerated by the internet. A natural requirement is that systems handle potentially\nmisaligned incentives, including self-interested human participants or firms, as well\nas automated AI-based agents representing them. Topics receiving attention include\ncomputational mechanism design (an economic theory of incentive design, seeking\nincentive-compatible systems where inputs are truthfully reported), computational",
    "page": 16
  },
  {
    "type": "text",
    "content": "e design, seeking\nincentive-compatible systems where inputs are truthfully reported), computational\nsocial choice (a theory for how to aggregate rank orders on alternatives), incentive\naligned information elicitation (prediction markets, scoring rules, peer prediction) and\nalgorithmic game theory (the equilibria of markets, network games, and parlor games\nsuch as Poker—a game where significant advances have been made in recent years\nthrough abstraction techniques and no-regret learning).\nInternet of Things (IoT)\nA growing body of research is devoted to the idea that a wide array of devices can\nbe interconnected to collect and share their sensory information. Such devices can\ninclude appliances, vehicles, buildings, cameras, and other things. While it’s a matter",
    "page": 16
  },
  {
    "type": "text",
    "content": "devices can\ninclude appliances, vehicles, buildings, cameras, and other things. While it’s a matter\nof technology and wireless networking to connect the devices, AI can process and\nuse the resulting huge amounts of data for intelligent and useful purposes. Currently,\nthese devices use a bewildering array of incompatible communication protocols. AI\ncould help tame this Tower of Babel.\nNeuromorphic Computing\nTraditional computers implement the von Neumann model of computing, which\nseparates the modules for input/output, instruction-processing, and memory. With\nthe success of deep neural networks on a wide array of tasks, manufacturers are\n16",
    "page": 16
  },
  {
    "type": "text",
    "content": "actively pursuing alternative models of computing—especially those that are inspired\nby what is known about biological neural networks—with the aim of improving the\nhardware efficiency and robustness of computing systems. At the moment, such\n“neuromorphic” computers have not yet clearly demonstrated big wins, and are just\nbeginning to become commercially viable. But it is possible that they will become\ncommonplace (even if only as additions to their von Neumann cousins) in the\nnear future. Deep neural networks have already created a splash in the application\nlandscape. A larger wave may hit when these networks can be trained and executed\nA growing body of research\non dedicated neuromorphic hardware, as opposed to simulated on standard von\nNeumann architectures, as they are today.",
    "page": 17
  },
  {
    "type": "text",
    "content": "morphic hardware, as opposed to simulated on standard von\nNeumann architectures, as they are today.\nis devoted to the idea that\nOverall trends and the future of AI research\na wide array of devices\nThe resounding success of the data-driven paradigm has displaced the traditional\nparadigms of AI. Procedures such as theorem proving and logic-based knowledge can be interconnected\nrepresentation and reasoning are receiving reduced attention, in part because of the\nto collect and share their\nongoing challenge of connecting with real-world groundings. Planning, which was a\nmainstay of AI research in the seventies and eighties, has also received less attention\nsensory information.\nof late due in part to its strong reliance on modeling assumptions that are hard\nto satisfy in realistic applications.",
    "page": 17
  },
  {
    "type": "text",
    "content": "t to its strong reliance on modeling assumptions that are hard\nto satisfy in realistic applications. Model-based approaches—such as physics-based Such devices can include\napproaches to vision and traditional control and mapping in robotics—have by and\nappliances, vehicles,\nlarge given way to data-driven approaches that close the loop with sensing the results\nof actions in the task at hand. Bayesian reasoning and graphical models, which were\nbuildings, cameras, and\nvery popular even quite recently, also appear to be going out of favor, having been\ndrowned by the deluge of data and the remarkable success of deep learning. other things.\nOver the next fifteen years, the Study Panel expects an increasing focus on\ndeveloping systems that are human-aware, meaning that they specifically model,",
    "page": 17
  },
  {
    "type": "text",
    "content": "increasing focus on\ndeveloping systems that are human-aware, meaning that they specifically model,\nand are specifically designed for, the characteristics of the people with whom they\nare meant to interact. There is a lot of interest in trying to find new, creative ways\nto develop interactive and scalable ways to teach robots. Also, IoT-type systems—\ndevices and the cloud—are becoming increasingly popular, as is thinking about\nsocial and economic dimensions of AI. In the coming years, new perception/object\nrecognition capabilities and robotic platforms that are human-safe will grow, as will\ndata-driven products and their markets.\nThe Study Panel also expects a reemergence of some of the traditional forms of",
    "page": 17
  },
  {
    "type": "text",
    "content": "s and their markets.\nThe Study Panel also expects a reemergence of some of the traditional forms of\nAI as practitioners come to realize the inevitable limitations of purely end-to-end deep\nlearning approaches. We encourage young researchers not to reinvent the wheel,\nbut rather to maintain an awareness of the significant progress in many areas of\nAI during the first fifty years of the field, and in related fields such as control theory,\ncognitive science, and psychology.\n17",
    "page": 17
  },
  {
    "type": "text",
    "content": "SECTION II: AI BY DOMAIN\nThough different instances of AI research and practice share common technologies, such\nas machine learning, they also vary considerably in different sectors of the economy and\nsociety. We call these sectors “domains,” and in this section describe the different states\nof AI research and implementation, as well as impacts and distinct challenges, in eight of\nthem: transportation; home/service robotics; healthcare; education; low-resource communities;\npublic safety and security; employment and workplace; and entertainment. Based on these\nAutonomous analyses, we also predict trends in a typical North American city over the next fifteen years.\nContrary to AI’s typical depiction in popular culture, we seek to offer a balanced overview\ntransportation will soon",
    "page": 18
  },
  {
    "type": "text",
    "content": "typical depiction in popular culture, we seek to offer a balanced overview\ntransportation will soon\nof the ways in which AI is already beginning to transform everyday life, and how those\ntransformations are likely to grow by the year 2030.\nbe commonplace and,\nas most people’s first TRANSPORTATION\nexperience with physically Transportation is likely to be one of the first domains in which the general public\nwill be asked to trust the reliability and safety of an AI system for a critical task.\nembodied AI systems, Autonomous transportation will soon be commonplace and, as most people’s first\nexperience with physically embodied AI systems, will strongly influence the public’s\nwill strongly influence the\nperception of AI. Once the physical hardware is made sufficiently safe and robust, its",
    "page": 18
  },
  {
    "type": "text",
    "content": "nfluence the\nperception of AI. Once the physical hardware is made sufficiently safe and robust, its\nintroduction to daily life may happen so suddenly as to surprise the public, which will\npublic’s perception of AI.\nrequire time to adjust. As cars will become better drivers than people, city-dwellers\nwill own fewer cars, live further from work, and spend time differently, leading to an\nentirely new urban organization. Further, in the typical North American city in 2030,\nchanges won’t be limited to cars and trucks, but are likely to include flying vehicles\nand personal robots, and will raise social, ethical and policy issues.\nA few key technologies have already catalyzed the widespread adoption of AI\nin transportation. Compared to 2000, the scale and diversity of data about personal",
    "page": 18
  },
  {
    "type": "text",
    "content": "adoption of AI\nin transportation. Compared to 2000, the scale and diversity of data about personal\nand population-level transportation available today—enabled by the adoption of\nsmartphones and decreased costs and improved accuracies for variety of sensors—is\nastounding. Without the availability of this data and connectivity, applications such as\nreal-time sensing and prediction of traffic, route calculations, peer-to-peer ridesharing\nand self-driving cars would not be possible.\nSmarter cars\nGPS was introduced to personal vehicles in 2001 with in-car navigation devices and\nhas since become a fundamental part of the transportation infrastructure.19 GPS\nassists drivers while providing large-scale information to technology companies and\ncities about transportation patterns.",
    "page": 18
  },
  {
    "type": "text",
    "content": "providing large-scale information to technology companies and\ncities about transportation patterns. Widespread adoption of smartphones with GPS\ntechnology further increased connectivity and the amount of location data shared by\nindividuals.\nCurrent vehicles are also equipped with a wide range of sensing capabilities.\nAn average automobile in the US is predicted to have seventy sensors including\ngyroscopes, accelerometers, ambient light sensors, and moisture sensors.20 Sensors\nare not new to vehicles. Automobiles built before 2000 had sensors for the\ninternal state of the vehicle such as its speed, acceleration, and wheel position.21\n19 Mark Sullivan, “A brief history of GPS,” PCWorld, August 9, 2012, accessed August 1, 2016,\nhttp://www.pcworld.com/article/2000276/a-brief-history-of-gps.",
    "page": 18
  },
  {
    "type": "text",
    "content": "ust 9, 2012, accessed August 1, 2016,\nhttp://www.pcworld.com/article/2000276/a-brief-history-of-gps.html.\n20 William J. Fleming, “New Automotive Sensors - A Review,” IEEE Sensors Journal 8, no 11,\n(2008): 1900-1921.\n21 Jean Jacques Meneu, ed., “Automotive Sensors: Now and in the Future,” Arrow, September 24,\n2015, accessed August 1, 2016, https://www.arrow.com/en/research-and-events/articles/automotive-\n18 sensors-now-and-in-the-future.",
    "page": 18
  },
  {
    "type": "text",
    "content": "They already had a number of functionalities that combined real-time sensing with\nperception and decision-making such as Anti-lock Braking Systems (ABS), airbag\ncontrol, Traction Control Systems (TCS), and Electronic Stability Control (ESC).22\nAutomated capabilities have been introduced into commercial cars gradually since\n2003 as summarized in the following table.\nContext Automated Functionality Release Date\nAs cars will become better\nParking Intelligent Parking Assist System Since 200323\ndrivers than people, city-\nParking Summon Since 201624\ndwellers will own fewer\nArterial & Highway Lane departure system Since 2004 in North America25\ncars, live further from\nArterial & Highway Adaptive cruise control Since 2005 in North America26\nwork, and spend time\nHighway Blind spot monitoring 200727",
    "page": 19
  },
  {
    "type": "text",
    "content": "ise control Since 2005 in North America26\nwork, and spend time\nHighway Blind spot monitoring 200727\ndifferently, leading to\nHighway Lane changing 201528 an entirely new urban\norganization.\nThese functionalities assist drivers or completely take over well-defined activities\nfor increased safety and comfort. Current cars can park themselves, perform adaptive\ncruise control on highways, steer themselves during stop-and-go traffic, and alert\ndrivers about objects in blind spots during lane changes. Vision and radar technology\nwere leveraged to develop pre-collision systems that let cars autonomously brake\nwhen risk of a collision is detected. Deep learning also has been applied to improve\nautomobiles’ capacity to detect objects in the environment and recognize sound.29\nSelf-driving vehicles",
    "page": 19
  },
  {
    "type": "text",
    "content": "mobiles’ capacity to detect objects in the environment and recognize sound.29\nSelf-driving vehicles\nSince the 1930s, science fiction writers dreamed of a future with self-driving cars,\nand building them has been a challenge for the AI community since the 1960s. By\nthe 2000s, the dream of autonomous vehicles became a reality in the sea and sky, and\neven on Mars, but self-driving cars existed only as research prototypes in labs. Driving\nin a city was considered to be a problem too complex for automation due to factors\nlike pedestrians, heavy traffic, and the many unexpected events that can happen\noutside of the car’s control. Although the technological components required to\n22 Carl Liersch, “Vehicle Technology Timeline: From Automated to Driverless,” Robert Bosch\n(Australia) Pty. Ltd.",
    "page": 19
  },
  {
    "type": "text",
    "content": "sch, “Vehicle Technology Timeline: From Automated to Driverless,” Robert Bosch\n(Australia) Pty. Ltd., 2014, accessed August 1, 2016, http://dpti.sa.gov.au/__data/assets/pdf_\nfile/0009/246807/Carl_Liersch_Presentation.pdf.\n23 “Intelligent Parking Assist System,” Wikipedia, last modified July 26, 2016, accessed August 1,\n2016, https://en.wikipedia.org/wiki/Intelligent_Parking_Assist_System.\n24 The Tesla Motors Team, “Summon Your Tesla from Your Phone,” Tesla, January 10, 2016,\naccessed August 1, 2016, https://www.teslamotors.com/blog/summon-your-tesla-your-phone.\n25 Lane departure warning system,” Wikipedia, last modified July 24, 2016, accessed August 1,\n2016, https://en.wikipedia.org/wiki/Lane_departure_warning_system.",
    "page": 19
  },
  {
    "type": "text",
    "content": "uly 24, 2016, accessed August 1,\n2016, https://en.wikipedia.org/wiki/Lane_departure_warning_system.\n26 “Autonomous cruise control system,” Wikipedia, last modified July 30, 2016, accessed August 1,\n2016, https://en.wikipedia.org/wiki/Autonomous_cruise_control_system.\n27 “Blind spot monitor,” Wikipedia, last modified April 20, 2016, accessed August 1, 2016,\nhttps://en.wikipedia.org/wiki/Blind_spot_monitor.\n28 Dana Hull, “Tesla Starts Rolling Out Autopilot Features,” Boomberg Technology, October 14,\n2015, accessed August 1, 2016, http://www.bloomberg.com/news/articles/2015-10-14/tesla-\nsoftware-upgrade-adds-automated-lane-changing-to-model-s.\n29 Aaron Tilley, “New Qualcomm Chip Brings Deep Learning To Cars,” Forbes, January 5, 2016,\naccessed August 1, 2016, http://www.forbes.",
    "page": 19
  },
  {
    "type": "text",
    "content": "Brings Deep Learning To Cars,” Forbes, January 5, 2016,\naccessed August 1, 2016, http://www.forbes.com/sites/aarontilley/2016/01/05/along-with-nvidia-\nnew-qualcomm-chip-brings-deep-learning-to-cars/#4cb4e9235357. 19",
    "page": 19
  },
  {
    "type": "table",
    "content": "TABLE (Page 19):\nContext | Automated Functionality | Release Date\nParking | Intelligent Parking Assist System | Since 200323\nParking | Summon | Since 201624\nArterial & Highway | Lane departure system | Since 2004 in North America25\nArterial & Highway | Adaptive cruise control | Since 2005 in North America26\nHighway | Blind spot monitoring | 200727\nHighway | Lane changing | 201528",
    "page": 19
  },
  {
    "type": "text",
    "content": "make such autonomous driving possible were available in 2000—and indeed some\nautonomous car prototypes existed30 31 32—few predicted that mainstream companies\nwould be developing and deploying autonomous cars by 2015. During the first\nDefense Advanced Research Projects Agency (DARPA) “grand challenge” on\nautonomous driving in 2004, research teams failed to complete the challenge in a\nlimited desert setting.\nBut in eight short years, from 2004-2012, speedy and surprising progress occurred\nin both academia and industry. Advances in sensing technology and machine learning\nWe will see self-driving and\nfor perception tasks has sped progress and, as a result, Google’s autonomous vehicles\nand Tesla’s semi-autonomous cars are driving on city streets today. Google’s self-",
    "page": 20
  },
  {
    "type": "text",
    "content": "onomous vehicles\nand Tesla’s semi-autonomous cars are driving on city streets today. Google’s self-\nremotely controlled delivery\ndriving cars, which have logged more than 1,500,000 miles (300,000 miles without an\nvehicles, flying vehicles, accident),33 are completely autonomous—no human input needed. Tesla has widely\nreleased self-driving capability to existing cars with a software update.34 Their cars are\nand trucks. Peer-to-peer semi-autonomous, with human drivers expected to stay engaged and take over if they\ndetect a potential problem. It is not yet clear whether this semi-autonomous approach\ntransportation services\nis sustainable, since as people become more confident in the cars’ capabilities, they\nare likely to pay less attention to the road, and become less reliable when they are",
    "page": 20
  },
  {
    "type": "text",
    "content": "bilities, they\nare likely to pay less attention to the road, and become less reliable when they are\nsuch as ridesharing are\nmost needed. The first traffic fatality involving an autonomous car, which occurred in\nalso likely to utilize self- June of 2016, brought this question into sharper focus.35\nIn the near future, sensing algorithms will achieve super-human performance for\ndriving vehicles.\ncapabilities required for driving. Automated perception, including vision, is already\nnear or at human-level performance for well-defined tasks such as recognition and\ntracking. Advances in perception will be followed by algorithmic improvements\nin higher level reasoning capabilities such as planning. A recent report predicts\nself-driving cars to be widely adopted by 2020.",
    "page": 20
  },
  {
    "type": "text",
    "content": "abilities such as planning. A recent report predicts\nself-driving cars to be widely adopted by 2020.36 And the adoption of self-driving\ncapabilities won’t be limited to personal transportation. We will see self-driving and\nremotely controlled delivery vehicles, flying vehicles, and trucks. Peer-to-peer\ntransportation services such as ridesharing are also likely to utilize self-driving vehicles.\nBeyond self-driving cars, advances in robotics will facilitate the creation and adoption\nof other types of autonomous vehicles, including robots and drones.\nIt is not yet clear how much better self-driving cars need to become to encourage\nbroad acceptance. The collaboration required in semi-self-driving cars and its\nimplications for the cognitive load of human drivers is not well understood. But",
    "page": 20
  },
  {
    "type": "text",
    "content": "iving cars and its\nimplications for the cognitive load of human drivers is not well understood. But\nif future self-driving cars are adopted with the predicted speed, and they exceed\nhuman-level performance in driving, other significant societal changes will follow.\nSelf-driving cars will eliminate one of the biggest causes of accidental death and\ninjury in United States, and lengthen people’s life expectancy. On average, a\n30 “Navlab,” Wikipedia, last updated June 4, 2016, accessed August 1, 2016, https://en.wikipedia.\norg/wiki/Navlab.\n31 “Navlab: The Carnegie Mellon University Navigation Laboratory,” Carnegie Mellon\nUniversity, accessed August 1, 2016, http://www.cs.cmu.edu/afs/cs/project/alv/www/.",
    "page": 20
  },
  {
    "type": "text",
    "content": "Carnegie Mellon\nUniversity, accessed August 1, 2016, http://www.cs.cmu.edu/afs/cs/project/alv/www/.\n32 “Eureka Prometheus Project,” Wikipedia, last modified February 12, 2016, accessed August 1,\n2016, https://en.wikipedia.org/wiki/Eureka_Prometheus_Project.\n33 “Google Self-Driving Car Project,” Google, accessed August 1, 2016, https://www.google.\ncom/selfdrivingcar/. 33 Molly McHugh, “Tesla’s Cars Now Drive Themselves, Kinda,” Wired,\nOctober 14, 2015, accessed August 1, 2016, http://www.wired.com/2015/10/tesla-self-driving-over-\nair-update-live/.\n34 Molly McHugh, “Tesla’s Cars Now Drive Themselves, Kinda,” Wired, October 14, 2015,\naccessed August 1, 2016, http://www.wired.com/2015/10/tesla-self-driving-over-air-update-live/.",
    "page": 20
  },
  {
    "type": "text",
    "content": "15,\naccessed August 1, 2016, http://www.wired.com/2015/10/tesla-self-driving-over-air-update-live/.\n35 Anjali Singhvi and Karl Russell, “Inside the Self-Driving Tesla Fatal Accident,” The New\nYork Times, Last updated July 12, 2016, accessed August 1, 2016, http://www.nytimes.com/\ninteractive/2016/07/01/business/inside-tesla-accident.html.\n36 John Greenough, “10 million self-driving cars will be on the road by 2020,” Business Insider,\nJune 15, 2016, accessed August 1, 2016, http://www.businessinsider.com/report-10-million-self-\n20 driving-cars-will-be-on-the-road-by-2020-2015-5-6.",
    "page": 20
  },
  {
    "type": "text",
    "content": "commuter in US spends twenty-five minutes driving each way.37 With self-driving car\ntechnology, people will have more time to work or entertain themselves during their\ncommutes. And the increased comfort and decreased cognitive load with self-driving\ncars and shared transportation may affect where people choose to live. The reduced\nneed for parking may affect the way cities and public spaces are designed. Self-driving\ncars may also serve to increase the freedom and mobility of different subgroups of\nthe population, including youth, elderly and disabled.\nSelf-driving cars and peer-to-peer transportation services may eliminate the need\nShared transportation\nto own a vehicle. The effect on total car use is hard to predict. Trips of empty vehicles",
    "page": 21
  },
  {
    "type": "text",
    "content": "portation\nto own a vehicle. The effect on total car use is hard to predict. Trips of empty vehicles\nand people’s increased willingness to travel may lead to more total miles driven.\nmay displace the need for\nAlternatively, shared autonomous vehicles—people using cars as a service rather than\nowning their own—may reduce total miles, especially if combined with well-constructed public transportation—\nincentives, such as tolls or discounts, to spread out travel demand, share trips, and\nreduce congestion. The availability of shared transportation may displace the need or public transportation\nfor public transportation—or public transportation may change form towards\nmay change form towards\npersonal rapid transit, already available in four cities,38 which uses small capacity",
    "page": 21
  },
  {
    "type": "text",
    "content": "form towards\npersonal rapid transit, already available in four cities,38 which uses small capacity\nvehicles to transport people on demand and point-to-point between many stations.39\npersonal rapid transit\nAs autonomous vehicles become more widespread, questions will arise over their\nsecurity, including how to ensure that technologies are safe and properly tested that uses small capacity\nunder different road conditions prior to their release. Autonomous vehicles and the\nvehicles to transport\nconnected transportation infrastructure will create a new venue for hackers to exploit\nvulnerabilities to attack. Ethical questions are also involved in programming cars to\npeople on demand.\nact in situations in which human injury or death is inevitable, especially when there",
    "page": 21
  },
  {
    "type": "text",
    "content": "le on demand.\nact in situations in which human injury or death is inevitable, especially when there\nare split-second choices to be made about whom to put at risk. The legal systems in\nmost states in the US do not have rules covering self-driving cars. As of 2016, four\nstates in the US (Nevada, Florida, California, and Michigan), Ontario in Canada,\nthe United Kingdom, France, and Switzerland have passed rules for the testing\nof self-driving cars on public roads. Even these laws do not address issues about\nresponsibility and assignment of blame for an accident for self-driving and semi-self-\ndriving cars.40\nTransportation planning\nBy 2005, cities had started investing in the transportation infrastructure to develop\nsensing capabilities for vehicle and pedestrian traffic.",
    "page": 21
  },
  {
    "type": "text",
    "content": "he transportation infrastructure to develop\nsensing capabilities for vehicle and pedestrian traffic.41 The sensors currently used\ninclude inductive loops, video cameras, remote traffic microwave sensors, radars, and\nGPS.42 For example, in 2013 New York started using a combination of microwave\nsensors, a network of cameras, and pass readers to detect vehicle traffic in the city.43\n37 Brian McKenzie and Melanie Rapino, “Commuting in the United States: 2009,” American\nCommunity Survey Reports, United States Census Bureau, September 2011, accessed August 1, 2016,\nhttps://www.census.gov/prod/2011pubs/acs-15.pdf.\n38 Morgantown, West Virginia; Masdar City, UAE; London, England; and Suncheon, South\nKorea.",
    "page": 21
  },
  {
    "type": "text",
    "content": "15.pdf.\n38 Morgantown, West Virginia; Masdar City, UAE; London, England; and Suncheon, South\nKorea.\n39 “Personal rapid transit,” Wikipedia, Last modified July 18, 2016, accessed August 1, 2016,\nhttps://en.wikipedia.org/wiki/Personal_rapid_transit.\n40 Patrick Lin, “The Ethics of Autonomous Cars,” The Atlantic, October 8, 2013, accessed\nAugust 1, 2016, http://www.theatlantic.com/technology/archive/2013/10/the-ethics-of-\nautonomous-cars/280360/.\n41 Steve Lohr, “Bringing Efficiency to the Infrastructure,” The New York Times, April 29,\n2009, accessed August 1, 2016, http://www.nytimes.com/2009/04/30/business/energy-\nenvironment/30smart.html.\n42 “Intelligent transportation system,” Wikipedia, last modified July 28, 2016, accessed August 1, 2016,\nhttps://en.wikipedia.",
    "page": 21
  },
  {
    "type": "text",
    "content": "tion system,” Wikipedia, last modified July 28, 2016, accessed August 1, 2016,\nhttps://en.wikipedia.org/wiki/Intelligent_transportation_system.\n43 Access Science Editors, “Active traffic management: adaptive traffic signal control,” Access Science,\n2014, accessed August 1, 2016, http://www.accessscience.com/content/active-traffic-management-\nadaptive-traffic-signal-control/BR0106141. 21",
    "page": 21
  },
  {
    "type": "text",
    "content": "Cities use AI methods to optimize services in several ways, such as bus and subway\nschedules, and tracking traffic conditions to dynamically adjust speed limits or apply\nsmart pricing on highways, bridges, and HOV lanes.44 45 46 Using sensors and cameras\nin the road network, they can also optimize traffic light timing for improving traffic\nflow and to help with automated enforcement.47 48 These dynamic strategies are aimed\nat better utilizing the limited resources in the transportation network, and are made\npossible by the availability of data and the widespread connectivity of individuals.\nBefore the 2000s, transportation planners were forced to rely on static pricing\nEthical questions arise\nstrategies tied to particular days or times of day, to manage demand. As dynamic",
    "page": 22
  },
  {
    "type": "text",
    "content": "al questions arise\nstrategies tied to particular days or times of day, to manage demand. As dynamic\npricing strategies are adopted, this raises new issues concerning the fair distribution\nwhen programming cars to\nof public goods, since market conditions in high-demand situations may make\nact in situations in which services unavailable to segments of the public.\nThe availability of large-scale data has also made transportation an ideal domain\nhuman injury or death is for machine learning applications. Since 2006, applications such as Mapquest, Google\nMaps, and Bing Maps have been widely used by the public for routing trips, using public\ninevitable, especially when\ntransportation, receiving real-time information and predictions about traffic conditions,",
    "page": 22
  },
  {
    "type": "text",
    "content": "ally when\ntransportation, receiving real-time information and predictions about traffic conditions,\n49 50 and finding services around a location.51 52 Optimal search algorithms have been\nthere are split-second\napplied to the routing of vehicles and pedestrians to a given destination (i.e.,53 54).\nchoices to be made about Despite these advances, the widespread application of sensing and optimization\ntechniques to city infrastructure has been slower than the application of these\nwhom to put at risk.\ntechniques to individual vehicles or people. Although individual cities have\nimplemented sensing and optimization applications, as yet there is no standardization\nof the sensing infrastructure and AI techniques used. Infrastructure costs, differing",
    "page": 22
  },
  {
    "type": "text",
    "content": "andardization\nof the sensing infrastructure and AI techniques used. Infrastructure costs, differing\npriorities among cities, and the high coordination costs among the parties involved\nhave slowed adoption, as have public concerns over privacy related to sensing. Still,\n44 Kitae Jang, Koohong Chung, and Hwasoo Yeo, “A Dynamic Pricing Strategy for High\nOccupancy Toll Lanes,” Transportation Research Part A: Policy and Practice 67 (2014): 69–80.\n45 “Seattle Variable Tolling Study,” City of Seattle Department of Transportation, May 2009,\naccessed August 1, 2016, http://www.seattle.gov/transportation/docs/FINAL%20Tolling%20\nStudy%20report%20revised%206.25.10.pdf.\n46 James F. Peltz, “Dynamic Pricing Is Catching On in the Public and Private Sectors,”",
    "page": 22
  },
  {
    "type": "text",
    "content": "6.25.10.pdf.\n46 James F. Peltz, “Dynamic Pricing Is Catching On in the Public and Private Sectors,”\nGovernment Technology, March 21, 2016, accessed August 1, 2016, http://www.govtech.com/budget-\nfinance/Dynamic-Pricing-Is-Catching-On-in-the-Public-and-Private-Sectors.html.\n47 Arthur G Sims and Kenneth W. Dobinson. “The Sydney Coordinated Adaptive Traffic\n(SCAT) System Philosophy and Benefits.” IEEE Transactions on Vehicular Technology 29, no. 2 (1980):\n130–137.\n48 “New York City Launches Nation’s Most Sophisticated Active Traffic Management System\nPowered by TransCore’s TransSuite Traffic Management Software and RFID Technology,”\nBusiness Wire, September 27, 2009, accessed August 1, 2016, http://www.businesswire.com/news/",
    "page": 22
  },
  {
    "type": "text",
    "content": "ogy,”\nBusiness Wire, September 27, 2009, accessed August 1, 2016, http://www.businesswire.com/news/\nhome/20110927005530/en/York-City-Launches-Nation%E2%80%99s-Sophisticated-Active-Traffic.\n49 Eric Horvitz, Johnson Apacible, Raman Sarin, and Lin Liao, “Prediction, Expectation, and\nSurprise: Methods, Designs, and Study of a Deployed Traffic Forecasting Service,” Proceedings of the\nTwenty-First Conference on Uncertainty and Artificial Intelligence (2005) (Arlington, Virginia: AUAI Press,\nJuly 2005), 275–283.\n50 Timothy Hunter, Ryan Herring, Pieter Abbeel, and Alexandre Bayen, “Path and Travel Time\nInference from GPS Probe Vehicle Data,” NIPS Analyzing Networks and Learning with Graphs 12, no. 1 (2009).\n51 John Krumm and Eric Horvitz, “Predestination: Inferring Destinations from Partial",
    "page": 22
  },
  {
    "type": "text",
    "content": "no. 1 (2009).\n51 John Krumm and Eric Horvitz, “Predestination: Inferring Destinations from Partial\nTrajectories,” UbiComp 2006: Ubiquitous Computing, Proceedings of the 8th International Conference,\nSeptember 2006, (Springer Berlin, Heidelberg, 2006), 243–260.\n52 Jill Duffy, “Get Organized: Using Location-Based Reminders,” PC Magazine, June 30, 2014,\naccessed August 1, 2016, http://www.pcmag.com/article2/0,2817,2460207,00.asp.\n53 Robert J. Szczerba, Peggy Galkowski, I. S. Glicktein, and Noah Ternullo. “Robust Algorithm\nfor Real-time Route Planning,” IEEE Transactions on Aerospace and Electronic Systems 36, no. 3 (2000):\n869–878.\n54 Matt Duckham and Lars Kulik, “Simplest” Paths: Automated Route Selection for\nNavigation,” Spatial Information Theory.",
    "page": 22
  },
  {
    "type": "text",
    "content": "Lars Kulik, “Simplest” Paths: Automated Route Selection for\nNavigation,” Spatial Information Theory. Foundations of Geographic Information Science,\nProceedings of the International Conference, COSIT 2003, September 2003 (Springer-Verlag\n22 Berlin Heidelberg, 2003), 169-185.",
    "page": 22
  },
  {
    "type": "text",
    "content": "AI is likely to have an increasing impact on city infrastructure. Accurate predictive\nmodels of individuals’ movements, their preferences, and their goals are likely to\nemerge with the greater availability of data. The ethical issues regarding such an\nemergence are discussed in Section III of this report.\nThe United States Department of Transportation released a call for proposals in\n2016 asking medium-size cities to imagine smart city infrastructure for transportation.55\nThis initiative plans to award forty million dollars to a city to demonstrate how\ntechnology and data can be used to reimagine the movement of people as well as goods.\nOur Study Panel doesn’t\nOne vision is a network of connected vehicles that can reach a high level of safety\nin driving with car-to-car communication.",
    "page": 23
  },
  {
    "type": "text",
    "content": "f connected vehicles that can reach a high level of safety\nin driving with car-to-car communication.56 If this vision becomes reality, we expect\nexpect drones that can\nadvances in multi-agent coordination, collaboration, and planning will have a\nsignificant impact on future cars and play a role in making the transportation system fly, swim, and drive, or\nmore reliable and efficient. Robots are also likely to take part in transportation by\ncarrying individuals and packages (c.f., Segway robot). For transportation of goods, flying quadcoptors to\ninterest in drones has increased, and Amazon is currently testing a delivery system using\nbecome a common means\nthem,57 although questions remain about the appropriate safety rules and regulations.",
    "page": 23
  },
  {
    "type": "text",
    "content": "common means\nthem,57 although questions remain about the appropriate safety rules and regulations.\nThe increased sensing capabilities, adoption of drones, and the connected\nof transportation by 2030\ntransportation infrastructure will also raise concerns about the privacy of individuals\nand the safety of private data. In coming years, these and related transportation issues (although prototypes exist\nwill need to be addressed either by preemptive action on the part of industry or within\ntoday).\nthe legal framework. As noted in the Section III policy discussion, how well this is done\nwill affect the pace and scope of AI-related advances in the transportation sector.\nOn-demand transportation\nOn-demand transportation services such as Uber and Lyft have emerged as another",
    "page": 23
  },
  {
    "type": "text",
    "content": "mand transportation\nOn-demand transportation services such as Uber and Lyft have emerged as another\npivotal application of sensing, connectivity, and AI,58 with algorithms for matching\ndrivers to passengers by location and suitability (reputation modeling).59 60\nThrough dynamic pricing, these services ration access by willingness-to-pay, with\ndynamic pricing also encouraging an increase in the supply of drivers, and have\nbecome a popular method for transportation in cities. With their rapid advance have\ncome multiple policy and legal issues, such as competition with existing taxi services\nand concerns about lack of regulation and safety. On-demand transportation services\nseem likely to be a major force towards self-driving cars.",
    "page": 23
  },
  {
    "type": "text",
    "content": "afety. On-demand transportation services\nseem likely to be a major force towards self-driving cars.\nCarpooling and ridesharing have long been seen as a promising approach to\ndecrease traffic congestion and better utilize personal transportation resources.\nServices such as Zimride and Nuride bring together people sharing similar routes for a\njoint trip. But this approach to carpooling has failed to gain traction on a large scale.\n55 “U.S. Department of Transportation Launches Smart City Challenge to Create a City of\nthe Future,” Transportation.gov, U.S. Department of Transportation, December 7, 2015, accessed\nAugust 1, 2016, https://www.transportation.gov/briefing-room/us-department-transportation-\nlaunches-smart-city-challenge-create-city-future.",
    "page": 23
  },
  {
    "type": "text",
    "content": "n.gov/briefing-room/us-department-transportation-\nlaunches-smart-city-challenge-create-city-future.\n56 Will Knight, “Car-to-Car Communication: A simple wireless technology promises to\nmake driving much safer.,” MIT Technology Review, accessed August 1, 2016, https://www.\ntechnologyreview.com/s/534981/car-to-car-communication/.\n57 “Amazon Prime Air,” Amazon, accessed August 1, 2016, http://www.amazon.com/\nb?node=8037720011.\n58 Jared Meyer, “Uber and Lyft are changing the way Americans move about their country,”\nNational Review, June 7, 2016, accessed August 1, 2016, http://www.nationalreview.com/\narticle/436263/uber-lyft-ride-sharing-services-sharing-economy-are-future.\n59 Alexander Howard, “How Digital Platforms Like LinkedIn, Uber And TaskRabbit Are",
    "page": 23
  },
  {
    "type": "text",
    "content": "nomy-are-future.\n59 Alexander Howard, “How Digital Platforms Like LinkedIn, Uber And TaskRabbit Are\nChanging The On-Demand Economy,” The Huffington Post, July 14, 2015, accessed August 1, 2016,\nhttp://www.huffingtonpost.com/entry/online-talent-platforms_us_55a03545e4b0b8145f72ccf6.\n60 “Announcing UberPool,” Uber Newsroom, August 5, 2014, accessed August 1, 2016, https://\nnewsroom.uber.com/announcing-uberpool/. 23",
    "page": 23
  },
  {
    "type": "text",
    "content": "Interacting with people\nFor decades, people have imagined wildly different, futuristic-looking transportation\nvehicles. Although future cars will be smarter and drones will be available widely, it\nis unlikely that by 2030 we will have widely adopted transportation vehicles that look\nand function differently than the ones we have today. Our Study Panel doesn’t expect\ndrones that can fly, swim, and drive, or flying quadcoptors to become a common\nmeans of transportation in this time horizon (although prototypes exist today).\nWe do expect humans to become partners to self-driving cars and drones in their\nOver the next fifteen years,\ntraining, execution, and evaluation. This partnering will happen both when humans\nare co-located with machines and also virtually.",
    "page": 24
  },
  {
    "type": "text",
    "content": "ation. This partnering will happen both when humans\nare co-located with machines and also virtually. We predict advances in algorithms to\ncoincident advances\nfacilitate machine learning from human input. We also expect models and algorithms\nin mechanical and AI for modeling of human attention, and to support communication and coordination\nbetween humans and machine. This is an integral part of the development of\ntechnologies promise to\nfuture vehicles.\nincrease the safe and\nHOME/SERVICE ROBOTS\nreliable use and utility of\nRobots have entered people’s homes in the past fifteen years. Disappointingly slow\ngrowth in the diversity of applications has occurred simultaneously with increasingly\nhome robots in a typical\nsophisticated AI deployed on existing applications.",
    "page": 24
  },
  {
    "type": "text",
    "content": "ously with increasingly\nhome robots in a typical\nsophisticated AI deployed on existing applications. AI advances are often inspired by\nNorth American city. mechanical innovations, which in turn prompt new AI techniques to be introduced.\nOver the next fifteen years, coincident advances in mechanical and AI technologies\npromise to increase the safe and reliable use and utility of home robots in a typical\nNorth American city. Special purpose robots will deliver packages, clean offices,\nand enhance security, but technical constraints and the high costs of reliable\nmechanical devices will continue to limit commercial opportunities to narrowly\ndefined applications for the foreseeable future. As with self-driving cars and other",
    "page": 24
  },
  {
    "type": "text",
    "content": "es to narrowly\ndefined applications for the foreseeable future. As with self-driving cars and other\nnew transportation machines, the difficulty of creating reliable, market-ready\nhardware is not to be underestimated.\nVacuum cleaners\nIn 2001, after many years of development, the Electrolux Trilobite, a vacuum\ncleaning robot, became the first commercial home robot. It had a simple control\nsystem to do obstacle avoidance, and some navigation. A year later, iRobot introduced\nRoomba, which was a tenth the price of the Trilobite and, with only 512 bytes of\nRAM, ran a behavior based controller. The most intelligent thing it did was to avoid\nfalling down stairs. Since then, sixteen million Roombas have been deployed all over\nthe world and several other competing brands now exist.",
    "page": 24
  },
  {
    "type": "text",
    "content": "million Roombas have been deployed all over\nthe world and several other competing brands now exist.\nAs the processing power and RAM capacity of low cost embedded processors\nimproved from its dismal state in the year 2000, the AI capabilities of these robots\nalso improved dramatically. Simple navigation, self-charging, and actions for dealing\nwith full dust bins were added, followed by ability to deal with electrical cords and\nrug tassels, enabled by a combination of mechanical improvements and sensor\nbased perception. More recently, the addition of full VSLAM (Visual Simultaneous\nLocation and Mapping)— an AI technology that had been around for twenty years—\nhas enabled the robots to build a complete 3D world model of a house as they clean,",
    "page": 24
  },
  {
    "type": "text",
    "content": "r twenty years—\nhas enabled the robots to build a complete 3D world model of a house as they clean,\nand become more efficient in their cleaning coverage.\nEarly expectations that many new applications would be found for home robots have\nnot materialized. Robot vacuum cleaners are restricted to localized flat areas, while real\nhomes have lots of single steps, and often staircases; there has been very little research\non robot mobility inside real homes. Hardware platforms remain challenging to build,\n24 and there are few applications that people want enough to buy. Perceptual algorithms",
    "page": 24
  },
  {
    "type": "text",
    "content": "for functions such as image labeling, and 3D object recognition, while common at AI\nconferences, are still only a few years into development as products.\nHome robots 2030\nDespite the slow growth to date of robots in the home, there are signs that this will\nchange in the next fifteen years. Corporations such as Amazon Robotics and Uber\nare developing large economies of scale using various aggregation technologies. Also:\nSystem in Module (SiM), with a lot of System on Chip (SoC) subsystems, are\nSpecial purpose robots\nnow being pushed out the door by phone-chip makers (Qualcomm’s SnapDragon,\nSamsung’s Artik, etc.). These are better than supercomputers of less than ten years\nwill deliver packages,\nago with eight or more sixty-four-bit cores, and specialized silicon for cryptography,",
    "page": 25
  },
  {
    "type": "text",
    "content": "er packages,\nago with eight or more sixty-four-bit cores, and specialized silicon for cryptography,\ncamera drivers, additional DSPs, and hard silicon for certain perceptual algorithms. clean offices, and enhance\nThis means that low cost devices will be able to support much more onboard AI than\nsecurity, but technical\nwe have been able to consider over the last fifteen years.\nCloud (“someone else’s computer”) is going to enable more rapid release of new\nconstraints and high\nsoftware on home robots, and more sharing of data sets gathered in many different\nhomes, which will in turn feed cloud-based machine learning, and then power costs will continue to limit\nimprovements to already deployed robots.",
    "page": 25
  },
  {
    "type": "text",
    "content": "hine learning, and then power costs will continue to limit\nimprovements to already deployed robots.\nThe great advances in speech understanding and image labeling enabled by deep commercial opportunities\nlearning will enhance robots’ interactions with people in their homes.\nfor the foreseeable future.\nLow cost 3D sensors, driven by gaming platforms, have fueled work on 3D\nperception algorithms by thousands of researchers worldwide, which will speed the\ndevelopment and adoption of home and service robots.\nIn the past three years, low cost and safe robot arms have been introduced to\nhundreds of research labs around the world, sparking a new class of research on\nmanipulation that will eventually be applicable in the home, perhaps around 2025.",
    "page": 25
  },
  {
    "type": "text",
    "content": "ss of research on\nmanipulation that will eventually be applicable in the home, perhaps around 2025.\nMore than half a dozen startups around the world are developing AI-based robots for\nthe home, for now concentrating mainly on social interaction. New ethics and privacy\nissues may surface as a result.\nHEALTHCARE\nFor AI technologies, healthcare has long been viewed as a promising domain.\nAI-based applications could improve health outcomes and quality of life for\nmillions of people in the coming years—but only if they gain the trust of doctors,\nnurses, and patients, and if policy, regulatory, and commercial obstacles are removed.\nPrime applications include clinical decision support, patient monitoring and\ncoaching, automated devices to assist in surgery or patient care, and management",
    "page": 25
  },
  {
    "type": "text",
    "content": "ent monitoring and\ncoaching, automated devices to assist in surgery or patient care, and management\nof healthcare systems. Recent successes, such as mining social media to infer\npossible health risks, machine learning to predict patients at risk, and robotics\nto support surgery, have expanded a sense of possibility for AI in healthcare.\nImprovements in methods for interacting with medical professionals and patients\nwill be a critical challenge.\nAs in other domains, data is a key enabler. There has been an immense forward\nleap in collecting useful data from personal monitoring devices and mobile apps, from\nelectronic health records (EHR) in clinical settings and, to a lesser extent, from robots\ndesigned to assist with medical procedures and hospital operations. But using this",
    "page": 25
  },
  {
    "type": "text",
    "content": "ent, from robots\ndesigned to assist with medical procedures and hospital operations. But using this\ndata to enable more finely-grained diagnostics and treatments for both individual\npatients and patient populations has proved difficult. Research and deployment have\nbeen slowed by outdated regulations and incentive structures. Poor human-computer\ninteraction methods and the inherent difficulties and risks of implementing\ntechnologies in such a large and complex system have slowed realization of AI’s\n25",
    "page": 25
  },
  {
    "type": "text",
    "content": "promise in healthcare.61 The reduction or removal of these obstacles, combined with\ninnovations still on the horizon, have the potential to significantly improve health\noutcomes and quality of life for millions of people in the coming years.\nThe clinical setting\nFor decades, the vision of an AI-powered clinician’s assistant has been a near cliché.\nAlthough there have been successful pilots of AI-related technology in healthcare,62\nthe current healthcare delivery system unfortunately remains structurally ill-suited to\nAI-based applications\nabsorb and deploy rapid advances. Incentives provided by the Affordable Care Act\nhave accelerated the penetration of electronic health records (EHRs) into clinical\ncould improve health",
    "page": 26
  },
  {
    "type": "text",
    "content": "accelerated the penetration of electronic health records (EHRs) into clinical\ncould improve health\npractice, but implementation has been poor, eroding clinicians’ confidence in their\noutcomes and quality of usefulness. A small group of companies control the EHR market, and user interfaces\nare widely considered substandard, including annoying pop-ups that physicians\nlife for millions of people\nroutinely dismiss. The promise of new analytics using data from EHRs, including AI,\nremains largely unrealized due to these and other regulatory and structural barriers.\nin the coming years—but\nLooking ahead to the next fifteen years, AI advances, if coupled with sufficient data\nonly if they gain the trust and well-targeted systems, promise to change the cognitive tasks assigned to human\nclinicians.",
    "page": 26
  },
  {
    "type": "text",
    "content": "trust and well-targeted systems, promise to change the cognitive tasks assigned to human\nclinicians. Physicians now routinely solicit verbal descriptions of symptoms from\nof doctors, nurses, and presenting patients and, in their heads, correlate patterns against the clinical\npresentation of known diseases. With automated assistance, the physician could\npatients.\ninstead supervise this process, applying her or his experience and intuition to guide the\ninput process and to evaluate the output of the machine intelligence. The literal\n“hands-on” experience of the physician will remain critical. A significant challenge is to\noptimally integrate the human dimensions of care with automated reasoning processes.\nTo achieve future advances, clinicians must be involved and engaged at the outset to",
    "page": 26
  },
  {
    "type": "text",
    "content": "ing processes.\nTo achieve future advances, clinicians must be involved and engaged at the outset to\nensure that systems are well-engineered and trusted. Already, a new generation of more\ntech savvy physicians routinely utilize specialized apps on mobile devices. At the same\ntime, workloads on primary care clinicians have increased to the point that they are\ngrateful for help from any quarter. Thus, the opportunity to exploit new learning methods,\nto create structured patterns of inference by mining the scientific literature automatically,\nand to create true cognitive assistants by supporting free-form dialogue, has never\nbeen greater. Provided these advances are not stymied by regulatory, legal, and social\nbarriers, immense improvements to the value of healthcare are within our grasp.",
    "page": 26
  },
  {
    "type": "text",
    "content": ", legal, and social\nbarriers, immense improvements to the value of healthcare are within our grasp.\nHealthcare analytics\nAt the population level, AI’s ability to mine outcomes from millions of patient clinical\nrecords promises to enable finer-grained, more personalized diagnosis and treatment.\nAutomated discovery of genotype-phenotype connections will also become possible\nas full, once-in-a-lifetime genome sequencing becomes routine for each patient.\nA related (and perhaps earlier) capability will be to find “patients like mine” as a way\nto inform treatment decisions based on analysis of a similar cohort. Traditional and\nnon-traditional healthcare data, augmented by social platforms, may lead to the emergence",
    "page": 26
  },
  {
    "type": "text",
    "content": "ional and\nnon-traditional healthcare data, augmented by social platforms, may lead to the emergence\nof self-defined subpopulations, each managed by a surrounding ecosystem of healthcare\nproviders augmented with automated recommendation and monitoring systems.\nThese developments have the potential to radically transform healthcare\n61 LeighAnne Olsen, Dara Aisner, and J. Michael McGinnis, eds., “Institute of Medicine\n(US) Roundtable on Evidence-Based Medicine,” The Learning Healthcare System: Workshop Summary.\n(Washington (DC): National Academies Press (US); 2007), accessed August 1, 2016, http://www.ncbi.\nnlm.nih.gov/books/NBK53500/.\n62 Katherine E. Henry, David N. Hager, Peter J. Pronovost, and Suchi Saria, “A Targeted Real-",
    "page": 26
  },
  {
    "type": "text",
    "content": "500/.\n62 Katherine E. Henry, David N. Hager, Peter J. Pronovost, and Suchi Saria, “A Targeted Real-\ntime Early Warning Score (TREWScore) for Septic Shock,” Science Translational Medicine 7, (299),\n26 299ra122.",
    "page": 26
  },
  {
    "type": "text",
    "content": "delivery as medical procedures and lifetime clinical records for hundreds of millions\nof individuals become available. Similarly, the automated capture of personal\nenvironmental data from wearable devices will expand personalized medicine. These\nactivities are becoming more commercially viable as vendors discover ways to engage\nlarge populations (e.g. ShareCare)63 and then to create population-scale data that can\nbe mined to produce individualized analytics and recommendations.\nUnfortunately, the FDA has been slow to approve innovative diagnostic software,\nand there are many remaining barriers to rapid innovation. HIPAA (Health Insurance\nA small group of companies\nPortability and Accountability Act) requirements for protecting patient privacy create",
    "page": 27
  },
  {
    "type": "text",
    "content": "of companies\nPortability and Accountability Act) requirements for protecting patient privacy create\nlegal barriers to the flow of patient data to applications that could utilize AI technologies.\ncontrol the EHR market,\nUnanticipated negative effects of approved drugs could show up routinely, sooner, and\nmore rigorously than they do today, but mobile apps that analyze drug interactions and user interfaces\nmay be blocked from pulling the necessary information from patient records. More\ngenerally, AI research and innovation in healthcare are hampered by the lack of are widely considered\nwidely accepted methods and standards for privacy protection. The FDA has been\nsubstandard, including\nslow to approve innovative software, in part due to an unclear understanding of the",
    "page": 27
  },
  {
    "type": "text",
    "content": "dard, including\nslow to approve innovative software, in part due to an unclear understanding of the\ncost/benefit tradeoffs of these systems. If regulators (principally the FDA) recognize\nannoying pop-ups that\nthat effective post-marketing reporting is a dependable hedge against some safety risks,\nfaster initial approval of new treatments and interventions may become possible. physicians routinely\nAutomated image interpretation has also been a promising subject of study for\ndismiss.\ndecades. Progress on interpreting large archives of weakly-labeled images, such as\nlarge photo archives scraped from the web, has been explosive. At first blush, it is\nsurprising that there has not been a similar revolution in interpretation of medical\nimages.",
    "page": 27
  },
  {
    "type": "text",
    "content": ", it is\nsurprising that there has not been a similar revolution in interpretation of medical\nimages. Most medical imaging modalities (CT, MR, ultrasound) are inherently digital,\nthe images are all archived, and there are large, established companies with internal\nR&D (e.g. Siemens, Philips, GE) devoted to imaging.\nBut several barriers have limited progress to date. Most hospital image archives\nhave only gone digital over the past decade. More importantly, the problem in\nmedicine is not to recognize what is in the image (is this a liver or a kidney?), but\nrather to make a fine-grained judgement about it (does the slightly darker smudge\nin the liver suggest a potentially cancerous tumor?). Strict regulations govern these\nhigh-stakes judgements.",
    "page": 27
  },
  {
    "type": "text",
    "content": "ver suggest a potentially cancerous tumor?). Strict regulations govern these\nhigh-stakes judgements. Even with state-of-the-art technologies, a radiologist will still\nlikely have to look at the images, so the value proposition is not yet compelling. Also,\nhealthcare regulations preclude easy federation of data across institutions. Thus, only\nvery large organizations of integrated care, such as Kaiser Permanente, are able to\nattack these problems.\nStill, automated/augmented image interpretation has started to gain momentum.\nThe next fifteen years will probably not bring fully automated radiology, but initial forays\ninto image “triage” or second level checking will likely improve the speed and cost-\neffectiveness of medical imaging. When coupled with electronic patient record systems,",
    "page": 27
  },
  {
    "type": "text",
    "content": "ed and cost-\neffectiveness of medical imaging. When coupled with electronic patient record systems,\nlarge-scale machine learning techniques could be applied to medical image data. For\nexample, multiple major healthcare systems have archives of millions of patient scans,\neach of which has an associated radiological report, and most have an associated\npatient record. Already, papers are appearing in the literature showing that deep neural\nnetworks can be trained to produce basic radiological findings, with high reliability,\nby training from this data.64\n63 Sharecare, accessed August 1, 2016, https://www.sharecare.com.\n64 Hoo-Chang Shin, Holger R. Roth, Mingchen Gao, Le Lu, Ziyue Xu, Isabella Nogues,\nJianhua Yao, Daniel Mollura, and Ronald M. Summers, “Deep Convolutional Neural Networks for",
    "page": 27
  },
  {
    "type": "text",
    "content": "Nogues,\nJianhua Yao, Daniel Mollura, and Ronald M. Summers, “Deep Convolutional Neural Networks for\nComputer-aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning,”\nIEEE Transactions on Medical Imaging 35, no. 5 (2016): 1285–1298. 27",
    "page": 27
  },
  {
    "type": "text",
    "content": "Healthcare robotics\nFifteen years ago, healthcare robotics was largely science fiction. One company\ncalled Robodoc,65 a spin-out from IBM, developed robotic systems for orthopedic\nsurgeries, such as hip and knee replacements. The technology worked, but the\ncompany struggled commercially, and was ultimately shut down and acquired for\nits technology.66 More recently, though, the research and practical use of surgical\nrobotics has exploded.\nIn 2000 Intuitive Surgical67 introduced the da Vinci system, a novel technology\nThe problem in medicine\ninitially marketed to support minimally invasive heart bypass surgery, and then gained\nsubstantial market traction for treatment of prostate cancer and merged with its\nis not to recognize what is\nonly major competition, Computer Motion, in 2003.",
    "page": 28
  },
  {
    "type": "text",
    "content": "er and merged with its\nis not to recognize what is\nonly major competition, Computer Motion, in 2003. The da Vinci, now in its fourth\nin the image—is this a liver generation, provides 3D visualization (as opposed to 2D monocular laparoscopy) and\nwristed instruments in an ergonomic platform. It is considered the standard of care\nor a kidney?—but rather\nin multiple laparoscopic procedures, and used in nearly three quarters of a million\nprocedures a year,68 providing not only a physical platform, but also a new data\nto make a fine-grained\nplatform for studying the process of surgery.\njudgement about it. Strict The da Vinci anticipates a day when much greater insight into how medical\nprofessionals carry out the process of providing interventional medical care will",
    "page": 28
  },
  {
    "type": "text",
    "content": "into how medical\nprofessionals carry out the process of providing interventional medical care will\nregulations govern these be possible. The presence of the da Vinci in day-to-day operation has also opened\nthe doors to new types of innovation—from new instrumentation to image fusion\nhigh-stakes judgements.\nto novel biomarkers—creating its own innovation ecosystem. The success of the\nplatform has inspired potential competitors in robotic surgery, most notably the\nAlphabet spin-off Verb, in collaboration with J&J/Ethicon.69 There are likely to be\nmany more, each exploring a unique niche or space and building out an ecosystem of\nsensing, data analytics, augmentation, and automation.\nIntelligent automation in hospital operations has been less successful. The story",
    "page": 28
  },
  {
    "type": "text",
    "content": ", and automation.\nIntelligent automation in hospital operations has been less successful. The story\nis not unlike surgical robotics. Twenty years ago, one company, HelpMate, created\na robot for hospital deliveries,70 such as meals and medical records, but ultimately\nwent bankrupt. More recently, Aethon71 introduced TUG Robots for basic deliveries,\nbut few hospitals have invested in this technology to date. However, robotics in\nother service industries such as hotels and warehouses, including Amazon Robotics\n(formerly Kiva), are demonstrating that these technologies are practical and cost\neffective in at least some large-scale settings, and may ultimately spur additional\ninnovation in health care.\nLooking ahead, many tasks that appear in healthcare will be amenable to",
    "page": 28
  },
  {
    "type": "text",
    "content": "innovation in health care.\nLooking ahead, many tasks that appear in healthcare will be amenable to\naugmentation, but will not be fully automated. For example, robots may be able to\ndeliver goods to the right room in a hospital, but then require a person to pick them\nup and place them in their final location. Walking a patient down the corridor may\n65 ROBODOC, accessed August 1, 2016, http://www.robodoc.com/professionals.html.\n66 THINK Surgical, accessed August 1, 2016, http://thinksurgical.com/history.\n67 Intuitive Surgical, accessed August 1, 2016, http://www.intuitivesurgical.com.\n68 Trefis Team, “Intuitive Surgical Maintains Its Growth Momentum With Strong Growth In\nProcedure Volumes,” Forbes, January 22, 2016, accessed August 1, 2016, http://www.forbes.com/",
    "page": 28
  },
  {
    "type": "text",
    "content": "th In\nProcedure Volumes,” Forbes, January 22, 2016, accessed August 1, 2016, http://www.forbes.com/\nsites/greatspeculations/2016/01/22/intuitive-surgical-maintains-its-growth-momentum-with-\nstrong-growth-in-procedure-volumes/#22ae6b0939a1.\n69 Evan Ackerman, “Google and Johnson & Johnson Conjugate to Create Verb Surgical,\nPromise Fancy Medical Robots,” IEEE Spectrum, December 17, 2015, accessed August 1, 2016,\nhttp://spectrum.ieee.org/automaton/robotics/medical-robots/google-verily-johnson-johnson-\nverb-surgical-medical-robots.\n70 John M. Evans and Bala Krishnamurthy, “HelpMate®, the trackless robotic courier: A\nperspective on the development of a commercial autonomous mobile robot,” Lecture Notes in Control",
    "page": 28
  },
  {
    "type": "text",
    "content": "A\nperspective on the development of a commercial autonomous mobile robot,” Lecture Notes in Control\nand Information Sciences 236, June 18, 2005 (Springer-Verlag London Limited, 1998), 182–210,\naccessed August 1, 2016, http://link.springer.com/chapter/10.1007%2FBFb0030806.\n28 71 Aethon, accessed August 1, 2016, http://www.aethon.com.",
    "page": 28
  },
  {
    "type": "text",
    "content": "be relatively simple once a patient is standing in a walker (though will certainly not\nbe trivial for patients recovering from surgery and/or elderly patients, especially in\ncorridors crowded with equipment and other people). Driving a needle to place a\nsuture is relatively straightforward once the needle is correctly placed.72 This implies\nthat many future systems will involve intimate interaction between people and\nmachines and require technologies that facilitate collaboration between them.\nThe growth of automation will enable new insights into healthcare processes.\nHistorically, robotics has not been a strongly data-driven or data-oriented science.\nSpecialized motion\nThis is changing as (semi)automation infiltrates healthcare. As the new surgical,",
    "page": 29
  },
  {
    "type": "text",
    "content": "pecialized motion\nThis is changing as (semi)automation infiltrates healthcare. As the new surgical,\ndelivery, and patient care platforms come online, the beginnings of quantification\ntracking devices... and\nand predictive analytics are being built on top of data coming from these platforms.73\nThis data will be used to assess quality of performance, identify deficiencies, errors, the emerging (inter)\nor potential optimizations, and will be used as feedback to improve performance. In\nshort, these platforms will facilitate making the connection between what is done, and connectedness between\nthe outcome achieved, making true “closed-loop” medicine a real possibility.\nthe home environment and\nMobile health\nhealth-monitoring devices",
    "page": 29
  },
  {
    "type": "text",
    "content": "loop” medicine a real possibility.\nthe home environment and\nMobile health\nhealth-monitoring devices\nTo date, evidence-driven analytics on healthcare have relied on traditional healthcare\ndata—mainly the electronic medical records discussed above. In the clinical setting, have created a vibrant new\nthere are hopeful trends towards bringing new data to bear. For example, Tele-\nsector of innovation.\nLanguage enables a human clinician to conduct language therapy sessions with\nmultiple patients simultaneously with the aid of an AI agent trained by the clinician.\nAnd Lifegraph, which extracts behavioral patterns and creates alerts from data\npassively collected from a patient’s smartphone, has been adopted by psychiatrists in\nIsrael to detect early signs of distressful behavior in patients.",
    "page": 29
  },
  {
    "type": "text",
    "content": "been adopted by psychiatrists in\nIsrael to detect early signs of distressful behavior in patients.\nLooking ahead, driven by the mobile computing revolution, the astonishing growth\nof “biometrics in the wild”—and the explosion of platforms and applications that use\nthem—is a hopeful and unanticipated trend. Thousands of mobile apps now offer\ninformation, introduce behavior modification, or identify groups of “people like me.”\nThis, combined with the emerging trend of more specialized motion tracking devices,\nsuch as Fitbit, and the emerging (inter)connectedness between the home environment\nand health-monitoring devices, has created a vibrant new sector of innovation.\nBy combining social and healthcare data, some healthcare apps can perform data",
    "page": 29
  },
  {
    "type": "text",
    "content": "ector of innovation.\nBy combining social and healthcare data, some healthcare apps can perform data\nmining, learning, and prediction from captured data, though their predictions are\nrelatively rudimentary. The convergence of data and functionality across applications\nwill likely spur new and even obvious products, such as an exercise app that not only\nproposes a schedule for exercise but also suggests the best time to do it, and provides\ncoaching to stick to that schedule.\n72 Azad Shademan, Ryan S. Decker, Justin D. Opfermann, Simon Leonard, Axel Krieger, and\nPeter CW Kim, “Supervised Autonomous Robotic Soft Tissue Surgery,” Science Translational Medicine\n8, no. 337 (2016): 337ra64–337ra64.\n73 Carolyn Chen, Lee White, Timothy Kowalewski, Rajesh Aggarwal, Chris Lintott, Bryan",
    "page": 29
  },
  {
    "type": "text",
    "content": "ra64–337ra64.\n73 Carolyn Chen, Lee White, Timothy Kowalewski, Rajesh Aggarwal, Chris Lintott, Bryan\nComstock, Katie Kuksenok, Cecilia Aragon, Daniel Holst, and Thomas Lendvay, “Crowd-Sourced\nAssessment of Technical Skills: a novel method to evaluate surgical performance.” Journal of Surgical\nResearch 187, no. 1 (2014): 65–71.\n29",
    "page": 29
  },
  {
    "type": "text",
    "content": "Elder care\nOver the next fifteen years the number of elderly in the United States will grow\nby over 50%.74 The National Bureau of Labor Statistics projects that home health\naides will grow 38% over the next ten years. Despite the broad opportunities in this\ndomain—basic social support, interaction and communication devices, home health\nmonitoring, a variety of simple in-home physical aids such as walkers, and light meal\npreparation—little has happened over the past fifteen years. But the coming generational\nshift will accompany a change in technology acceptance among the elderly. Currently,\nBetter hearing aids and\nsomeone who is seventy was born in 1946 and may have first experienced some form\nof personalized IT in middle age or later, while a fifty-year-old today is far more",
    "page": 30
  },
  {
    "type": "text",
    "content": "enced some form\nof personalized IT in middle age or later, while a fifty-year-old today is far more\nvisual assistive devices\ntechnology-friendly and savvy. As a result, there will be a growing interest and market\nwill mitigate the effects for already available and maturing technologies to support physical, emotional, social,\nand mental health. Here are a few likely examples by category:\nof hearing and vision\nLife quality and independence\n• Automated transportation will support continued independence and expanded\nloss, improving safety\nsocial horizons.\nand social connection. • Sharing of information will help families remain engaged with one another at a\ndistance, and predictive analytics may be used to “nudge” family groups toward",
    "page": 30
  },
  {
    "type": "text",
    "content": "ith one another at a\ndistance, and predictive analytics may be used to “nudge” family groups toward\nPersonalized rehabilitation positive behaviors, such as reminders to “call home.”\n• Smart devices in the home will help with daily living activities when needed,\nand in-home therapy\nsuch as cooking and, if robot manipulation capabilities improve sufficiently,\ndressing and toileting.\nwill reduce the need for\nHealth and wellness\nhospital stays. • Mobile applications that monitor movement and activities, coupled with social\nplatforms, will be able to make recommendations to maintain mental and\nphysical health.\n• In-home health monitoring and health information access will be able to detect\nchanges in mood or behavior and alert caregivers.",
    "page": 30
  },
  {
    "type": "text",
    "content": "health information access will be able to detect\nchanges in mood or behavior and alert caregivers.\n• Personalized health management will help mitigate the complexities associated\nwith multiple co-morbid conditions and/or treatment interactions.\nTreatments and devices\n• Better hearing aids and visual assistive devices will mitigate the effects of\nhearing and vision loss, improving safety and social connection.\n• Personalized rehabilitation and in-home therapy will reduce the need for\nhospital or care facility stays.\n• Physical assistive devices (intelligent walkers, wheel chairs, and exoskeletons) will\nextend the range of activities of an infirm individual.\nThe Study Panel expects an explosion of low-cost sensing technologies that can",
    "page": 30
  },
  {
    "type": "text",
    "content": "n infirm individual.\nThe Study Panel expects an explosion of low-cost sensing technologies that can\nprovide substantial capabilities to the elderly in their homes. In principle, social\nagents with a physical presence and simple physical capabilities (e.g. a mobile robot\nwith basic communication capabilities) could provide a platform for new innovations.\nHowever, doing so will require integration across multiple areas of AI—Natural\nLanguage Processing, reasoning, learning, perception, and robotics—to create\na system that is useful and usable by the elderly.\nThese innovations will also introduce questions regarding privacy within various\ncircles, including friends, family, and care-givers, and create new challenges to\naccommodate an evermore active and engaged population far past retirement.",
    "page": 30
  },
  {
    "type": "text",
    "content": "create new challenges to\naccommodate an evermore active and engaged population far past retirement.\n74 Jennifer M. Ortman, Victoria A. Velkoff, and Howard Hogan, “An Aging Nation: The\nOlder Population in the United States: Population Estimates and Projections,” Current Population\nReports, U.S Census Bureau (May 2014), accessed August 1, 2016, https://www.census.gov/\nprod/2014pubs/p25-1140.pdf.\n30",
    "page": 30
  },
  {
    "type": "text",
    "content": "EDUCATION\nThe past fifteen years have seen considerable AI advances in education. Applications\nare in wide use by educators and learners today, with some variation between K-12\nand university settings. Though quality education will always require active engagement\nby human teachers, AI promises to enhance education at all levels, especially by\nproviding personalization at scale. Similar to healthcare, resolving how to best\nintegrate human interaction and face-to-face learning with promising AI technologies\nremains a key challenge. Though quality education\nRobots have long been popular educational devices, starting with the early\nLego Mindstorms kits developed with the MIT Media Lab in the 1980s. Intelligent will always require active",
    "page": 31
  },
  {
    "type": "text",
    "content": "ndstorms kits developed with the MIT Media Lab in the 1980s. Intelligent will always require active\nTutoring Systems (ITS) for science, math, language, and other disciplines match\nengagement by human\nstudents with interactive machine tutors. Natural Language Processing, especially when\ncombined with machine learning and crowdsourcing, has boosted online learning\nteachers, AI promises to\nand enabled teachers to multiply the size of their classrooms while simultaneously\naddressing individual students’ learning needs and styles. The data sets from large enhance education at\nonline learning systems have fueled rapid growth in learning analytics.\nall levels, especially by\nStill, schools and universities have been slow in adopting AI technologies primarily",
    "page": 31
  },
  {
    "type": "text",
    "content": "especially by\nStill, schools and universities have been slow in adopting AI technologies primarily\ndue to lack of funds and lack of solid evidence that they help students achieve\nproviding personalization\nlearning objectives. Over the next fifteen years in a typical North American city, the\nuse of intelligent tutors and other AI technologies to assist teachers in the classroom at scale.\nand in the home is likely to expand significantly, as will learning based on virtual\nreality applications. But computer-based learning systems are not likely to fully\nreplace human teaching in schools.\nTeaching robots\nToday, more sophisticated and versatile kits for use in K-12 schools are available\nfrom a number of companies that create robots with new sensing technologies",
    "page": 31
  },
  {
    "type": "text",
    "content": "2 schools are available\nfrom a number of companies that create robots with new sensing technologies\nprogrammable in a variety of languages. Ozobot is a robot that teaches children\nto code and reason deductively while configuring it to dance or play based on\ncolor-coded patterns.75 Cubelets help teach children logical thinking through\nassembling robot blocks to think, act, or sense, depending upon the function of the\ndifferent blocks.76 Wonder Workshop’s Dash and Dot span a range of programming\ncapabilities. Children eight years old and older can create simple actions using a\nvisual programming language, Blockly, or build iOS and Android applications using\nC or Java.77 PLEO rb is a robot pet that helps children learn biology by teaching",
    "page": 31
  },
  {
    "type": "text",
    "content": "pplications using\nC or Java.77 PLEO rb is a robot pet that helps children learn biology by teaching\nthe robot to react to different aspects of the environment.78 However, while fun and\nengaging for some, in order for such kits to become widespread, there will need to be\ncompelling evidence that they improve students’ academic performance.\nIntelligent Tutoring Systems (ITS) and online learning\nITS have been developed from research laboratory projects such as Why-2 Atlas,\nwhich supported human-machine dialogue to solve physics problems early in the\nera.79 The rapid migration of ITS from laboratory experimental stages to real use is\n75 Ozobot, accessed August 1, 2016, http://ozobot.com/.\n76 “Cubelets,” Modular Robotics, accessed August 1, 2016, http://www.modrobotics.com/\ncubelets.",
    "page": 31
  },
  {
    "type": "text",
    "content": "m/.\n76 “Cubelets,” Modular Robotics, accessed August 1, 2016, http://www.modrobotics.com/\ncubelets.\n77 “Meet Dash,” Wonder Workshop, accessed August 1, 2016, https://www.makewonder.com/\ndash.\n78 “Pleo rb,” Innvo Labs, accessed August 1, 2016, http://www.pleoworld.com/pleo_rb/eng/\nlifeform.php.\n79 Kurt VanLehn, Pamela W. Jordan, Carolyn P. Rosé, Dumisizwe Bhembe, Michael Böttner,\nAndy Gaydos, Maxim Makatchev, Umarani Pappuswamy, Michael Ringenberg, Antonio Roque,\nStephanie Siler, and Ramesh Srivastava, “The Architecture of Why2-Atlas: A Coach for Qualitative 31",
    "page": 31
  },
  {
    "type": "text",
    "content": "surprising and welcome. Downloadable software and online systems such as Carnegie\nSpeech or Duolingo provide foreign language training using Automatic Speech\nRecognition (ASR) and NLP techniques to recognize language errors and help users\ncorrect them.80 Tutoring systems such as the Carnegie Cognitive Tutor81 have been\nused in US high schools to help students learn mathematics. Other ITS have been\ndeveloped for training in geography, circuits, medical diagnosis, computer literacy\nand programming, genetics, and chemistry. Cognitive tutors use software to mimic\nthe role of a good human tutor by, for example, providing hints when a student gets\nIt can be argued that AI\nstuck on a math problem. Based on the hint requested and the answer provided, the\ntutor offers context specific feedback.",
    "page": 32
  },
  {
    "type": "text",
    "content": "m. Based on the hint requested and the answer provided, the\ntutor offers context specific feedback.\nis the secret sauce that\nApplications are growing in higher education. An ITS called SHERLOCK82 is\nhas enabled instructors, beginning to be used to teach Air Force technicians to diagnose electrical systems\nproblems in aircraft. And the University of Southern California’s Information\nparticularly in higher Sciences Institute has developed more advanced avatar-based training modules to\ntrain military personnel being sent to international posts in appropriate behavior\neducation, to multiply the\nwhen dealing with people from different cultural backgrounds. New algorithms for\npersonalized tutoring, such as Bayesian Knowledge Tracing, enable individualized\nsize of their classrooms",
    "page": 32
  },
  {
    "type": "text",
    "content": "alized tutoring, such as Bayesian Knowledge Tracing, enable individualized\nsize of their classrooms\nmastery learning and problem sequencing.83\nby a few orders of Most surprising has been the explosion of the Massive Open Online Courses\n(MOOCs) and other models of online education at all levels—including the use\nmagnitude—class sizes of\nof tools like Wikipedia and Khan Academy as well as sophisticated learning\nmanagement systems that build in synchronous as well as asynchronous education\na few tens of thousands\nand adaptive learning tools. Since the late 1990s, companies such as the Educational\nare not uncommon. Testing Service and Pearson have been developing automatic NLP assessment tools to\nco-grade essays in standardized testing.84 Many of the MOOCs which have become",
    "page": 32
  },
  {
    "type": "text",
    "content": "assessment tools to\nco-grade essays in standardized testing.84 Many of the MOOCs which have become\nso popular, including those created by EdX, Coursera, and Udacity, are making use\nof NLP, machine learning, and crowdsourcing techniques for grading short-answer\nand essay questions as well as programming assignments.85 Online education systems\nthat support graduate-level professional education and lifelong learning are also\nexpanding rapidly. These systems have great promise because the need for face-to-face\ninteraction is less important for working professionals and career changers. While not\nthe leaders in AI-supported systems and applications, they will become early adopters\nas the technologies are tested and validated.",
    "page": 32
  },
  {
    "type": "text",
    "content": "ems and applications, they will become early adopters\nas the technologies are tested and validated.\nIt can be argued that AI is the secret sauce that has enabled instructors, particularly\nin higher education, to multiply the size of their classrooms by a few orders of\nmagnitude—class sizes of a few tens of thousands are not uncommon. In order to\ncontinually test large classes of students, automated generation of the questions is\nPhysics Essay Writing,” Intelligent Tutoring Systems: Proceedings of the 6th International Conference, (Springer\nBerlin Heidelberg, 2002), 158–167.\n80 VanLehn et al, “The Architecture of Why2-Atlas.”\n81 “Resources and Support,” Carnegie Learning, accessed August 1, 2016, https://www.\ncarnegielearning.com/resources-support/.",
    "page": 32
  },
  {
    "type": "text",
    "content": "” Carnegie Learning, accessed August 1, 2016, https://www.\ncarnegielearning.com/resources-support/.\n82 Alan Lesgold, Suzanne Lajoie, Marilyn Bunzo, and Gary Eggan, “SHERLOCK: A Coached\nPractice Environment for an Electronics Troubleshooting Job,” in J. H. Larkin and R. W. Chabay,\neds., Computer-Assisted Instruction and Intelligent Tutoring Systems: Shared Goals and Complementary Approaches\n(Hillsdale, New Jersey: Lawrence Erlbaum Associates, 1988).\n83 Michael V. Yudelson, Kenneth R. Koedinger, and Geoffrey J. Gordon, (2013). “ Individualized\nBayesian Knowledge Tracing Models,” Artificial Intelligence in Education, (Springer Berlin Heidelberg,\n2013), 171–180.\n84 Jill Burstein, Karen Kukich, Susanne Wolff, Chi Lu, Martin Chodorow, Lisa Braden-Harder,",
    "page": 32
  },
  {
    "type": "text",
    "content": "71–180.\n84 Jill Burstein, Karen Kukich, Susanne Wolff, Chi Lu, Martin Chodorow, Lisa Braden-Harder,\nand Mary Dee Harris, “Automated Scoring Using a Hybrid Feature Identification Technique” in\nProceedings of the Annual Meeting of the Association of Computational Linguistics, Montreal, Canada, August\n1998, accessed August 1, 2016, https://www.ets.org/Media/Research/pdf/erater_acl98.pdf.\n85 EdX, https://www.edx.org/, Coursera, https://www.coursera.org/, Udacity, https://www.\n32 udacity.com/, all accessed August 1, 2016.",
    "page": 32
  },
  {
    "type": "text",
    "content": "also possible, such as those designed to assess vocabulary,86 wh (who/what/when/\nwhere/why) questions,87 and multiple choice questions,88 using electronic resources\nsuch as WordNet, Wikipedia, and online ontologies. With the explosion of online\ncourses, these techniques are sure to be eagerly adopted for use in online education.\nAlthough the long term impact of these systems will have on the educational system\nremains unclear, the AI community has learned a great deal in a very short time.\nLearning analytics\nThe current absence of\nData sets being collected from massive scale online learning systems, ranging from\nMOOCs to Khan Academy, as well as smaller scale online programs, have fueled\nsophisticated use of AI\nthe rapid growth of the field of learning analytics.",
    "page": 33
  },
  {
    "type": "text",
    "content": "e programs, have fueled\nsophisticated use of AI\nthe rapid growth of the field of learning analytics. Online courses are not only good\nfor widespread delivery, but are natural vehicles for data collection and experimental technologies in schools,\ninstrumentation that will contribute to scientific findings and improving the quality\nof learning at scale. Organizations such as the Society for Learning Analytics colleges, and universities\nResearch (SOLAR), and the rise of conferences including the Learning Analytics and\nmay be explained by\nKnowledge Conference89 and the Learning at Scale Conference (L@S)90 reflect this\ntrend. This community applies deep learning, natural language processing, and other\nthe lack of financial\nAI techniques to analysis of student engagement, behavior, and outcomes.",
    "page": 33
  },
  {
    "type": "text",
    "content": "other\nthe lack of financial\nAI techniques to analysis of student engagement, behavior, and outcomes.\nCurrent projects seek to model common student misconceptions, predict resources as well as the\nwhich students are at risk of failure, and provide real-time student feedback that is\nlack of data establishing\ntightly integrated with learning outcomes. Recent work has also been devoted to\nunderstanding the cognitive processes involved in comprehension, writing, knowledge\nthe technologies’\nacquisition, and memory, and to applying that understanding to educational practice\nby developing and testing educational technologies. effectiveness.\nChallenges and opportunities\nOne might have expected more and more sophisticated use of AI technologies in\nschools, colleges, and universities by now.",
    "page": 33
  },
  {
    "type": "text",
    "content": "ed more and more sophisticated use of AI technologies in\nschools, colleges, and universities by now. Much of its absence can be explained\nby the lack of financial resources of these institutions as well as the lack of data\nestablishing the technologies’ effectiveness. These problems are being addressed,\nalbeit slowly, by private foundations and by numerous programs to train primarily\nsecondary school teachers in summer programs. As in other areas of AI, excessive\nhype and promises about the capabilities of MOOCs have meant that expectations\nfrequently exceed the reality. The experiences of certain institutions, such as San Jose\nState University’s experiment with Udacity,91 have led to more sober assessment of\nthe potential of the new educational technologies.\n86 Jonathan C. Brown, Gwen A.",
    "page": 33
  },
  {
    "type": "text",
    "content": "sober assessment of\nthe potential of the new educational technologies.\n86 Jonathan C. Brown, Gwen A. Frishkoff , and Maxine Eskenazi, “Automatic Question\nGeneration for Vocabulary Assessment,” Proceedings of Human Language Technology Conference and\nConference on Empirical Methods in Natural Language Processing (HLT/EMNLP), Vancouver, October\n2005, (Association for Computational Linguistics, 2005), 819–826.\n87 Michael Heilman, “Automatic Factual Question Generation from Text,” PhD thesis CMU-\nLTI-11-004, (Carnegie Mellon University, 2011), accessed August 1, 2016, http://www.cs.cmu.\nedu/~ark/mheilman/questions/papers/heilman-question-generation-dissertation.pdf.\n88 Tahani Alsubait, Bijan Parsia, and Uli Sattler, “Generating Multiple Choice Questions from",
    "page": 33
  },
  {
    "type": "text",
    "content": ".pdf.\n88 Tahani Alsubait, Bijan Parsia, and Uli Sattler, “Generating Multiple Choice Questions from\nOntologies: How Far Can We Go?,” in eds. P. Lambrix, E. Hyvönen. E. Blomqvist, V. Presutti, G.\nQi, U. Sattler, Y. Ding, and C. Ghidini, Knowledge Engineering and Knowledge Management: EKAW 2014\nSatellite Events, VISUAL, EKM1, and ARCOE-Logic Linköping, Sweden, November 24–28, 2014 Revised\nSelected Papers, (Switzerland: Springer International Publishing, 2015), 66–79.\n89 The 6th International Learning Analytics & Knowledge Conference, accessed August 1, 2016,\nhttp://lak16.solaresearch.org/.\n90 Third Annual ACM Conference on Learning at Scale, http://learningatscale.acm.org/\nlas2016/.\n91 Ry Rivard, “Udacity Project on ‘Pause’,” Inside Higher Ed, July 18, 2013, accessed August 1,",
    "page": 33
  },
  {
    "type": "text",
    "content": "6/.\n91 Ry Rivard, “Udacity Project on ‘Pause’,” Inside Higher Ed, July 18, 2013, accessed August 1,\n2016, https://www.insidehighered.com/news/2013/07/18/citing-disappointing-student-outcomes-\nsan-jose-state-pauses-work-udacity. 33",
    "page": 33
  },
  {
    "type": "text",
    "content": "In the next fifteen years, it is likely that human teachers will be assisted by AI\ntechnologies with better human interaction, both in the classroom and in the home.\nThe Study Panel expects that more general and more sophisticated virtual reality\nscenarios in which students can immerse themselves in subjects from all disciplines\nwill be developed. Some steps in this direction are being taken now by increasing\ncollaborations between AI researchers and researchers in the humanities and social\nsciences, exemplified by Stanford’s Galileo Correspondence Project92 and Columbia’s\nMaking and Knowing Project.93 These interdisciplinary efforts create interactive\nWhile formal education\nexperiences with historical documents and the use of Virtual Reality (VR) to explore",
    "page": 34
  },
  {
    "type": "text",
    "content": "rmal education\nexperiences with historical documents and the use of Virtual Reality (VR) to explore\ninteractive archeological sites.94 VR techniques are already being used in the natural\nwill not disappear, the\nsciences such as biology, anatomy, geology and astronomy to allow students to interact\nStudy Panel believes that with environments and objects that are difficult to engage with in the real world. The\nrecreation of past worlds and fictional worlds will become just as popular for studies\nMOOCs and other forms\nof arts and other sciences.\nAI techniques will increasingly blur the line between formal, classroom education\nof online education will\nand self-paced, individual learning. Adaptive learning systems, for example, are going",
    "page": 34
  },
  {
    "type": "text",
    "content": "ucation will\nand self-paced, individual learning. Adaptive learning systems, for example, are going\nbecome part of learning to become a core part of the teaching process in higher education because of the\npressures to contain cost while serving a larger number of students and moving students\nat all levels, from K-12 through school more quickly. While formal education will not disappear, the Study\nPanel believes that MOOCs and other forms of online education will become part of\nthrough university, in\nlearning at all levels, from K-12 through university, in a blended classroom experience.\nThis development will facilitate more customizable approaches to learning, in which\na blended classroom\nstudents can learn at their own pace using educational techniques that work best for\nexperience. them.",
    "page": 34
  },
  {
    "type": "text",
    "content": "udents can learn at their own pace using educational techniques that work best for\nexperience. them. Online education systems will learn as the students learn, supporting rapid\nadvances in our understanding of the learning process. Learning analytics, in turn, will\naccelerate the development of tools for personalized education.\nThe current transition from hard copy books to digital and audio media and texts\nis likely to become prevalent in education as well. Digital reading devices will also\nbecome much ‘smarter’, providing students with easy access to additional information\nabout subject matter as they study. Machine Translation (MT) technology will\nalso make it easier to translate educational material into different languages with a",
    "page": 34
  },
  {
    "type": "text",
    "content": "chnology will\nalso make it easier to translate educational material into different languages with a\nfair degree of accuracy, just as it currently translates technical manuals. Textbook\ntranslation services that currently depend only upon human translators will\nincreasingly incorporate automatic methods to improve the speed and affordability of\ntheir services for school systems.\nOnline learning systems will also expand the opportunity for adults and working\nprofessionals to enhance their knowledge and skills (or to retool and learn a new field)\nin a world where these fields are evolving rapidly. This will include the expansion\nof fully online professional degrees as well as professional certifications based on\nonline coursework.\nBroader societal consequences",
    "page": 34
  },
  {
    "type": "text",
    "content": "es as well as professional certifications based on\nonline coursework.\nBroader societal consequences\nIn countries where education is difficult for the broad population to obtain, online\nresources may have a positive effect if the population has the tools to access them.\nThe development of online educational resources should make it easier for\nfoundations that support international educational programs to provide quality\n92 Stanford University: Galileo Correspondence Project, accessed August 1, 2016, http://galileo.\nstanford.edu.\n93 The Making and Knowing Project: Reconstructing the 16th Century Workshop of BNF MS.\nFR. 640 at Columbia University, accessed August 1, 2016, http://www.makingandknowing.org.\n94 Paul James, “3D Mapped HTC Vive Demo Brings Archaeology to Life,” Road to VR, August",
    "page": 34
  },
  {
    "type": "text",
    "content": "nowing.org.\n94 Paul James, “3D Mapped HTC Vive Demo Brings Archaeology to Life,” Road to VR, August\n31, 2015, accessed August 1, 2016, http://www.roadtovr.com/3d-mapped-htc-vive-demo-brings-\n34 archaeology-to-life/.",
    "page": 34
  },
  {
    "type": "text",
    "content": "education by providing tools and relatively simple amounts of training in their use.\nFor example, large numbers of educational apps, many of them free, are being\ndeveloped for the iPad. On the negative side, there is already a major trend among\nstudents to restrict their social contacts to electronic ones and to spend large amounts\nof time without social contact, interacting with online programs. If education also\noccurs more and more online, what effect will the lack of regular, face-to-face contact\nwith peers have on students’ social development? Certain technologies have even\nbeen shown to create neurological side effects.95 On the other hand, autistic children\nWith targeted incentives\nhave benefited from interactions with AI systems already.96\nand funding priorities, AI",
    "page": 35
  },
  {
    "type": "text",
    "content": "d incentives\nhave benefited from interactions with AI systems already.96\nand funding priorities, AI\nLOW-RESOURCE COMMUNITIES\ntechnologies could help\nMany opportunities exist for AI to improve conditions for people in low-resource\ncommunities in a typical North American city—and, indeed, in some cases it address the needs of low-\nalready has. Understanding these direct AI contributions may also inform potential\ncontributions in the poorest parts of the developing world. There has not been a resource communities.\nsignificant focus on these populations in AI gatherings, and, traditionally, AI funders\nBudding efforts are\nhave underinvested in research lacking commercial application. With targeted incentives\nand funding priorities, AI technologies could help address the needs of low-resource",
    "page": 35
  },
  {
    "type": "text",
    "content": "ted incentives\nand funding priorities, AI technologies could help address the needs of low-resource\npromising.\ncommunities. Budding efforts are promising. Counteracting fears that AI may contribute\nto joblessness and other societal problems, AI may provide mitigations and solutions,\nparticularly if implemented in ways that build trust in them by the affected communities.\nMachine learning, data mining approaches\nUnder the banner of “data science for social good,” AI has been used to create\npredictive models to help government agencies more effectively use their limited\nbudgets to address problems such as lead poisoning,97 a major public health concern\nthat has been in the news due to ongoing events in Flint, Michigan. Children may",
    "page": 35
  },
  {
    "type": "text",
    "content": "lic health concern\nthat has been in the news due to ongoing events in Flint, Michigan. Children may\nbe tested for elevated lead levels, but that unfortunately means the problem is only\ndetected after they have already been poisoned. Many efforts are underway to use\npredictive models to assist government agencies in prioritizing children at\nrisk, including those who may not yet have been exposed.98 Similarly, the Illinois\nDepartment of Human Services (IDHS) uses predictive models to identify pregnant\nwomen at risk for adverse birth outcomes in order to maximize the impact of\nprenatal care. The City of Cincinnati uses them to proactively identify and deploy\ninspectors to properties at risk of code violations.\nScheduling, planning",
    "page": 35
  },
  {
    "type": "text",
    "content": "ively identify and deploy\ninspectors to properties at risk of code violations.\nScheduling, planning\nTask assignment scheduling and planning techniques have been applied by many\ndifferent groups to distribute food before it spoils from those who may have excess,\nsuch as restaurants, to food banks, community centers and individuals.99\n95 Scientist have studied, for example, the way reliance on GPS may lead to changes in the\nhippocampus. Kim Tingley, “The Secrets of the Wave Pilots,” The New York Times, March 17, 2016,\naccessed August 1, 2016, http://www.nytimes.com/2016/03/20/magazine/the-secrets-of-the-wave-\npilots.html.\n96 Judith Newman, “To Siri, With Love: How One Boy With Autism Became BFF With Apple’s\nSiri,” The New York Times, October 17, 2014, accessed August 1, 2016, http://www.",
    "page": 35
  },
  {
    "type": "text",
    "content": "e BFF With Apple’s\nSiri,” The New York Times, October 17, 2014, accessed August 1, 2016, http://www.nytimes.\ncom/2014/10/19/fashion/how-apples-siri-became-one-autistic-boys-bff.html.\n97 Eric Potash, Joe Brew, Alexander Loewi, Subhabrata Majumdar, Andrew Reece, Joe Walsh,\nEric Rozier, Emile Jorgensen, Raed Mansour, and Rayid Ghani, “Predictive Modeling for Public\nHealth: Preventing Childhood Lead Poisoning,” Proceedings of the 21th ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining (New York: Association for Computing Machinery,\n2015), 2039–2047.\n98 Data Science for Social Good, University of Chicago, accessed August 1, 2016,\nhttp://dssg.uchicago.edu/.\n99 Senay Solak, Christina Scherrer, and Ahmed Ghoniem, “The Stop-and-Drop Problem in",
    "page": 35
  },
  {
    "type": "text",
    "content": "uchicago.edu/.\n99 Senay Solak, Christina Scherrer, and Ahmed Ghoniem, “The Stop-and-Drop Problem in\nNonprofit Food Distribution Networks,” Annals of Operations Research 221, no. 1 (October 2014): 35",
    "page": 35
  },
  {
    "type": "text",
    "content": "Reasoning with social networks and influence maximization\nSocial networks can be harnessed to create earlier, less-costly interventions involving\nlarge populations. For example, AI might be able to assist in spreading health-\nrelated information. In Los Angeles, there are more than 5,000 homeless youth (ages\nthirteen-twenty-four). Individual interventions are difficult and expensive, and the\nyouths’ mistrust of authority dictates that key messages are best spread through peer\nleaders. AI programs might be able to leverage homeless youth social networks to\nOne of the more successful strategically select peer leaders to spread health-related information, such as how to\navoid spread of HIV. The dynamic, uncertain nature of these networks does pose\nuses of AI analytics is in",
    "page": 36
  },
  {
    "type": "text",
    "content": "spread of HIV. The dynamic, uncertain nature of these networks does pose\nuses of AI analytics is in\nchallenges for AI research.100 Care must also be taken to prevent AI systems from\nreproducing discriminatory behavior, such as machine learning that identifies people\ndetecting white collar\nthrough illegal racial indicators, or through highly-correlated surrogate factors, such\ncrime, such as credit as zip codes. But if deployed with great care, greater reliance on AI may well result\nin a reduction in discrimination overall, since AI programs are inherently more easily\ncard fraud. Cybersecurity\naudited than humans.\n(including spam) is a\nPUBLIC SAFETY AND SECURITY\nwidely shared concern,\nCities already have begun to deploy AI technologies for public safety and security.",
    "page": 36
  },
  {
    "type": "text",
    "content": "shared concern,\nCities already have begun to deploy AI technologies for public safety and security.\nBy 2030, the typical North American city will rely heavily upon them. These include\nand machine learning is\ncameras for surveillance that can detect anomalies pointing to a possible crime,\nmaking an impact. drones, and predictive policing applications. As with most issues, there are benefits\nand risks. Gaining public trust is crucial. While there are legitimate concerns that\npolicing that incorporates AI may become overbearing or pervasive in some contexts,\nthe opposite is also possible. AI may enable policing to become more targeted and\nused only when needed. And assuming careful deployment, AI may also help remove\nsome of the bias inherent in human decision-making.",
    "page": 36
  },
  {
    "type": "text",
    "content": "ing careful deployment, AI may also help remove\nsome of the bias inherent in human decision-making.\nOne of the more successful uses of AI analytics is in detecting white collar\ncrime, such as credit card fraud.101 Cybersecurity (including spam) is a widely shared\nconcern, and machine learning is making an impact. AI tools may also prove useful\nin helping police manage crime scenes or search and rescue events by helping\ncommanders prioritize tasks and allocate resources, though these tools are not yet\nready for automating such activities. Improvements in machine learning in general,\nand transfer learning in particular—for speeding up learning in new scenarios based\non similarities with past scenarios—may facilitate such systems.",
    "page": 36
  },
  {
    "type": "text",
    "content": "up learning in new scenarios based\non similarities with past scenarios—may facilitate such systems.\nThe cameras deployed almost everywhere in the world today tend to be more\nuseful for helping solve crimes than preventing them.102 103 This is due to the low\nquality of event identification from videos and the lack of manpower to look at\nmassive video streams. As AI for this domain improves, it will better assist crime\nprevention and prosecution through greater accuracy of event classification and\nefficient automatic processing of video to detect anomalies—including, potentially,\n407–426.\n100 Jordan Pearson, “Artificial Intelligence Could Help Reduce HIV Among Homeless Youths,”\nTeamcore, University of Southern California, February 4. 2015, accessed August 1, 2016, http://\nteamcore.usc.",
    "page": 36
  },
  {
    "type": "text",
    "content": "University of Southern California, February 4. 2015, accessed August 1, 2016, http://\nteamcore.usc.edu/news/motherboard_news_ai_could_help_reduce_HIV.pdf.\n101 “RSA Adaptive Authentication,” RSA, accessed August 1, 2016, https://www.rsa.com/en-us/\nproducts-services/fraud-prevention/adaptive-authentication.\n102 Takeshi Arikuma and Yasunori Mochizuki, “Intelligent multimedia surveillance system for\nsafer cities” APSIPA Transactions on Signal and Information Processing 5 (2016): 1–8.\n103 “Big Op-Ed: Shifting Opinions On Surveillance Cameras,”, Talk of the Nation, NPR, April 22,\n2013, accessed August 1, 2016, http://www.npr.org/2013/04/22/178436355/big-op-ed-shifting-\n36 opinions-on-surveillance-cameras.",
    "page": 36
  },
  {
    "type": "text",
    "content": "-cameras.",
    "page": 36
  },
  {
    "type": "text",
    "content": "evidence of police malpractice. These improvements could lead to even more\nwidespread surveillance. Some cities have already added drones for surveillance\npurposes, and police use of drones to maintain security of ports, airports, coastal\nareas, waterways, industrial facilities is likely to increase, raising concerns about\nprivacy, safety, and other issues.\nThe New York Police Department’s CompStat was the first tool pointing toward\npredictive policing,104 and many police departments now use it.105 Machine learning\nsignificantly enhances the ability to predict where and when crimes are more likely\nAs dramatized in the\nto happen and who may commit them. As dramatized in the movie Minority Report,\npredictive policing tools raise the specter of innocent people being unjustifiably",
    "page": 37
  },
  {
    "type": "text",
    "content": "Minority Report,\npredictive policing tools raise the specter of innocent people being unjustifiably\nmovie Minority Report,\ntargeted. But well-deployed AI prediction tools have the potential to actually remove\nor reduce human bias, rather than reinforcing it, and research and resources should predictive policing tools\nbe directed toward ensuring this effect.\nAI techniques can be used to develop intelligent simulations for training law- raise the specter of\nenforcement personnel to collaborate. While international criminal organizations and\ninnocent people being\nterrorists from different countries are colluding, police forces from different countries\nstill face difficulty in joining forces to fight them. Training international groups of law\nunjustifiably targeted. But",
    "page": 37
  },
  {
    "type": "text",
    "content": "y in joining forces to fight them. Training international groups of law\nunjustifiably targeted. But\nenforcement personnel to work as teams is very challenging. The European Union,\nthrough the Horizon 2020 program, currently supports such attempts in projects such well-deployed AI prediction\nas LawTrain.106 The next step will be to move from simulation to actual investigations\ntools have the potential to\nby providing tools that support such collaborations.\nTools do exist for scanning Twitter and other feeds to look for certain types\nactually remove or reduce\nof events and how they may impact security. For example, AI can help in social\nnetwork analysis to prevent those at risk from being radicalized by ISIS or other human bias.\nviolent groups.",
    "page": 37
  },
  {
    "type": "text",
    "content": "nalysis to prevent those at risk from being radicalized by ISIS or other human bias.\nviolent groups. Law enforcement agencies are increasingly interested in trying to\ndetect plans for disruptive events from social media, and also to monitor activity at\nlarge gatherings of people to analyze security. There is significant work on crowd\nsimulations to determine how crowds can be controlled. At the same time, legitimate\nconcerns have been raised about the potential for law enforcement agencies to\noverreach and use such tools to violate people’s privacy.\nThe US Transportation Security Administration (TSA), Coast Guard, and the\nmany other security agencies that currently rely on AI will likely increase their\nreliance to enable significant efficiency and efficacy improvements.107 AI techniques—",
    "page": 37
  },
  {
    "type": "text",
    "content": "crease their\nreliance to enable significant efficiency and efficacy improvements.107 AI techniques—\nvision, speech analysis, and gait analysis— can aid interviewers, interrogators, and\nsecurity guards in detecting possible deception and criminal behavior. For example,\nthe TSA currently has an ambitious project to redo airport security nationwide.108\nCalled DARMS, the system is designed to improve efficiency and efficacy of airport\nsecurity by relying on personal information to tailor security based on a person’s risk\ncategorization and the flights being taken. The future vision for this project is a tunnel\nthat checks people’s security while they walk through it. Once again, developers of\nthis technology should be careful to avoid building in bias (e.g. about a person’s risk",
    "page": 37
  },
  {
    "type": "text",
    "content": "velopers of\nthis technology should be careful to avoid building in bias (e.g. about a person’s risk\nlevel category) through use of datasets that reflect prior bias.109\n104 Walter L. Perry, Brian McInnis, Carter C. Price, Susan Smith, and John S. Hollywood, “The\nRole of Crime Forecasting in Law Enforcement Operations,” Rand Corporation Report 233 (2013).\n105 “CompStat,” Wikipedia, last modified July 28, 2016, accessed August 1, 2016, https://\nen.wikipedia.org/wiki/CompStat.\n106 LAW-TRAIN, accessed August 1, 2016, http://www.law-train.eu/.\n107 Milind Tambe, Security and Game Theory: Algorithms, Deployed Systems, Lessons Learned (New York:\nCambridge University Press, 2011).\n108 Peter Neffenger, “TSA’s 2017 Budget—A Commitment to Security (Part I),” Department",
    "page": 37
  },
  {
    "type": "text",
    "content": "ress, 2011).\n108 Peter Neffenger, “TSA’s 2017 Budget—A Commitment to Security (Part I),” Department\nof Homeland Security, March 1, 2016, accessed August 1, 2016, https://www.tsa.gov/news/\ntestimony/2016/03/01/hearing-fy17-budget-request-transportation-security-administration.\n109 Crawford, “AI’s White Guy Problem.” 37",
    "page": 37
  },
  {
    "type": "text",
    "content": "EMPLOYMENT AND WORKPLACE\nWhile AI technologies are likely to have a profound future impact on employment\nand workplace trends in a typical North American city, it is difficult to accurately\nassess current impacts, positive or negative. In the past fifteen years, employment\nhas shifted due to a major recession and increasing globalization, particularly with\nChina’s introduction to the world economy, as well as enormous changes in non-AI\ndigital technology. Since the 1990s, the US has experienced continued growth in\nproductivity and GDP, but median income has stagnated and the employment to\nAI will likely replace tasks\npopulation ratio has fallen.\nrather than jobs in the There are clear examples of industries in which digital technologies have had",
    "page": 38
  },
  {
    "type": "text",
    "content": "ther than jobs in the There are clear examples of industries in which digital technologies have had\nprofound impacts, good and bad, and other sectors in which automation will likely\nnear term, and will also\nmake major changes in the near future. Many of these changes have been driven\nstrongly by “routine” digital technologies, including enterprise resource planning,\ncreate new kinds of jobs.\nnetworking, information processing, and search. Understanding these changes should\nBut the new jobs that provide insights into how AI will affect future labor demand, including the shift in\nskill demands. To date, digital technologies have been affecting workers more in the\nwill emerge are harder to skilled middle, such as travel agents, rather than the very lowest-skilled or highest\nskilled work.",
    "page": 38
  },
  {
    "type": "text",
    "content": "skilled middle, such as travel agents, rather than the very lowest-skilled or highest\nskilled work.110 On the other hand, the spectrum of tasks that digital systems can\nimagine in advance than\ndo is evolving as AI systems improve, which is likely to gradually increase the scope\nof what is considered routine. AI is also creeping into high end of the spectrum,\nthe existing jobs that will\nincluding professional services not historically performed by machines.\nlikely be lost. To be successful, AI innovations will need to overcome understandable human\nfears of being marginalized. AI will likely replace tasks rather than jobs in the near\nterm, and will also create new kinds of jobs. But the new jobs that will emerge are",
    "page": 38
  },
  {
    "type": "text",
    "content": "obs in the near\nterm, and will also create new kinds of jobs. But the new jobs that will emerge are\nharder to imagine in advance than the existing jobs that will likely be lost. Changes\nin employment usually happen gradually, often without a sharp transition, a trend\nlikely to continue as AI slowly moves into the workplace. A spectrum of effects will\nemerge, ranging from small amounts of replacement or augmentation to complete\nreplacement. For example, although most of a lawyer’s job is not yet automated,111\nAI applied to legal information extraction and topic modeling has automated parts of\nfirst-year lawyers’ jobs.112 In the not too distant future, a diverse array of job-holders,\nfrom radiologists to truck drivers to gardeners, may be affected.",
    "page": 38
  },
  {
    "type": "text",
    "content": ", a diverse array of job-holders,\nfrom radiologists to truck drivers to gardeners, may be affected.\nAI may also influence the size and location of the workforce. Many organizations\nand institutions are large because they perform functions that can be scaled only by\nadding human labor, either “horizontally” across geographical areas or “vertically”\nin management hierarchies. As AI takes over many functions, scalability no longer\nimplies large organizations. Many have noted the small number of employees of\nsome high profile internet companies, but not of others. There may be a natural scale\nof human enterprise, perhaps where the CEO can know everyone in the company.\nThrough the creation of efficiently outsourced labor markets enabled by AI,\nenterprises may tend towards that natural size.",
    "page": 38
  },
  {
    "type": "text",
    "content": "efficiently outsourced labor markets enabled by AI,\nenterprises may tend towards that natural size.\nAI will also create jobs, especially in some sectors, by making certain tasks more\nimportant, and create new categories of employment by making new modes of\ninteraction possible. Sophisticated information systems can be used to create new\n110 Jeremy Ashkenas and Alicia Parlapiano, “How the Recession Reshaped the Economy, in 255\nCharts,” The New York Times, June 6, 2014, accessed August 1, 2016, http://www.nytimes.com/\ninteractive/2014/06/05/upshot/how-the-recession-reshaped-the-economy-in-255-charts.html.\n111 R Dana Remus and Frank S. Levy, “Can Robots Be Lawyers? Computers, Lawyers, and the",
    "page": 38
  },
  {
    "type": "text",
    "content": "harts.html.\n111 R Dana Remus and Frank S. Levy, “Can Robots Be Lawyers? Computers, Lawyers, and the\nPractice of Law,” Social Science Research Network, last modified February 12, 2016, accessed August 1,\n2016, http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2701092.\n112 John Markoff, “Armies of Expensive Lawyers, Replaced by Cheaper Software,” The New\nYork Times, March 4, 2011, accessed August 1, 2016, http://www.nytimes.com/2011/03/05/\n38 science/05legal.html.",
    "page": 38
  },
  {
    "type": "text",
    "content": "markets, which often have the effect of lowering barriers to entry and increasing\nparticipation—from app stores to AirBnB to taskrabbit. A vibrant research\ncommunity within AI studies further ways of creating new markets and making\nexisting ones operate more efficiently.\nWhile work has intrinsic value, most people work to be able to purchase goods and\nservices they value. Because AI systems perform work that previously required human\nlabor, they have the effect of lowering the cost of many goods and services, effectively\nmaking everyone richer. But as exemplified in current political debates, job loss is\nAs labor becomes a\nmore salient to people—especially those directly affected—than diffuse economic\ngains, and AI unfortunately is often framed as a threat to jobs rather than a boon to",
    "page": 39
  },
  {
    "type": "text",
    "content": "fuse economic\ngains, and AI unfortunately is often framed as a threat to jobs rather than a boon to\nless important factor in\nliving standards.\nThere is even fear in some quarters that advances in AI will be so rapid as production as compared\nto replace all human jobs—including those that are largely cognitive or involve\njudgment—within a single generation. This sudden scenario is highly unlikely, but to owning intellectual\nAI will gradually invade almost all employment sectors, requiring a shift away from\ncapital, a majority of\nhuman labor that computers are able to take over.\nThe economic effects of AI on cognitive human jobs will be analogous to\ncitizens may find the value\nthe effects of automation and robotics on humans in manufacturing jobs. Many",
    "page": 39
  },
  {
    "type": "text",
    "content": "ens may find the value\nthe effects of automation and robotics on humans in manufacturing jobs. Many\nmiddle-aged workers have lost well-paying factory jobs and the socio-economic status of their labor insufficient\nin family and society that traditionally went with such jobs. An even larger fraction\nto pay for a socially\nof the total workforce may, in the long run, lose well-paying “cognitive” jobs. As labor\nbecomes a less important factor in production as compared to owning intellectual\nacceptable standard of\ncapital, a majority of citizens may find the value of their labor insufficient to pay for\na socially acceptable standard of living. These changes will require a political, rather living.\nthan a purely economic, response concerning what kind of social safety nets should",
    "page": 39
  },
  {
    "type": "text",
    "content": ", rather living.\nthan a purely economic, response concerning what kind of social safety nets should\nbe in place to protect people from large, structural shifts in the economy. Absent\nmitigating policies, the beneficiaries of these shifts may be a small group at the\nupper stratum of the society.113\nIn the short run, education, re-training, and inventing new goods and services may\nmitigate these effects. Longer term, the current social safety net may need to evolve into\nbetter social services for everyone, such as healthcare and education, or a guaranteed\nbasic income. Indeed, countries such as Switzerland and Finland have actively considered\nsuch measures. AI may be thought of as a radically different mechanism of wealth",
    "page": 39
  },
  {
    "type": "text",
    "content": "ctively considered\nsuch measures. AI may be thought of as a radically different mechanism of wealth\ncreation in which everyone should be entitled to a portion of the world’s AI-produced\ntreasure.114 It is not too soon for social debate on how the economic fruits of\nAI-technologies should be shared. As children in traditional societies support their\naging parents, perhaps our artificially intelligent “children” should support us, the\n“parents” of their intelligence.\n113 For example, Brynjolfsson and McAfee, Second Machine Age, have two chapters of devoted to\nthis (Erik Brynjolfsson and Andrew McAfee, The Second Machine Age: Work, Progress, and Prosperity in a\nTime of Brilliant Technologies, (New York: W. W. Norton & Company, Inc., 2014)) and Brynjolfsson,",
    "page": 39
  },
  {
    "type": "text",
    "content": "a\nTime of Brilliant Technologies, (New York: W. W. Norton & Company, Inc., 2014)) and Brynjolfsson,\nMcAfee, and Spence describe policy responses for the combination of globalization and digital\ntechnology (Erik Brynjolfsson, Andrew McAfee, and Michael Spence, Foreign Affairs, July/August\n2014, accessed August 1, 2016, https://www.foreignaffairs.com/articles/united-states/\n2014-06-04/new-world-order).\n114 GDP does not do a good job of measuring the value of many digital goods. When society\ncan’t manage what isn’t measured, bad policy decisions result. One alternative is to look at\nconsumer surplus, not just dollar flows. As AI is embodied in more goods, this issue becomes more\nsalient. It may look like GDP goes down but people have better well-being through access to these\ndigital goods.",
    "page": 39
  },
  {
    "type": "text",
    "content": "may look like GDP goes down but people have better well-being through access to these\ndigital goods. See Erik Brynjolfsson and Adam Saunders, “What the GDP Gets Wrong (Why\nManagers Should Care),” Sloan Management Review, vol. 51, no. 1 (October 1, 2009): 95–96. 39",
    "page": 39
  },
  {
    "type": "text",
    "content": "ENTERTAINMENT\nWith the explosive growth of the internet over the past fifteen years, few can imagine\ntheir daily lives without it. Powered by AI, the internet has established user-generated\ncontent as a viable source of information and entertainment. Social networks such\nas Facebook are now pervasive, and they function as personalized channels of\nsocial interaction and entertainment—sometimes to the detriment of interpersonal\ninteraction. Apps such as WhatsApp and Snapchat enable smart-phone users to\nremain constantly “in touch” with peers and share sources of entertainment and\nAI will increasingly enable\ninformation. In on-line communities such as Second Life and role-playing games such",
    "page": 40
  },
  {
    "type": "text",
    "content": "easingly enable\ninformation. In on-line communities such as Second Life and role-playing games such\nentertainment that is more as World of Warcraft, people imagine an alternative existence in a virtual world.115\nSpecialized devices, such as Amazon’s Kindle have also redefined the essentials of\ninteractive, personalized,\nlong-cherished pastimes. Books can now be browsed and procured with a few swipes\nof the finger, stored by the thousands in a pocket-sized device, and read in much the\nand engaging. Research\nsame way as a handheld paperback.\nshould be directed toward Trusted platforms now exist for sharing and browsing blogs, videos, photos, and\ntopical discussions, in addition to a variety of other user-generated information. To",
    "page": 40
  },
  {
    "type": "text",
    "content": ", photos, and\ntopical discussions, in addition to a variety of other user-generated information. To\nunderstanding how to operate at the scale of the internet, these platforms must rely on techniques that are\nbeing actively developed in natural language processing, information retrieval, image\nleverage these attributes\nprocessing, crowdsourcing, and machine learning. Algorithms such as collaborative\nfiltering have been developed, for example, to recommend relevant movies, songs, or\nfor individuals’ and\narticles based on the user’s demographic details and browsing history.116\nsociety’s benefit. Traditional sources of entertainment have also embraced AI to keep pace with the\ntimes. As exemplified in the book and movie Moneyball, professional sport is now subjected",
    "page": 40
  },
  {
    "type": "text",
    "content": "with the\ntimes. As exemplified in the book and movie Moneyball, professional sport is now subjected\nto intensive quantitative analysis.117 Beyond aggregate performance statistics, on-field\nsignals can be monitored using sophisticated sensors and cameras. Software has been\ncreated for composing music118 and recognizing soundtracks.119 Techniques from computer\nvision and NLP have been used in creating stage performances.120 Even the lay user can\nexercise his or her creativity on platforms such as WordsEye, which automatically\ngenerates 3D scenes from natural language text.121 AI has also come to the aid of\nhistorical research in the arts, and is used extensively in stylometry and, more recently,\nin the analysis of paintings.122",
    "page": 40
  },
  {
    "type": "text",
    "content": "he arts, and is used extensively in stylometry and, more recently,\nin the analysis of paintings.122\nThe enthusiasm with which humans have responded to AI-driven entertainment\nhas been surprising and led to concerns that it reduces interpersonal interaction\namong human beings. Few predicted that people would spend hours on end\ninteracting with a display. Children often appear to be genuinely happier playing\nat home on their devices rather than outside with their friends. AI will increasingly\nenable entertainment that is more interactive, personalized, and engaging. Research\nshould be directed toward understanding how to leverage these attributes for\nindividuals’ and society’s benefit.\n115 Second Life, accessed August 1, 2016, http://secondlife.com; “World of Warcraft,” Blizzard",
    "page": 40
  },
  {
    "type": "text",
    "content": "fit.\n115 Second Life, accessed August 1, 2016, http://secondlife.com; “World of Warcraft,” Blizzard\nEntertainment, Inc, accessed August 1, 2016, http://us.battle.net/wow/en/.\n116 John S. Breese, David Heckerman, and Carl Kadie, “Empirical Analysis of Predictive\nAlgorithms for Collaborative Filtering,” Proceedings of the 14th Conference on Uncertainty in Artificial\nIntelligence (July 1998), accessed August 1, 2016, http://arxiv.org/pdf/1301.7363.pdf, 43–52.\n117 Michael Lewis, Moneyball: The Art of Winning an Unfair Game (New York: W. W. Norton &\nCompany, Inc., 2003): http://www.imdb.com/title/tt1210166/).\n118 MuseScore, accessed August 1, 2016, https://musescore.org/.\n119 Shazam, accessed August 1, 2016, http://www.shazam.com/.\n120 Annie Dorsen, accessed August 1, 2016, http://www.",
    "page": 40
  },
  {
    "type": "text",
    "content": "essed August 1, 2016, http://www.shazam.com/.\n120 Annie Dorsen, accessed August 1, 2016, http://www.anniedorsen.com/.\n121 WordsEye, accessed August 1, 2016, https://www.wordseye.com/.\n122 “Stylometry,” Wikipedia, last modified August 4, 2016, accessed August 1, 2016, https://\n40 en.wikipedia.org/wiki/Stylometry; http://arxiv.org/pdf/1408.3218v1.pdf.",
    "page": 40
  },
  {
    "type": "text",
    "content": "Imagining the Future\nThe success of any form of entertainment is ultimately determined by the individuals\nand social groups that are its subjects. The modes of entertainment that people find\nappealing are diverse and change over time. It is therefore hard to predict the forms\nentertainment will take in the next fifteen years precisely. Nevertheless, current trends\nsuggest at least a few features that the future entertainment landscape is likely to contain.\nTo date, the information revolution has mostly unfolded in software. However,\nwith the growing availability of cheaper sensors and devices, greater innovation in the\nMore sophisticated tools\nhardware used in entertainment systems is expected. Virtual reality and haptics could",
    "page": 41
  },
  {
    "type": "text",
    "content": "ticated tools\nhardware used in entertainment systems is expected. Virtual reality and haptics could\nenter our living rooms—personalized companion robots are already being developed.123\nand apps will become\nWith the accompanying improvements in Automatic Speech Recognition, the Study\nPanel expects that interaction with robots and other entertainment systems will become available to make it\ndialogue-based, perhaps constrained at the start, but progressively more human-like.\neven easier to produce\nEqually, the interacting systems are predicted to develop new characteristics such as\nemotion, empathy, and adaptation to environmental rhythms such as time of day.124\nhigh-quality content, for\nToday, an amateur with a video camera and readily-available software tools can",
    "page": 41
  },
  {
    "type": "text",
    "content": "quality content, for\nToday, an amateur with a video camera and readily-available software tools can\nmake a relatively good movie. In the future, more sophisticated tools and apps will example, to compose\nbecome available to make it even easier to produce high-quality content, for example,\nto compose music or to choreograph dance using an avatar. The creation and music or to choreograph\ndissemination of entertainment will benefit from the progress of technologies such as\ndance using an avatar.\nASR, dubbing, and Machine Translation, which will enable content to be customized\nto different audiences inexpensively. This democratization and proliferation of AI-\ncreated media makes it difficult to predict how humans’ taste for entertainment, which\nare already fluid, will evolve.",
    "page": 41
  },
  {
    "type": "text",
    "content": "it difficult to predict how humans’ taste for entertainment, which\nare already fluid, will evolve.\nWith content increasingly delivered digitally, and large amounts of data being\nlogged about consumers’ preferences and usage characteristics, media powerhouses\nwill be able to micro-analyze and micro-serve content to increasingly specialized\nsegments of the population—down to the individual.125 Conceivably the stage is set\nfor the emergence of media conglomerates acting as “Big Brothers” who are able to\ncontrol the ideas and online experiences to which specific individuals are exposed.\nIt remains to be seen whether broader society will develop measures to prevent their\nemergence. This topic, along with others pertaining to AI-related policy, is treated in\nmore detail in the next section.",
    "page": 41
  },
  {
    "type": "text",
    "content": ", along with others pertaining to AI-related policy, is treated in\nmore detail in the next section.\n123 Emoters, accessed August 1, 2016, http://emoterbots.com/.\n124 “Siri,” Apple, Inc., accessed August 1, 2016, http://www.apple.com/in/ios/siri/.\n125 Ryan Calo, “Digital Market Manipulation,” George Washington Law Review 82, no. 4 (2014):\n995–1051. 41",
    "page": 41
  },
  {
    "type": "text",
    "content": "SECTION III: PROSPECTS AND\nRECOMMENDATIONS FOR AI PUBLIC POLICY\nThe goal of AI applications must be to create value for society. Our policy recommendations\nflow from this goal, and, while this report is focused on a typical North American city in\n2030, the recommendations are broadly applicable to other places over time. Strategies that\nenhance our ability to interpret AI systems and participate in their use may help build trust\nThe measure of success and prevent drastic failures. Care must be taken to augment and enhance human capabilities\nand interaction, and to avoid discrimination against segments of society. Research to encourage\nfor AI applications is this direction and inform public policy debates should be emphasized. Given the current",
    "page": 42
  },
  {
    "type": "text",
    "content": "ications is this direction and inform public policy debates should be emphasized. Given the current\nsector-specific regulation of US industries, new or retooled laws and policies will be needed\nthe value they create\nto address the widespread impacts AI is likely to bring. Rather than “more” or “stricter”\nregulation, policies should be designed to encourage helpful innovation, generate and transfer\nfor human lives. Going\nexpertise, and foster broad corporate and civic responsibility for addressing critical societal\nforward, the ease with issues raised by these technologies. In the long term, AI will enable new wealth creation that\nwill require social debate on how the economic fruits of AI technologies should be shared.\nwhich people use and\nAI POLICY, NOW AND IN THE FUTURE",
    "page": 42
  },
  {
    "type": "text",
    "content": "c fruits of AI technologies should be shared.\nwhich people use and\nAI POLICY, NOW AND IN THE FUTURE\nadapt to AI applications\nThroughout history, humans have both shaped and adapted to new technologies. This\nwill likewise largely\nreport anticipates that advances in AI technologies will be developed and fielded\ngradually—not in sudden, unexpected jumps in the techniques themselves—and will\ndetermine their success.\nbuild on what exists today, making this adaptation easier. On the other hand, small\nimprovements to techniques, computing power, or availability of data can occasionally\nlead to novel, game-changing applications. The measure of success for AI applications\nis the value they create for human lives. Going forward, the ease with which people",
    "page": 42
  },
  {
    "type": "text",
    "content": "AI applications\nis the value they create for human lives. Going forward, the ease with which people\nuse and adapt to AI applications will likewise largely determine their success.\nConversely, since AI applications are susceptible to errors and failures, a mark of\ntheir success will be how users perceive and tolerate their shortcomings. As AI becomes\nincreasingly embedded in daily lives and used for more critical tasks, system mistakes\nmay lead to backlash from users and negatively affect their trust. Though accidents\nin a self-driving car may be less probable than those driven by humans, for example,\nthey will attract more attention. Design strategies that enhance the ability of humans\nto understand AI systems and decisions (such as explicitly explaining those decisions),",
    "page": 42
  },
  {
    "type": "text",
    "content": "y of humans\nto understand AI systems and decisions (such as explicitly explaining those decisions),\nand to participate in their use, may help build trust and prevent drastic failures. Likewise,\ndevelopers should help manage people’s expectations, which will affect their happiness\nand satisfaction with AI applications. Frustration in carrying out functions promised\nby a system diminishes people’s trust and reduces their willingness to use the system\nin the future.\nAnother important consideration is how AI systems that take over certain tasks\nwill affect people’s affordances and capabilities. As machines deliver super-human\nperformances on some tasks, people’s ability to perform them may wither. Already,\nintroducing calculators to classrooms has reduced children’s ability to do basic",
    "page": 42
  },
  {
    "type": "text",
    "content": "y wither. Already,\nintroducing calculators to classrooms has reduced children’s ability to do basic\narithmetic operations. Still, humans and AI systems have complementary abilities.\nPeople are likely to focus on tasks that machines cannot do as well, including complex\nreasoning and creative expression.\nAlready, children are increasingly exposed to AI applications, such as interacting\nwith personal assistants on cell phones or with virtual agents in theme parks. Having\nearly exposure will improve children’s interactions with AI applications, which\nwill become a natural part of their daily lives. As a result, gaps will appear in how\nyounger and older generations perceive AI’s influences on society.\n42",
    "page": 42
  },
  {
    "type": "text",
    "content": "iety.\n42",
    "page": 42
  },
  {
    "type": "text",
    "content": "Likewise, AI could widen existing inequalities of opportunity if access to AI\ntechnologies—along with the high-powered computation and large-scale data that\nfuel many of them—is unfairly distributed across society. These technologies will\nimprove the abilities and efficiency of people who have access to them. A person with\naccess to accurate Machine Translation technology will be better able to use learning\nresources available in different languages. Similarly, if speech translation technology is\nonly available in English, people who do not speak English will be at a disadvantage.\nFurther, AI applications and the data they rely upon may reflect the biases of their\nAI could widen\ndesigners and users, who specify the data sources. This threatens to deepen existing",
    "page": 43
  },
  {
    "type": "text",
    "content": "AI could widen\ndesigners and users, who specify the data sources. This threatens to deepen existing\nsocial biases, and concentrate AI’s benefits unequally among different subgroups\nexisting inequalities of\nof society. For example, some speech recognition technologies do not work well for\nwomen and people with accents. As AI is increasingly used in critical applications, opportunity if access to\nthese biases may surface issues of fairness to diverse groups in society. On the other\nhand, compared to the well-documented biases in human decision-making, AI-based AI technologies—along\ndecision-making tools have the potential to significantly reduce the bias in critical\nwith the high-powered\ndecisions such as who is lent money or sent to jail.",
    "page": 43
  },
  {
    "type": "text",
    "content": "uce the bias in critical\nwith the high-powered\ndecisions such as who is lent money or sent to jail.\nPrivacy concerns about AI-enabled surveillance are also widespread, particularly\ncomputation and large-\nin cities with pervasive instrumentation. Sousveillance, the recording of an activity\nby a participant, usually with portable personal devices, has increased as well. Since scale data that fuel\nviews about bias and privacy are based on personal and societal ethical and value\nmany of them—is unfairly\njudgments, the debates over how to address these concerns will likely grow and resist\nquick resolution. Similarly, since AI is generating significant wealth, debates will grow\ndistributed across society.\nregarding how the economic fruits of AI technologies should be shared—especially as",
    "page": 43
  },
  {
    "type": "text",
    "content": "across society.\nregarding how the economic fruits of AI technologies should be shared—especially as\nAI expertise and the underlying data sets that fuel applications are concentrated in a\nsmall number of large corporations.\nTo help address these concerns about the individual and societal implications\nof rapidly evolving AI technologies, the Study Panel offers three general policy\nrecommendations:\n1. Define a path toward accruing technical expertise in AI at all\nlevels of government. Effective governance requires more experts\nwho understand and can analyze the interactions between AI\ntechnologies, programmatic objectives, and overall societal values.\nAbsent sufficient technical expertise to assess safety or other metrics, national or",
    "page": 43
  },
  {
    "type": "text",
    "content": "cietal values.\nAbsent sufficient technical expertise to assess safety or other metrics, national or\nlocal officials may refuse to permit a potentially promising application. Or insufficiently\ntrained officials may simply take the word of industry technologists and green light a\nsensitive application that has not been adequately vetted. Without an understanding\nof how AI systems interact with human behavior and societal values, officials will be\npoorly positioned to evaluate the impact of AI on programmatic objectives.\n2. Remove the perceived and actual impediments to research on the\nfairness, security, privacy, and social impacts of AI systems.\nSome interpretations of federal laws such as the Computer Fraud and Abuse Act",
    "page": 43
  },
  {
    "type": "text",
    "content": "mpacts of AI systems.\nSome interpretations of federal laws such as the Computer Fraud and Abuse Act\nand the anti-circumvention provision of the Digital Millennium Copyright Act are\nambiguous regarding whether and how proprietary AI systems may be reverse engineered\nand evaluated by academics, journalists, and other researchers. Such research is critical\nif AI systems with physical and other material consequences are to be properly vetted\nand held accountable.\n3. Increase public and private funding for interdisciplinary studies of\nthe societal impacts of AI.\nAs a society, we are underinvesting resources in research on the societal implications\nof AI technologies. Private and public dollars should be directed toward interdisciplinary\n43",
    "page": 43
  },
  {
    "type": "text",
    "content": "ould be directed toward interdisciplinary\n43",
    "page": 43
  },
  {
    "type": "text",
    "content": "teams capable of analyzing AI from multiple angles. Research questions range from\nbasic research into intelligence to methods to assess and affect the safety, privacy,\nfairness, and other impacts of AI.\nQuestions include: Who is responsible when a self-driven car crashes or an\nintelligent medical device fails? How can AI applications be prevented from unlawful\ndiscrimination? Who should reap the gains of efficiencies enabled by AI technologies\nand what protections should be afforded to people whose skills are rendered obsolete?\nAs AI becomes integrated more broadly and deeply into industrial and consumer\nAs a society, we are\nproducts, it enters areas in which established regulatory regimes will need to be\nadapted to AI innovations or in some cases fundamentally reconfigured according to",
    "page": 44
  },
  {
    "type": "text",
    "content": "will need to be\nadapted to AI innovations or in some cases fundamentally reconfigured according to\nunderinvesting resources\nbroadly accepted goals and principles.\nin research on the The approach in the United States to date has been sector-specific, with oversight\nby a variety of agencies. The use of AI in devices that deliver medical diagnostics and\nsocietal implications of treatments is subject to aggressive regulation by the Food and Drug Administration\n(FDA), both in defining what the product is and specifying the methods by which it is\nAI technologies. Private\nproduced, including standards of software engineering. The use of drones in regulated\nairspace falls under the authority of the Federal Aviation Administration (FAA).126 For\nand public dollars should",
    "page": 44
  },
  {
    "type": "text",
    "content": "under the authority of the Federal Aviation Administration (FAA).126 For\nand public dollars should\nconsumer-facing AI systems, regulation by the Federal Trade Commission (FTC) comes\nbe directed toward into play. Financial markets using AI technologies, such as in high-frequency trading,\ncome under regulation by the Security Exchange Commission (SEC).\ninterdisciplinary teams\nIn addition to sector-specific approaches, the somewhat ambiguous and broad\nregulatory category of “critical infrastructure” may apply to AI applications.127 The\ncapable of analyzing AI\nObama Administration’s Presidential Policy Directive (PPD) 21 broadly defines critical\nfrom multiple angles. infrastructure as composed of “the assets, systems, and networks, whether physical or",
    "page": 44
  },
  {
    "type": "text",
    "content": "tiple angles. infrastructure as composed of “the assets, systems, and networks, whether physical or\nvirtual, so vital to the United States that their incapacitation or destruction would have\na debilitating effect on security, national economic security, national public health or\nsafety, or any combination thereof.” Today, an enterprise does not come under federal\nregulation solely by falling under that broad definition. Instead, the general trend of\nfederal policy is to seek regulation in sixteen sectors of the economy.128\nAs regards AI, critical infrastructure is notably defined by the end-user application,\nand not the technology or sector that actually produces AI software.129 Software\n126 FAA controls the ways drones fly, requires drones to be semiautonomous as opposed to",
    "page": 44
  },
  {
    "type": "text",
    "content": "9 Software\n126 FAA controls the ways drones fly, requires drones to be semiautonomous as opposed to\nautonomous, requires visual connection to the drone, and enforces no-fly zones close to airports.\n127 “Presidential Policy Directive (PPD-21)—Critical Infrastructure Security and Resilience,” The\nWhite House, February 12, 2013, accessed August 1, 2016, https://www.whitehouse.gov/the-press-\noffice/2013/02/12/presidential-policy-directive-critical-infrastructure-security-and-resil.\n128 PPD 21 identifies agencies responsible in each case. Chemical: Department of Homeland\nSecurity; Commercial Facilities: Department of Homeland Security; Communications: Department\nof Homeland Security; Critical Manufacturing: Department of Homeland Security; Dams:",
    "page": 44
  },
  {
    "type": "text",
    "content": "ns: Department\nof Homeland Security; Critical Manufacturing: Department of Homeland Security; Dams:\nDepartment of Homeland Security; Defense Industrial Base: Department of Defense; Emergency\nServices: Department of Homeland Security; Energy: Department of Energy; Financial Services:\nDepartment of the Treasury; Food and Agriculture: U.S. Department of Agriculture and\nDepartment of Health and Human Services; Government Facilities: Department of Homeland\nSecurity and General Services Administration; Healthcare and Public Health: Department of\nHealth and Human Services; Information Technology: Department of Homeland Security;\nNuclear Reactors, Materials, and Waste: Department of Homeland Security; Transportation",
    "page": 44
  },
  {
    "type": "text",
    "content": "d Security;\nNuclear Reactors, Materials, and Waste: Department of Homeland Security; Transportation\nSystems: Department of Homeland Security and Department of Transportation; Water and\nWastewater Systems: Environmental Protection Agency.\n129 In “ICYMI- Business Groups Urge White House to Rethink Cyber Security Order,” Internet\nAssociation, March 5, 2013, accessed August 1, 2016, https://internetassociation.org/030513gov-3/:\n“Obama’s Feb. 12 order says the government can’t designate ‘commercial information technology\nproducts’ or consumer information technology services as critical U.S. infrastructure targeted for\nvoluntary computer security standards,’ ... ‘Obama’s order isn’t meant to get down to the level",
    "page": 44
  },
  {
    "type": "text",
    "content": "for\nvoluntary computer security standards,’ ... ‘Obama’s order isn’t meant to get down to the level\nof products and services and dictate how those products and services behave,’ said David LeDuc,\nsenior director of public policy for the Software & Information Industry Association, a Washington\n44 trade group that lobbied for the exclusions.”",
    "page": 44
  },
  {
    "type": "text",
    "content": "companies such as Google, Facebook, and Amazon have actively lobbied to avoid\nbeing designated as critical to the economy, arguing that this would open the door to\nregulation that would inevitably compromise their rapid product development cycles\nand ability to innovate.130 Nonetheless, as the companies creating, operating, and\nmaintaining critical infrastructure use AI, interest will grow in regulating that software.\nSome existing regulatory regimes for software safety (for example, the FDA’s\nregulation of high consequence medical software) require specific software\nengineering practices at the developer level. However, modern software systems\nAbsent sufficient technical\nare often assembled from library components which may be supplied by multiple",
    "page": 45
  },
  {
    "type": "text",
    "content": "sufficient technical\nare often assembled from library components which may be supplied by multiple\nvendors, and are relatively application-independent. It doesn’t seem feasible or\nexpertise to assess\ndesirable to subject all such developers to the standards required for the most critical,\nrare applications. Nor does it seem advisable to allow unregulated use of such safety or other metrics,\ncomponents in safety critical applications. Tradeoffs between promoting innovation\nand regulating for safety are difficult ones, both conceptually and in practice. At a national or local officials\nminimum, regulatory entities will require greater expertise going forward in order to\nmay refuse to permit a\nunderstand the implications of standards and measures put in place by researchers,",
    "page": 45
  },
  {
    "type": "text",
    "content": "fuse to permit a\nunderstand the implications of standards and measures put in place by researchers,\ngovernment, and industry.131\npotentially promising\nPolicy and legal considerations application—or green light\nWhile a comprehensive examination of the ways artificial intelligence (AI) interacts\na sensitive application that\nwith the law is beyond the scope of this inaugural report, this much seems clear:\nas a transformative technology, AI has the potential to challenge any number of has not been adequately\nlegal assumptions in the short, medium, and long term. Precisely how law and policy\nwill adapt to advances in AI—and how AI will adapt to values reflected in law and vetted.\npolicy—depends on a variety of social, cultural, economic, and other factors, and\nis likely to vary by jurisdiction.",
    "page": 45
  },
  {
    "type": "text",
    "content": "n a variety of social, cultural, economic, and other factors, and\nis likely to vary by jurisdiction.\nAmerican law represents a mixture of common law, federal, state, and local\nstatutes and ordinances, and—perhaps of greatest relevance to AI—regulations.\nDepending on its instantiation, AI could implicate each of these sources of law. For\nexample, Nevada passed a law broadly permitting autonomous vehicles and instructed\nthe Nevada Department of Motor Vehicles to craft requirements. Meanwhile, the\nNational Highway Transportation Safety Administration has determined that a self-\ndriving car system, rather than the vehicle occupants, can be considered the “driver”\nof a vehicle. Some car designs sidestep this issue by staying in autonomous mode",
    "page": 45
  },
  {
    "type": "text",
    "content": "dered the “driver”\nof a vehicle. Some car designs sidestep this issue by staying in autonomous mode\nonly when hands are on the wheel (at least every so often), so that the human driver\nhas ultimate control and responsibility. Still, Tesla’s adoption of this strategy did not\nprevent the first traffic fatality involving an autonomous car, which occurred in June\nof 2016. Such incidents are sure to influence public attitudes towards autonomous\ndriving. And as most people’s first experience with embodied agents, autonomous\ntransportation will strongly influence the public’s perception of AI.\nDriverless cars are, of course, but one example of the many instantiations of\nAI in services, products, and other contexts. The legal effect of introducing AI into",
    "page": 45
  },
  {
    "type": "text",
    "content": "antiations of\nAI in services, products, and other contexts. The legal effect of introducing AI into\nthe provision of tax advice, automated trading on the stock market, or generating\nmedical diagnoses will also vary in accordance to the regulators that govern\nthese contexts and the rules that apply within them. Many other examples of AI\napplications fall within current non-technology-specific policy, including predictive\n130 Eric Engleman, “Google Exception in Obama’s Cyber Order Questioned as Unwise Gap,”\nBloomberg Technology, March 4, 2013, accessed August 1, 2016, http://www.bloomberg.com/news/\narticles/2013-03-05/google-exception-in-obama-s-cyber-order-questioned-as-unwise-gap.\n131 Ryan Calo, “The Case for a Federal Robotics Commission,” Brookings Report, September 15,",
    "page": 45
  },
  {
    "type": "text",
    "content": "e-gap.\n131 Ryan Calo, “The Case for a Federal Robotics Commission,” Brookings Report, September 15,\n2014, accessed August 1, 2016, http://www.brookings.edu/research/reports2/2014/09/case-for-\nfederal-robotics-commission. 45",
    "page": 45
  },
  {
    "type": "text",
    "content": "policing, non-discriminatory loans, healthcare applications such as eldercare and\ndrug delivery, systems designed to interact with children (for example, autonomous\ntutoring systems are required to respect laws in regard to balanced handling of\nevolution vs. intelligent design), and interactive entertainment.\nGiven the present structure of American administrative law, it seems unlikely\nthat AI will be treated comprehensively in the near term. Nevertheless, it is possible\nto enumerate broad categories of legal and policy issues that AI tends to raise in\nvarious contexts.\nAs AI applications engage\nPrivacy\nPrivate information about an individual can be revealed through decisions and\nin behavior that, were it\npredictions made by AI. While some of the ways that AI implicates privacy mirror",
    "page": 46
  },
  {
    "type": "text",
    "content": "vior that, were it\npredictions made by AI. While some of the ways that AI implicates privacy mirror\ndone by a human, would those of technologies such as computers and the internet, other issues may be unique\nto AI. For example, the potential of AI to predict future behavior based on previous\nconstitute a crime, courts patterns raises challenging questions. Companies already use machine learning to\npredict credit risk. And states run prisoner details through complex algorithms to\nand other legal actors will\npredict the likelihood of recidivism when considering parole. In these cases, it is a\ntechnical challenge to ensure that factors such as race and sexual orientation are not\nhave to puzzle through\nbeing used to inform AI-based decisions. Even when such features are not directly",
    "page": 46
  },
  {
    "type": "text",
    "content": "to puzzle through\nbeing used to inform AI-based decisions. Even when such features are not directly\nwhom to hold accountable provided to the algorithms, they may still correlate strongly with seemingly innocuous\nfeatures such as zip code. Nonetheless, with careful design, testing, and deployment,\nand on what theory.\nAI algorithms may be able to make less biased decisions than a typical person.\nAnthropomorphic interfaces increasingly associated with AI raise novel privacy\nconcerns. Social science research suggests people are hardwired to respond to\nanthropomorphic technology as though it were human. Subjects in one study\nwere more likely to answer when they were born if the computer first stated\nwhen it was built.132 In another, they skipped sensitive questions when posed by an",
    "page": 46
  },
  {
    "type": "text",
    "content": "er first stated\nwhen it was built.132 In another, they skipped sensitive questions when posed by an\nanthropomorphic interface.133 At a basic level lies the question: Will humans continue\nto enjoy the prospect of solitude in a world permeated by apparently social agents\n“living” in our houses, cars, offices, hospital rooms, and phones?134\nInnovation policy\nEarly law and policy decisions concerning liability and speech helped ensure the\ncommercial viability of the Internet. By contrast, the software industry arguably\nsuffers today from the decision of firms to pivot from open and free software to the\nmore aggressive pursuit of intellectual property protections, resulting in what some\nhave termed patent “thickets.” Striking the proper balance between incentivizing",
    "page": 46
  },
  {
    "type": "text",
    "content": "lting in what some\nhave termed patent “thickets.” Striking the proper balance between incentivizing\ninnovation in AI while promoting cooperation and protection against third party\nharm will prove a central challenge.\nLiability (civil)\nAs AI is organized to directly affect the world, even physically, liability for harms\ncaused by AI will increase in salience. The prospect that AI will behave in ways\ndesigners do not expect challenges the prevailing assumption within tort law that\ncourts only compensate for foreseeable injuries. Courts might arbitrarily assign\nliability to a human actor even when liability is better located elsewhere for reasons\nof fairness or efficiency. Alternatively, courts could refuse to find liability because",
    "page": 46
  },
  {
    "type": "text",
    "content": "for reasons\nof fairness or efficiency. Alternatively, courts could refuse to find liability because\nthe defendant before the court did not, and could not, foresee the harm that the AI\ncaused. Liability would then fall by default on the blameless victim. The role\n132 Youngme Moon, “Intimate Exchanges: Using Computers to Elicit Self-Disclosure from\nConsumers,” Journal of Consumer Research 26, no. 4 (March 2000): 323–339.\n133 Lee Sproull, Mani Subramani, Sara Kiesler , Janet H. Walker, and Keith Waters, “When the\nInterface is a Face,” Human-Computer Interaction 11, no. 2 (1996): 97–124.\n134 M. Ryan Calo, “People Can Be So Fake: A New Dimension to Privacy and Technology\n46 Scholarship,” Penn State Law Review 114, no. 3 (2010): 809–855.",
    "page": 46
  },
  {
    "type": "text",
    "content": "te Law Review 114, no. 3 (2010): 809–855.",
    "page": 46
  },
  {
    "type": "text",
    "content": "of product liability—and the responsibility that falls to companies manufacturing\nthese products— will likely grow when human actors become less responsible for the\nactions of a machine.\nLiability (criminal)\nIf tort law expects harms to be foreseeable, criminal law goes further to expect that\nharms be intended. US law in particular attaches great importance to the concept of\nmens rea—the intending mind. As AI applications engage in behavior that, were it\ndone by a human, would constitute a crime, courts and other legal actors will have to\nAI applications could\npuzzle through whom to hold accountable and on what theory.\nAgency\nincreasingly shift\nThe above issues raise the question of whether and under what circumstances an\nAI system could operate as the agent of a person or corporation.",
    "page": 47
  },
  {
    "type": "text",
    "content": "her and under what circumstances an\nAI system could operate as the agent of a person or corporation. Already regulatory investment from payroll\nbodies in the United States, Canada, and elsewhere are setting the conditions under\nwhich software can enter into a binding contract.135 The more AI conducts legally and income to capital\nsalient activities, the greater the challenge to principles of agency under the law.\nexpenditure. Depending on\nCertification\nThe very notion of “artificial intelligence” suggests a substitution for human skill\na state budget’s reliance\nand ingenuity. And in many contexts, ranging from driving to performing surgery or\npracticing law, a human must attain some certification or license before performing on payroll and income\na given task.",
    "page": 47
  },
  {
    "type": "text",
    "content": "uman must attain some certification or license before performing on payroll and income\na given task. Accordingly, law and policy will have to—and already does—grapple\ntax, such a shift could be\nwith how to determine competency in an AI system. For example, imagine a\nrobotics company creates a surgical platform capable of autonomously removing an\ndestabilizing.\nappendix. Or imagine a law firm writes an application capable of rendering legal\nadvice. Today, it is unclear from a legal perspective who in this picture would have to\npass the medical boards or legal bar, let alone where they would be required to do so.136\nLabor\nAs AI substitutes for human roles, some jobs will be eliminated and new jobs will\nbe created. The net effect on jobs is ambiguous, but labor markets are unlikely to",
    "page": 47
  },
  {
    "type": "text",
    "content": "nd new jobs will\nbe created. The net effect on jobs is ambiguous, but labor markets are unlikely to\nbenefit everyone evenly. The demand for some types of skills or abilities will likely\ndrop significantly, negatively affecting the employment levels and wages of people\nwith those skills.137 While the ultimate effects on income levels and distribution are not\ninevitable, they depend substantially on government policies, on the way companies\nchoose to organize work, and on decisions by individuals to invest in learning new\nskills and seeking new types of work and income opportunities. People who find their\nemployment altered or terminated as a consequence of advances of AI may seek\nrecourse in the legislature and courts. This may be why Littler Mendelson LLP—",
    "page": 47
  },
  {
    "type": "text",
    "content": "ances of AI may seek\nrecourse in the legislature and courts. This may be why Littler Mendelson LLP—\nperhaps the largest employment law firm in the world—has an entire practice group\nto address robotics and artificial intelligence.\nTaxation\nFederal, state, and local revenue sources may be affected. Accomplishing a task using AI\ninstead of a person can be faster and more accurate—and avoid employment taxes.\nAs a result, AI applications could increasingly shift investment from payroll and\nincome to capital expenditure. Depending on a state budget’s reliance on payroll\nand income tax, such a shift could be destabilizing. AI may also display different\n135 Ian R. Kerr, “Ensuring the Success of Contract Formation in Agent-Mediated Electronic",
    "page": 47
  },
  {
    "type": "text",
    "content": "different\n135 Ian R. Kerr, “Ensuring the Success of Contract Formation in Agent-Mediated Electronic\nCommerce,” Electronic Commerce Research 1 (2001): 183–202.\n136 Ryan Calo, “Digital Agenda’s public discussion on ‘The effects of robotics on economics,\nlabour and society,’” Ausschuss Digitale Agenda, (Deutsche Bundestag: Ausschussdrucksache A-Drs.\n18(24)102), June 22, 2016, accessed August 1, 2016, https://www.bundestag.de/blob/428266/195a\n1cde8d5347849accbbe60ed91865/a-drs-18-24-102-data.pdf.\n137 Brynjolfsson and McAfee, “Race Against the Machine: How the Digital Revolution is\nAccelerating Innovation, Driving Productivity, and Irreversibly Transforming Employment and the\nEconomy (2011)”; Brynjolfsson and McAfee, Second Machine Age. 47",
    "page": 47
  },
  {
    "type": "text",
    "content": "njolfsson and McAfee, Second Machine Age. 47",
    "page": 47
  },
  {
    "type": "text",
    "content": "“habits” than people, resulting in still fewer revenue sources. The many municipalities\nrelying on income from speeding or parking tickets will have to find alternatives\nif autonomous cars can drop people off and find distance parking, or if they are\nprogrammed not to violate the law. As a result, government bodies trying to balance\ntheir budgets in light of advances in AI may pass legislation to slow down or alter the\ncourse of the technology.\nPolitics\nAI technologies are already being used by political actors in gerrymandering and\nLike other technologies,\ntargeted “robocalls” designed to suppress votes, and on social media platforms in the\nform of “bots.”138 They can enable coordinated protest as well as the ability to predict\nAI has the potential to be",
    "page": 48
  },
  {
    "type": "text",
    "content": "38 They can enable coordinated protest as well as the ability to predict\nAI has the potential to be\nprotests, and promote greater transparency in politics by more accurately pinpointing\nused for good or nefarious who said what, when. Thus, administrative and regulatory laws regarding AI can be\ndesigned to promote greater democratic participation or, if ill-conceived, to reduce it.\npurposes. A vigorous and This list is not exhaustive and focuses largely on domestic policy in the United\nStates, leaving out many areas of law that AI is likely to touch. One lesson that\ninformed debate about\nmight be drawn concerns the growing disconnect between the context-specific way\nin which AI is governed today and a wider consideration of themes shared by AI\nhow to best steer AI in",
    "page": 48
  },
  {
    "type": "text",
    "content": "which AI is governed today and a wider consideration of themes shared by AI\nhow to best steer AI in\ntechnologies across industries or sectors of society. It could be tempting to create new\nways that enrich our lives institutional configurations capable of amassing expertise and setting AI standards\nacross multiple contexts. The Study Panel’s consensus is that attempts to regulate “AI”\nand our society is an\nin general would be misguided, since there is no clear definition of AI (it isn’t any\none thing), and the risks and considerations are very different in different domains.\nurgent and vital need.\nInstead, policymakers should recognize that to varying degrees and over time, various\nindustries will need distinct, appropriate, regulations that touch on software built",
    "page": 48
  },
  {
    "type": "text",
    "content": "time, various\nindustries will need distinct, appropriate, regulations that touch on software built\nusing AI or incorporating AI in some way. The government will need the expertise to\nscrutinize standards and technology developed by the private and public sector, and\nto craft regulations where necessary.\nGuidelines for the future\nFaced with the profound changes that AI technologies can produce, pressure for\n“more” and “tougher” regulation is inevitable. Misunderstanding about what AI is\nand is not, especially against a background of scare-mongering, could fuel opposition\nto technologies that could benefit everyone. This would be a tragic mistake.\nRegulation that stifles innovation, or relocates it to other jurisdictions, would be\nsimilarly counterproductive.",
    "page": 48
  },
  {
    "type": "text",
    "content": "t stifles innovation, or relocates it to other jurisdictions, would be\nsimilarly counterproductive.\nFortunately, principles that guide successful regulation of current digital\ntechnologies can be instructive. A recent multi-year study comparing privacy\nregulation in four European countries and the United States, for example, yielded\ncounter-intuitive results.139 Those countries, such as Spain and France, with strict\nand detailed regulations bred a “compliance mentality” within corporations, which\nhad the effect of discouraging both innovation and robust privacy protections.\nRather than taking responsibility for privacy protection internally and developing a\nprofessional staff to foster it in business and manufacturing processes, or engaging with",
    "page": 48
  },
  {
    "type": "text",
    "content": "eloping a\nprofessional staff to foster it in business and manufacturing processes, or engaging with\nprivacy advocates or academics outside their walls, these companies viewed privacy as\na compliance activity. Their focus was on avoiding fines or punishments, rather than\nproactively designing technology and adapting practices to protect privacy.\nBy contrast, the regulatory environment in the United States and Germany,\nwhich combined more ambiguous goals with tough transparency requirements and\nmeaningful enforcement, were more successful in catalyzing companies to view\n138 Political Bots, accessed August 1, 2016, http://politicalbots.org/.\n139 Kenneth A. Bamberger and Deirdre K. Mulligan, Privacy on the Ground: Driving Corporate Behavior",
    "page": 48
  },
  {
    "type": "text",
    "content": "139 Kenneth A. Bamberger and Deirdre K. Mulligan, Privacy on the Ground: Driving Corporate Behavior\n48 in the United States and Europe (Cambridge, Massachusetts: MIT Press, 2015).",
    "page": 48
  },
  {
    "type": "text",
    "content": "privacy as their responsibility. Broad legal mandates encouraged companies to\ndevelop a professional staff and processes to enforce privacy controls, engage with\noutside stakeholders, and to adapt their practices to technology advances. Requiring\ngreater transparency enabled civil society groups and media to become credible\nenforcers both in court and in the court of public opinion, making privacy more\nsalient to corporate boards and leading them to further invest in privacy protection.\nIn AI, too, regulators can strengthen a virtuous cycle of activity involving internal\nand external accountability, transparency, and professionalization, rather than narrow\ncompliance. As AI is integrated into cities, it will continue to challenge existing",
    "page": 49
  },
  {
    "type": "text",
    "content": "her than narrow\ncompliance. As AI is integrated into cities, it will continue to challenge existing\nprotections for values such as privacy and accountability. Like other technologies, AI\nhas the potential to be used for good or nefarious purposes. This report has tried to\nhighlight the potential for both. A vigorous and informed debate about how to best\nsteer AI in ways that enrich our lives and our society, while encouraging creativity\nin the field, is an urgent and vital need. Policies should be evaluated as to whether\nthey democratically foster the development and equitable sharing of AI’s benefits,\nor concentrate power and benefits in the hands of a fortunate few. And since future\nAI technologies and their effects cannot be foreseen with perfect clarity, policies will",
    "page": 49
  },
  {
    "type": "text",
    "content": "nce future\nAI technologies and their effects cannot be foreseen with perfect clarity, policies will\nneed to be continually re-evaluated in the context of observed societal challenges and\nevidence from fielded systems.\nAs this report documents, significant AI-related advances have already had\nan impact on North American cities over the past fifteen years, and even more\nsubstantial developments will occur over the next fifteen. Recent advances are largely\ndue to the growth and analysis of large data sets enabled by the Internet, advances\nin sensory technologies and, more recently, applications of “deep learning.” In the\ncoming years, as the public encounters new AI applications in domains such as\ntransportation and healthcare, they must be introduced in ways that build trust and",
    "page": 49
  },
  {
    "type": "text",
    "content": "domains such as\ntransportation and healthcare, they must be introduced in ways that build trust and\nunderstanding, and respect human and civil rights. While encouraging innovation,\npolicies and processes should address ethical, privacy, and security implications, and\nshould work to ensure that the benefits of AI technologies will be spread broadly and\nfairly. Doing so will be critical if Artificial Intelligence research and its applications\nare to exert a positive influence on North American urban life in 2030 and beyond.\n49",
    "page": 49
  },
  {
    "type": "text",
    "content": "APPENDIX I: A SHORT HISTORY OF AI\nThis Appendix is based primarily on Nilsson’s book140 and written from the prevalent\ncurrent perspective, which focuses on data intensive methods and big data. However\nimportant, this focus has not yet shown itself to be the solution to all problems. A\ncomplete and fully balanced history of the field is beyond the scope of this document.\nThe field of Artificial Intelligence (AI) was officially born and christened at a 1956\nworkshop organized by John McCarthy at the Dartmouth Summer Research Project\non Artificial Intelligence. The goal was to investigate ways in which machines could\nThe field of Artificial\nbe made to simulate aspects of intelligence—the essential idea that has continued to\nIntelligence (AI) was drive the field forward.",
    "page": 50
  },
  {
    "type": "text",
    "content": "intelligence—the essential idea that has continued to\nIntelligence (AI) was drive the field forward. McCarthy is credited with the first use of the term “artificial\nintelligence” in the proposal he co-authored for the workshop with Marvin Minsky,\nofficially born and\nNathaniel Rochester, and Claude Shannon.141 Many of the people who attended soon\nled significant projects under the banner of AI, including Arthur Samuel, Oliver\nchristened at a 1956\nSelfridge, Ray Solomonoff, Allen Newell, and Herbert Simon.\nworkshop. The goal was to Although the Dartmouth workshop created a unified identity for the field and\na dedicated research community, many of the technical ideas that have come to\ninvestigate ways in which characterize AI existed much earlier. In the eighteenth century, Thomas Bayes",
    "page": 50
  },
  {
    "type": "text",
    "content": "stigate ways in which characterize AI existed much earlier. In the eighteenth century, Thomas Bayes\nprovided a framework for reasoning about the probability of events.142 In the\nmachines could be made\nnineteenth century, George Boole showed that logical reasoning—dating back to\nAristotle—could be performed systematically in the same manner as solving a system\nto simulate aspects of\nof equations.143 By the turn of the twentieth century, progress in the experimental\nintelligence—the essential sciences had led to the emergence of the field of statistics,144 which enables\ninferences to be drawn rigorously from data. The idea of physically engineering a\nidea that has continued to\nmachine to execute sequences of instructions, which had captured the imagination",
    "page": 50
  },
  {
    "type": "text",
    "content": "t has continued to\nmachine to execute sequences of instructions, which had captured the imagination\nof pioneers such as Charles Babbage, had matured by the 1950s, and resulted in the\ndrive the field forward.\nconstruction of the first electronic computers.145 Primitive robots, which could\nsense and act autonomously, had also been built by that time.146\nThe most influential ideas underpinning computer science came from Alan Turing,\nwho proposed a formal model of computing. Turing’s classic essay, Computing Machinery\nand Intelligence,147 imagines the possibility of computers created for simulating intelligence\nand explores many of the ingredients now associated with AI, including how intelligence\nmight be tested, and how machines might automatically learn. Though these ideas",
    "page": 50
  },
  {
    "type": "text",
    "content": "ng how intelligence\nmight be tested, and how machines might automatically learn. Though these ideas\ninspired AI, Turing did not have access to the computing resources needed to\ntranslate his ideas into action.\nSeveral focal areas in the quest for AI emerged between the 1950s and the 1970s.148\n140 Nilsson, The Quest for Artificial Intelligence.\n141 J. McCarthy, Marvin L. Minsky, Nathaniel Rochester, and Claude E. Shannon, “A Proposal\nfor the Dartmouth Summer Research Project on Artificial Intelligence,” August 31, 1955, accessed\nAugust 1, 2016, http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html.\n142 Thomas Bayes, “An Essay towards Solving a Problem in the Doctrine of Chances,”",
    "page": 50
  },
  {
    "type": "text",
    "content": "/dartmouth.html.\n142 Thomas Bayes, “An Essay towards Solving a Problem in the Doctrine of Chances,”\nPhilosophical Transactions of the Royal Society of London 53 (January 1, 1763): 370–418, accessed August 1,\n2016, http://rstl.royalsocietypublishing.org/search?fulltext=an+essay+towards+solving&submit=yes\n&andorexactfulltext=and&x=0&y=0.\n143 George Boole, An Investigation of the Laws of Thought on Which are Founded the Mathematical Theories\nof Logic and Probabilities, (Macmillan, 1854, reprinted with corrections, Dover Publications, New\nYork, NY, 1958, and reissued by Cambridge University Press, 2009), accessed August 1, 2016,\nhttp://ebooks.cambridge.org/ebook.jsf?bid=CBO9780511693090.\n144 “History of statistics,” Wikipedia, Last modified June 3, 2016, accessed August 1, 2016,\nhttps://en.",
    "page": 50
  },
  {
    "type": "text",
    "content": "“History of statistics,” Wikipedia, Last modified June 3, 2016, accessed August 1, 2016,\nhttps://en.wikipedia.org/wiki/History_of_statistics.\n145 Joel N. Shurkin, Engines of the Mind: The Evolution of the Computer from Mainframes to Microprocessors\n(New York: W. W. Norton & Company, 1996).\n146 William Grey Walter, “An Electromechanical Animal,” Dialectica 4 (1950): 42–49.\n147 A. M. Turing, “Computing Machinery and Intelligence,” Mind 59, no. 236 (1950): 433–460.\n148 Marvin Minsky, “Steps toward Artificial Intelligence,” MIT Media Laboratory, October 24,\n50 1960, accessed August 1, 2016, http://web.media.mit.edu/~minsky/papers/steps.html.",
    "page": 50
  },
  {
    "type": "text",
    "content": "Newell and Simon pioneered the foray into heuristic search, an efficient procedure\nfor finding solutions in large, combinatorial spaces. In particular, they applied this\nidea to construct proofs of mathematical theorems, first through their Logic Theorist\nprogram, and then through the General Problem Solver.149 In the area of computer\nvision, early work in character recognition by Selfridge and colleagues150 laid the\nbasis for more complex applications such as face recognition.151 By the late sixties,\nwork had also begun on natural language processing.152 “Shakey”, a wheeled\nrobot built at SRI International, launched the field of mobile robotics. Samuel’s\nAlthough the separation\nCheckers-playing program, which improved itself through self-play, was one of the",
    "page": 51
  },
  {
    "type": "text",
    "content": "gh the separation\nCheckers-playing program, which improved itself through self-play, was one of the\nfirst working instances of a machine learning system.153 Rosenblatt’s Perceptron,154\nof AI into sub-fields\na computational model based on biological neurons, became the basis for the field\nof artificial neural networks. Feigenbaum and others advocated 155the case for has enabled deep\nbuilding expert systems—knowledge repositories tailored for specialized domains\nsuch as chemistry and medical diagnosis.156 technical progress along\nEarly conceptual progress assumed the existence of a symbolic system that could\nseveral different fronts,\nbe reasoned about and built upon. But by the 1980s, despite this promising headway",
    "page": 51
  },
  {
    "type": "text",
    "content": "ifferent fronts,\nbe reasoned about and built upon. But by the 1980s, despite this promising headway\nmade into different aspects of artificial intelligence, the field still could boast no\nsynthesizing intelligence\nsignificant practical successes. This gap between theory and practice arose in part from\nan insufficient emphasis within the AI community on grounding systems physically, with at any reasonable scale\ndirect access to environmental signals and data. There was also an overemphasis on\ninvariably requires many\nBoolean (True/False) logic, overlooking the need to quantify uncertainty. The field\nwas forced to take cognizance of these shortcomings in the mid-1980s, since interest\ndifferent ideas to be\nin AI began to drop, and funding dried up. Nilsson calls this period the “AI winter.”",
    "page": 51
  },
  {
    "type": "text",
    "content": "t ideas to be\nin AI began to drop, and funding dried up. Nilsson calls this period the “AI winter.”\nA much needed resurgence in the nineties built upon the idea that “Good Old- integrated.\nFashioned AI”157 was inadequate as an end-to-end approach to building intelligent\nsystems. Rather, intelligent systems needed to be built from the ground up, at all times\nsolving the task at hand, albeit with different degrees of proficiency.158 Technological\nprogress had also made the task of building systems driven by real-world data more\nfeasible. Cheaper and more reliable hardware for sensing and actuation made robots\neasier to build. Further, the Internet’s capacity for gathering large amounts of data,\nand the availability of computing power and storage to process that data, enabled",
    "page": 51
  },
  {
    "type": "text",
    "content": "amounts of data,\nand the availability of computing power and storage to process that data, enabled\nstatistical techniques that, by design, derive solutions from data. These developments\nhave allowed AI to emerge in the past two decades as a profound influence on our\ndaily lives, as detailed in Section II.\n149 Allen Newell, John C Shaw, and Herbert A Simon, “Report on a general problem-solving\nprogram,” Proceedings of the International Conference on Information Processing, UNESCO, Paris 15-20\nJune 1959 (Unesco/Oldenbourg/Butterworths, 1960), 256–264.\n150 O. G. Selfridge, “Pandemonium: A paradigm for learning,” Proceedings of the Symposium on\nMechanization of Thought Processes (London: H. M. Stationary Office, 1959): 511–531.\n151 Woodrow W.",
    "page": 51
  },
  {
    "type": "text",
    "content": "Mechanization of Thought Processes (London: H. M. Stationary Office, 1959): 511–531.\n151 Woodrow W. Bledsoe and Helen Chan, “A Man-Machine Facial Recognition System: Some\nPreliminary Results,” Technical Report PRI 19A (Palo Alto, California: Panoramic Research, Inc., 1965).\n152 D. Raj Reddy, “Speech Recognition by Machine: A Review,” Proceedings of the IEEE 64, no.4\n(April 1976), 501–531.\n153 Arthur Samuel, “Some Studies in Machine Learning Using the Game of Checkers, IBM\nJournal of Research and Development 3, no. 3 (1959): 210—229.\n154 Frank Rosenblatt, “The Perceptron—A Perceiving and Recognizing Automaton,”\nReport 85-460-1, (Buffalo, New York: Cornell Aeronautical Laboratory, 1957).\n155 “Shakey the robot,” Wikipedia, last modified July 11, 2016, accessed August 1, 2016,\nhttps://en.",
    "page": 51
  },
  {
    "type": "text",
    "content": "155 “Shakey the robot,” Wikipedia, last modified July 11, 2016, accessed August 1, 2016,\nhttps://en.wikipedia.org/wiki/Shakey_the_robot.\n156 Edward A. Feigenbaum and Bruce G. Buchanan, “DENDRAL and Meta-DENDRAL:\nRoots of Knowledge Systems and Expert System Applications,” Artificial Intelligence 59, no. 1-2\n(1993), 233–240.\n157 John Haugeland, Artificial Intelligence: The Very Idea, (Cambridge, Massachusetts: MIT\nPress, 1985).\n158 Rodney A. Brooks, “Elephants Don’t Play Chess,” Robotics and Autonomous Systems 6, no. 1-2\n(June 1990): 3–15. 51",
    "page": 51
  },
  {
    "type": "text",
    "content": "In summary, following is a list of some of the traditional sub-areas of AI. As described\nin Section II, some of them are currently “hotter” than others for various reasons.\nBut that is neither to minimize the historical importance of the others, nor to say that\nthey may not re-emerge as hot areas in the future.\n• Search and Planning deal with reasoning about goal-directed behavior. Search\nplays a key role, for example, in chess-playing programs such as Deep Blue, in\ndeciding which move (behavior) will ultimately lead to a win (goal).\n• The area of Knowledge Representation and Reasoning involves processing\ninformation (typically when in large amounts) into a structured form that can\nbe queried more reliably and efficiently. IBM’s Watson program, which beat",
    "page": 52
  },
  {
    "type": "text",
    "content": "structured form that can\nbe queried more reliably and efficiently. IBM’s Watson program, which beat\nhuman contenders to win the Jeopardy challenge in 2011, was largely based on\nan efficient scheme for organizing, indexing, and retrieving large amounts of\ninformation gathered from various sources.159\n• Machine Learning is a paradigm that enables systems to automatically improve\ntheir performance at a task by observing relevant data. Indeed, machine\nlearning has been the key contributor to the AI surge in the past few decades,\nranging from search and product recommendation engines, to systems for\nspeech recognition, fraud detection, image understanding, and countless other\ntasks that once relied on human skill and judgment. The automation of these",
    "page": 52
  },
  {
    "type": "text",
    "content": "ng, and countless other\ntasks that once relied on human skill and judgment. The automation of these\ntasks has enabled the scaling up of services such as e-commerce.\n• As more and more intelligent systems get built, a natural question to consider\nis how such systems will interact with each other. The field of Multi-Agent\nSystems considers this question, which is becoming increasingly important in\non-line marketplaces and transportation systems.\n• From its early days, AI has taken up the design and construction of systems that\nare embodied in the real world. The area of Robotics investigates fundamental\naspects of sensing and acting—and especially their integration—that enable\na robot to behave effectively. Since robots and other computer systems share",
    "page": 52
  },
  {
    "type": "text",
    "content": "ntegration—that enable\na robot to behave effectively. Since robots and other computer systems share\nthe living world with human beings, the specialized subject of Human Robot\nInteraction has also become prominent in recent decades.\n• Machine perception has always played a central role in AI, partly in developing\nrobotics, but also as a completely independent area of study. The most commonly\nstudied perception modalities are Computer Vision and Natural Language\nProcessing, each of which is attended to by large and vibrant communities.\n• Several other focus areas within AI today are consequences of the growth of the\nInternet. Social Network Analysis investigates the effect of neighborhood relations\nin influencing the behavior of individuals and communities. Crowdsourcing is",
    "page": 52
  },
  {
    "type": "text",
    "content": "neighborhood relations\nin influencing the behavior of individuals and communities. Crowdsourcing is\nyet another innovative problem-solving technique, which relies on harnessing\nhuman intelligence (typically from thousands of humans) to solve hard\ncomputational problems.\nAlthough the separation of AI into sub-fields has enabled deep technical progress\nalong several different fronts, synthesizing intelligence at any reasonable scale invariably\nrequires many different ideas to be integrated. For example, the AlphaGo program160 161\nthat recently defeated the current human champion at the game of Go used multiple\nmachine learning algorithms for training itself, and also used a sophisticated search\nprocedure while playing the game.\n159 David A.",
    "page": 52
  },
  {
    "type": "text",
    "content": "training itself, and also used a sophisticated search\nprocedure while playing the game.\n159 David A. Ferrucci, “Introduction to ‘This is Watson,’” IBM Journal of Research and Development,\n56, no. 3-4 (2012): 1.\n160 David Silver et al., “Mastering the Game of Go with Deep Neural Networks and Tree Search.”\n161 Steven Borowiec and Tracey Lien, “AlphaGo beats human Go champ in milestone for\nartificial intelligence,” Los Angeles Times, March 12, 2016, accessed August 1, 2016, http://www.\nlatimes.com/world/asia/la-fg-korea-alphago-20160312-story.html.\n52",
    "page": 52
  }
]